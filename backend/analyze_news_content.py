#!/usr/bin/env python3
"""
ë„¤ì´ë²„ ë‰´ìŠ¤ API ì‘ë‹µ ë‚´ìš© ìƒì„¸ ë¶„ì„
"""

import requests
import json
import re

def analyze_news_content():
    client_id = "kXwlSsFmb055ku9rWyx1"
    client_secret = "JZqw_LTiq_"
    base_url = "https://openapi.naver.com/v1/search/news.json"
    
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret,
        "User-Agent": "NewsBot/1.0"
    }
    
    def clean_html(text):
        clean = re.sub('<.*?>', '', text)
        clean = clean.replace('&lt;', '<').replace('&gt;', '>')
        clean = clean.replace('&amp;', '&').replace('&quot;', '"')
        clean = clean.replace('&#39;', "'").replace('&nbsp;', ' ')
        return clean.strip()
    
    # ì •ì¹˜ì¸ë³„ ë‰´ìŠ¤ ìƒì„¸ ë¶„ì„
    politicians = ['ì´ì¬ëª…', 'í•œë™í›ˆ', 'ì¡°êµ­']
    
    for politician in politicians:
        print(f"\nğŸ” {politician} ë‰´ìŠ¤ ìƒì„¸ ë¶„ì„")
        print("=" * 50)
        
        # ê°€ì¥ íš¨ê³¼ì ì¸ ê²€ìƒ‰ì–´ ì°¾ê¸°
        queries = [
            f'{politician} ì •ì¹˜',
            f'{politician} ì˜ì›', 
            f'{politician} êµ­íšŒ'
        ]
        
        for query in queries:
            print(f"\nê²€ìƒ‰ì–´: '{query}'")
            
            try:
                params = {
                    "query": query,
                    "display": 5,
                    "start": 1,
                    "sort": "date"
                }
                
                response = requests.get(base_url, headers=headers, params=params, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    items = data.get('items', [])
                    
                    print(f"  ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(items)}ê±´")
                    
                    for i, item in enumerate(items[:3]):
                        title = clean_html(item.get('title', ''))
                        description = clean_html(item.get('description', ''))
                        pub_date = item.get('pubDate', '')
                        
                        print(f"\n  ë‰´ìŠ¤ {i+1}:")
                        print(f"    ì œëª©: {title}")
                        print(f"    ì„¤ëª…: {description[:150]}...")
                        print(f"    ë°œí–‰ì¼: {pub_date}")
                        
                        # ì •ì¹˜ í‚¤ì›Œë“œ ì²´í¬
                        political_keywords = ['ì˜ì›', 'êµ­íšŒ', 'ì •ì¹˜', 'ì •ë¶€', 'ì •ë‹¹', 'ë²•ì•ˆ', 'ë°œì˜']
                        found_keywords = [kw for kw in political_keywords if kw in (title + description)]
                        print(f"    ì •ì¹˜ í‚¤ì›Œë“œ: {found_keywords}")
                        
                        # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
                        exclude_keywords = ['ì˜í™”', 'ë“œë¼ë§ˆ', 'ì˜ˆëŠ¥', 'ë°°ìš°']
                        found_exclude = [kw for kw in exclude_keywords if kw in (title + description)]
                        print(f"    ì œì™¸ í‚¤ì›Œë“œ: {found_exclude}")
                        
                        # ìµœì¢… íŒë‹¨
                        is_political = len(found_keywords) > 0 and len(found_exclude) == 0
                        print(f"    ì •ì¹˜ ê´€ë ¨ì„±: {'âœ…' if is_political else 'âŒ'}")
                
                else:
                    print(f"  API ì˜¤ë¥˜: {response.status_code}")
                    
            except Exception as e:
                print(f"  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    analyze_news_content()
