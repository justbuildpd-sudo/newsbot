#!/usr/bin/env python3
"""
í†µê³„ìë£Œ ì‹œê³„ì—´ ê²€ì¦ê¸°
2014ë…„ ì‹œì‘ì‹œì  í™•ì¸ ë° ë°ì´í„° ì‹œê°„ì  ì—°ì†ì„± ê²€ì¦
- ëª¨ë“  ìˆ˜ì§‘ëœ í†µê³„ ë°ì´í„°ì˜ ì‹œì‘ì‹œì  í™•ì¸
- ì„ ê±° ë°ì´í„°ì™€ í†µê³„ ë°ì´í„° ì‹œì  ë§¤ì¹­
- ì‹œê³„ì—´ ë¶„ì„ ê¸°ì¤€ì  ì •í™•ì„± ê²€ì¦
"""

import json
import glob
import os
import re
from datetime import datetime
from typing import Dict, List, Optional, Tuple

class DataTimelineValidator:
    def __init__(self):
        self.base_dir = "/Users/hopidaay/newsbot-kr/backend"
        
        # ì•Œë ¤ì§„ ì„ ê±° ì‹œì ë“¤
        self.election_timeline = {
            "2014-06-04": "ì œ6íšŒ ì „êµ­ë™ì‹œì§€ë°©ì„ ê±°",
            "2016-04-13": "ì œ20ëŒ€ êµ­íšŒì˜ì›ì„ ê±°", 
            "2018-06-13": "ì œ7íšŒ ì „êµ­ë™ì‹œì§€ë°©ì„ ê±°",
            "2020-04-15": "ì œ21ëŒ€ êµ­íšŒì˜ì›ì„ ê±°",
            "2022-06-01": "ì œ8íšŒ ì „êµ­ë™ì‹œì§€ë°©ì„ ê±°"
        }
        
        # í†µê³„ ë°ì´í„° ìˆ˜ì§‘ ì£¼ê¸°
        self.statistical_cycles = {
            "ì¸êµ¬ì£¼íƒì´ì¡°ì‚¬": {"cycle": 5, "years": [2015, 2020, 2025]},
            "ë†ë¦¼ì–´ì—…ì´ì¡°ì‚¬": {"cycle": 5, "years": [2015, 2020, 2025]}, 
            "ì „êµ­ì‚¬ì—…ì²´ì¡°ì‚¬": {"cycle": 1, "start_year": 2014},
            "ì‚¬íšŒì¡°ì‚¬": {"cycle": 2, "years": [2014, 2016, 2018, 2020, 2022, 2024]},
            "ìƒí™œì‹œê°„ì¡°ì‚¬": {"cycle": 5, "years": [2014, 2019, 2024]}
        }

    def extract_years_from_file(self, filepath: str) -> List[int]:
        """íŒŒì¼ì—ì„œ ì—°ë„ ì •ë³´ ì¶”ì¶œ"""
        years_found = []
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
                
                # ì—°ë„ íŒ¨í„´ ì°¾ê¸° (2014-2025)
                year_patterns = [
                    r'20[12][0-9]',  # 2010-2029
                    r'["\']20[12][0-9]["\']',  # ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ì—°ë„
                    r'year.*?20[12][0-9]',  # year í‚¤ì›Œë“œ í¬í•¨
                    r'data_period.*?20[12][0-9]'  # data_period í‚¤ì›Œë“œ í¬í•¨
                ]
                
                for pattern in year_patterns:
                    matches = re.findall(pattern, content)
                    for match in matches:
                        # ìˆ«ìë§Œ ì¶”ì¶œ
                        year_str = re.search(r'20[12][0-9]', match)
                        if year_str:
                            year = int(year_str.group())
                            if 2014 <= year <= 2025:
                                years_found.append(year)
                
        except Exception as e:
            print(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {filepath} - {e}")
        
        return sorted(list(set(years_found)))

    def analyze_data_timeline_coverage(self) -> Dict:
        """ë°ì´í„° ì‹œê³„ì—´ ì»¤ë²„ë¦¬ì§€ ë¶„ì„"""
        print("ğŸ“Š ë°ì´í„° ì‹œê³„ì—´ ì»¤ë²„ë¦¬ì§€ ë¶„ì„...")
        
        timeline_analysis = {
            'files_analyzed': 0,
            'files_with_timeline': 0,
            'year_coverage': {str(year): 0 for year in range(2014, 2026)},
            'data_categories': {},
            'earliest_year': None,
            'latest_year': None,
            'timeline_completeness': 0.0
        }
        
        # JSON íŒŒì¼ë“¤ ë¶„ì„
        json_files = glob.glob(os.path.join(self.base_dir, "*.json"))
        
        for filepath in json_files:
            timeline_analysis['files_analyzed'] += 1
            filename = os.path.basename(filepath)
            
            # íŒŒì¼ì—ì„œ ì—°ë„ ì¶”ì¶œ
            years_in_file = self.extract_years_from_file(filepath)
            
            if years_in_file:
                timeline_analysis['files_with_timeline'] += 1
                
                # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
                category = self._categorize_file(filename)
                if category not in timeline_analysis['data_categories']:
                    timeline_analysis['data_categories'][category] = {
                        'files': 0,
                        'years_covered': set(),
                        'earliest_year': None,
                        'latest_year': None
                    }
                
                timeline_analysis['data_categories'][category]['files'] += 1
                timeline_analysis['data_categories'][category]['years_covered'].update(years_in_file)
                
                # ì „ì²´ ì—°ë„ ì»¤ë²„ë¦¬ì§€ ì—…ë°ì´íŠ¸
                for year in years_in_file:
                    timeline_analysis['year_coverage'][str(year)] += 1
                
                # ìµœì¡°/ìµœì‹  ì—°ë„ ì—…ë°ì´íŠ¸
                min_year = min(years_in_file)
                max_year = max(years_in_file)
                
                if timeline_analysis['earliest_year'] is None or min_year < timeline_analysis['earliest_year']:
                    timeline_analysis['earliest_year'] = min_year
                if timeline_analysis['latest_year'] is None or max_year > timeline_analysis['latest_year']:
                    timeline_analysis['latest_year'] = max_year
                
                cat_data = timeline_analysis['data_categories'][category]
                if cat_data['earliest_year'] is None or min_year < cat_data['earliest_year']:
                    cat_data['earliest_year'] = min_year
                if cat_data['latest_year'] is None or max_year > cat_data['latest_year']:
                    cat_data['latest_year'] = max_year
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì—°ë„ ì»¤ë²„ë¦¬ì§€ ì •ë¦¬
        for category, data in timeline_analysis['data_categories'].items():
            data['years_covered'] = sorted(list(data['years_covered']))
            data['year_span'] = len(data['years_covered'])
        
        # ì‹œê³„ì—´ ì™„ì„±ë„ ê³„ì‚°
        expected_years = list(range(2014, 2026))  # 2014-2025
        covered_years = [year for year, count in timeline_analysis['year_coverage'].items() if count > 0]
        timeline_analysis['timeline_completeness'] = len(covered_years) / len(expected_years)
        
        return timeline_analysis

    def _categorize_file(self, filename: str) -> str:
        """íŒŒì¼ëª… ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        filename_lower = filename.lower()
        
        if any(keyword in filename_lower for keyword in ['population', 'household', 'dong_map']):
            return 'population_demographics'
        elif any(keyword in filename_lower for keyword in ['housing', 'house']):
            return 'housing_residential'
        elif any(keyword in filename_lower for keyword in ['company', 'business', 'corp']):
            return 'business_economic'
        elif any(keyword in filename_lower for keyword in ['university', 'academy', 'education']):
            return 'education'
        elif any(keyword in filename_lower for keyword in ['urban', 'city']):
            return 'urbanization'
        elif any(keyword in filename_lower for keyword in ['welfare', 'culture']):
            return 'welfare_culture'
        elif any(keyword in filename_lower for keyword in ['labor', 'economy']):
            return 'labor_economy'
        elif any(keyword in filename_lower for keyword in ['religion']):
            return 'religion_culture'
        elif any(keyword in filename_lower for keyword in ['social']):
            return 'social_structure'
        elif any(keyword in filename_lower for keyword in ['transport', 'traffic']):
            return 'transportation'
        else:
            return 'other'

    def verify_2014_start_point(self, timeline_analysis: Dict) -> Dict:
        """2014ë…„ ì‹œì‘ì‹œì  ê²€ì¦"""
        print("ğŸ“… 2014ë…„ ì‹œì‘ì‹œì  ê²€ì¦...")
        
        verification_result = {
            'is_2014_start_confirmed': False,
            'actual_earliest_year': timeline_analysis['earliest_year'],
            'year_2014_coverage': timeline_analysis['year_coverage'].get('2014', 0),
            'categories_with_2014': [],
            'categories_without_2014': [],
            'start_point_assessment': 'UNKNOWN'
        }
        
        # 2014ë…„ ì‹œì‘ í™•ì¸
        if timeline_analysis['earliest_year'] == 2014:
            verification_result['is_2014_start_confirmed'] = True
            verification_result['start_point_assessment'] = 'CONFIRMED'
        elif timeline_analysis['earliest_year'] and timeline_analysis['earliest_year'] < 2014:
            verification_result['start_point_assessment'] = 'EARLIER_THAN_2014'
        elif timeline_analysis['earliest_year'] and timeline_analysis['earliest_year'] > 2014:
            verification_result['start_point_assessment'] = 'LATER_THAN_2014'
        
        # ì¹´í…Œê³ ë¦¬ë³„ 2014ë…„ í¬í•¨ ì—¬ë¶€ í™•ì¸
        for category, data in timeline_analysis['data_categories'].items():
            if 2014 in data['years_covered']:
                verification_result['categories_with_2014'].append({
                    'category': category,
                    'files': data['files'],
                    'year_span': data['year_span'],
                    'earliest': data['earliest_year']
                })
            else:
                verification_result['categories_without_2014'].append({
                    'category': category,
                    'files': data['files'],
                    'earliest': data['earliest_year'],
                    'missing_years': [year for year in range(2014, 2026) if year not in data['years_covered']]
                })
        
        return verification_result

    def check_statistical_survey_alignment(self, timeline_analysis: Dict) -> Dict:
        """í†µê³„ì¡°ì‚¬ ì£¼ê¸°ì™€ ë°ì´í„° ì •ë ¬ í™•ì¸"""
        print("ğŸ“‹ í†µê³„ì¡°ì‚¬ ì£¼ê¸° ì •ë ¬ í™•ì¸...")
        
        alignment_check = {
            'survey_alignment': {},
            'data_gaps': [],
            'temporal_consistency': 0.0
        }
        
        for survey_name, survey_info in self.statistical_cycles.items():
            alignment_result = {
                'survey_name': survey_name,
                'expected_cycle': survey_info['cycle'],
                'expected_years': survey_info.get('years', []),
                'found_in_data': False,
                'coverage_assessment': 'NOT_FOUND'
            }
            
            # ê´€ë ¨ ì¹´í…Œê³ ë¦¬ì—ì„œ í•´ë‹¹ ì¡°ì‚¬ ë°ì´í„° ì°¾ê¸°
            relevant_categories = []
            if 'ì¸êµ¬ì£¼íƒ' in survey_name:
                relevant_categories = ['population_demographics', 'housing_residential']
            elif 'ë†ë¦¼ì–´ì—…' in survey_name:
                relevant_categories = ['business_economic']  # 1ì°¨ ì‚°ì—…
            elif 'ì‚¬ì—…ì²´' in survey_name:
                relevant_categories = ['business_economic']
            elif 'ì‚¬íšŒì¡°ì‚¬' in survey_name:
                relevant_categories = ['social_structure', 'welfare_culture']
            
            # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ì—°ë„ í™•ì¸
            found_years = set()
            for category in relevant_categories:
                if category in timeline_analysis['data_categories']:
                    cat_years = timeline_analysis['data_categories'][category]['years_covered']
                    found_years.update(cat_years)
            
            if found_years:
                alignment_result['found_in_data'] = True
                alignment_result['found_years'] = sorted(list(found_years))
                
                # ì˜ˆìƒ ì—°ë„ì™€ ë¹„êµ
                if 'years' in survey_info:
                    expected = set(survey_info['years'])
                    overlap = expected.intersection(found_years)
                    if len(overlap) >= len(expected) * 0.7:
                        alignment_result['coverage_assessment'] = 'GOOD'
                    elif len(overlap) >= len(expected) * 0.4:
                        alignment_result['coverage_assessment'] = 'MODERATE'
                    else:
                        alignment_result['coverage_assessment'] = 'POOR'
                else:
                    # ì—°ê°„ ì¡°ì‚¬ì˜ ê²½ìš°
                    start_year = survey_info.get('start_year', 2014)
                    expected_span = 2025 - start_year + 1
                    actual_span = len(found_years)
                    if actual_span >= expected_span * 0.7:
                        alignment_result['coverage_assessment'] = 'GOOD'
                    elif actual_span >= expected_span * 0.4:
                        alignment_result['coverage_assessment'] = 'MODERATE'
                    else:
                        alignment_result['coverage_assessment'] = 'POOR'
            
            alignment_check['survey_alignment'][survey_name] = alignment_result
        
        return alignment_check

    def generate_timeline_validation_report(self) -> str:
        """ì‹œê³„ì—´ ê²€ì¦ ë³´ê³ ì„œ ìƒì„±"""
        print("ğŸ“‹ ì‹œê³„ì—´ ê²€ì¦ ë³´ê³ ì„œ ìƒì„±...")
        
        try:
            # 1. ë°ì´í„° ì‹œê³„ì—´ ì»¤ë²„ë¦¬ì§€ ë¶„ì„
            timeline_analysis = self.analyze_data_timeline_coverage()
            
            # 2. 2014ë…„ ì‹œì‘ì‹œì  ê²€ì¦
            start_verification = self.verify_2014_start_point(timeline_analysis)
            
            # 3. í†µê³„ì¡°ì‚¬ ì£¼ê¸° ì •ë ¬ í™•ì¸
            survey_alignment = self.check_statistical_survey_alignment(timeline_analysis)
            
            # ì¢…í•© ë³´ê³ ì„œ
            comprehensive_report = {
                'metadata': {
                    'title': 'í†µê³„ìë£Œ ì‹œê³„ì—´ ê²€ì¦ ë³´ê³ ì„œ',
                    'created_at': datetime.now().isoformat(),
                    'version': '1.0',
                    'purpose': '2014ë…„ ì‹œì‘ì‹œì  í™•ì¸ ë° ì‹œê³„ì—´ ì—°ì†ì„± ê²€ì¦',
                    'validation_scope': 'ì „ì²´ ìˆ˜ì§‘ í†µê³„ ë°ì´í„°'
                },
                
                'timeline_verification_summary': {
                    'files_analyzed': timeline_analysis['files_analyzed'],
                    'files_with_timeline': timeline_analysis['files_with_timeline'],
                    'earliest_year_found': timeline_analysis['earliest_year'],
                    'latest_year_found': timeline_analysis['latest_year'],
                    'is_2014_start_confirmed': start_verification['is_2014_start_confirmed'],
                    'start_point_assessment': start_verification['start_point_assessment'],
                    'timeline_completeness': timeline_analysis['timeline_completeness']
                },
                
                'detailed_timeline_analysis': timeline_analysis,
                'start_point_verification': start_verification,
                'statistical_survey_alignment': survey_alignment,
                
                'key_findings': {
                    'temporal_coverage_assessment': self._assess_temporal_coverage(timeline_analysis),
                    'data_continuity_status': self._assess_data_continuity(timeline_analysis),
                    'statistical_alignment_status': self._assess_survey_alignment(survey_alignment),
                    'recommendations': self._generate_timeline_recommendations(timeline_analysis, start_verification)
                },
                
                'election_data_context': {
                    'election_timeline': self.election_timeline,
                    'statistical_cycles': self.statistical_cycles,
                    'data_election_alignment': self._analyze_election_data_alignment(timeline_analysis)
                }
            }
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'data_timeline_validation_report_{timestamp}.json'
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(comprehensive_report, f, ensure_ascii=False, indent=2)
            
            print(f'âœ… ì‹œê³„ì—´ ê²€ì¦ ë³´ê³ ì„œ ì €ì¥: {filename}')
            return filename
            
        except Exception as e:
            print(f'âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}')
            return ''

    def _assess_temporal_coverage(self, timeline_analysis: Dict) -> str:
        """ì‹œê°„ì  ì»¤ë²„ë¦¬ì§€ í‰ê°€"""
        completeness = timeline_analysis['timeline_completeness']
        
        if completeness >= 0.9:
            return 'EXCELLENT'
        elif completeness >= 0.7:
            return 'GOOD'
        elif completeness >= 0.5:
            return 'MODERATE'
        else:
            return 'POOR'

    def _assess_data_continuity(self, timeline_analysis: Dict) -> str:
        """ë°ì´í„° ì—°ì†ì„± í‰ê°€"""
        year_coverage = timeline_analysis['year_coverage']
        
        # ì—°ì†ì„± í™•ì¸ (2014-2025)
        consecutive_years = 0
        max_consecutive = 0
        
        for year in range(2014, 2026):
            if year_coverage.get(str(year), 0) > 0:
                consecutive_years += 1
                max_consecutive = max(max_consecutive, consecutive_years)
            else:
                consecutive_years = 0
        
        continuity_ratio = max_consecutive / 12  # 2014-2025 = 12ë…„
        
        if continuity_ratio >= 0.9:
            return 'EXCELLENT'
        elif continuity_ratio >= 0.7:
            return 'GOOD'
        elif continuity_ratio >= 0.5:
            return 'MODERATE'
        else:
            return 'POOR'

    def _assess_survey_alignment(self, survey_alignment: Dict) -> str:
        """í†µê³„ì¡°ì‚¬ ì •ë ¬ í‰ê°€"""
        good_alignments = 0
        total_surveys = len(survey_alignment['survey_alignment'])
        
        for survey_name, result in survey_alignment['survey_alignment'].items():
            if result['coverage_assessment'] in ['GOOD', 'MODERATE']:
                good_alignments += 1
        
        alignment_ratio = good_alignments / total_surveys if total_surveys > 0 else 0
        
        if alignment_ratio >= 0.8:
            return 'EXCELLENT'
        elif alignment_ratio >= 0.6:
            return 'GOOD'
        elif alignment_ratio >= 0.4:
            return 'MODERATE'
        else:
            return 'POOR'

    def _generate_timeline_recommendations(self, timeline_analysis: Dict, start_verification: Dict) -> List[str]:
        """ì‹œê³„ì—´ ê´€ë ¨ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # 2014ë…„ ì‹œì‘ì‹œì  ê´€ë ¨
        if not start_verification['is_2014_start_confirmed']:
            if start_verification['actual_earliest_year'] and start_verification['actual_earliest_year'] > 2014:
                recommendations.append(f"2014ë…„ ë°ì´í„° ë³´ì™„ í•„ìš” (í˜„ì¬ ìµœì´ˆ: {start_verification['actual_earliest_year']}ë…„)")
            elif start_verification['actual_earliest_year'] and start_verification['actual_earliest_year'] < 2014:
                recommendations.append(f"ì‹œì‘ì‹œì  ì¬ì •ì˜ ê³ ë ¤ (ì‹¤ì œ ìµœì´ˆ: {start_verification['actual_earliest_year']}ë…„)")
        
        # ì‹œê³„ì—´ ì™„ì„±ë„ ê´€ë ¨
        if timeline_analysis['timeline_completeness'] < 0.8:
            missing_years = [year for year in range(2014, 2026) 
                           if timeline_analysis['year_coverage'].get(str(year), 0) == 0]
            if missing_years:
                recommendations.append(f"ëˆ„ë½ ì—°ë„ ë°ì´í„° ë³´ì™„: {missing_years}")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì‹œê³„ì—´ ê°­
        for category, data in timeline_analysis['data_categories'].items():
            if data['year_span'] < 8:  # 12ë…„ ì¤‘ 8ë…„ ë¯¸ë§Œ
                recommendations.append(f"{category} ì¹´í…Œê³ ë¦¬ ì‹œê³„ì—´ í™•ì¥ í•„ìš”")
        
        return recommendations

    def _analyze_election_data_alignment(self, timeline_analysis: Dict) -> Dict:
        """ì„ ê±° ë°ì´í„°ì™€ í†µê³„ ë°ì´í„° ì •ë ¬ ë¶„ì„"""
        alignment_analysis = {
            'election_years_in_data': [],
            'statistical_years_coverage': {},
            'alignment_quality': 'UNKNOWN'
        }
        
        # ì„ ê±° ì—°ë„ë“¤ì´ ë°ì´í„°ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        election_years = [2014, 2016, 2018, 2020, 2022]
        
        for year in election_years:
            year_str = str(year)
            if timeline_analysis['year_coverage'].get(year_str, 0) > 0:
                alignment_analysis['election_years_in_data'].append(year)
        
        # í†µê³„ ì—°ë„ë³„ ì»¤ë²„ë¦¬ì§€
        for year_str, count in timeline_analysis['year_coverage'].items():
            year = int(year_str)
            if 2014 <= year <= 2025:
                alignment_analysis['statistical_years_coverage'][year] = {
                    'data_sources': count,
                    'is_election_year': year in election_years,
                    'coverage_quality': 'HIGH' if count >= 5 else 'MODERATE' if count >= 2 else 'LOW'
                }
        
        # ì •ë ¬ í’ˆì§ˆ í‰ê°€
        election_coverage_ratio = len(alignment_analysis['election_years_in_data']) / len(election_years)
        
        if election_coverage_ratio >= 0.8:
            alignment_analysis['alignment_quality'] = 'EXCELLENT'
        elif election_coverage_ratio >= 0.6:
            alignment_analysis['alignment_quality'] = 'GOOD'
        elif election_coverage_ratio >= 0.4:
            alignment_analysis['alignment_quality'] = 'MODERATE'
        else:
            alignment_analysis['alignment_quality'] = 'POOR'
        
        return alignment_analysis

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    validator = DataTimelineValidator()
    
    print('ğŸ“Šâ° í†µê³„ìë£Œ ì‹œê³„ì—´ ê²€ì¦ê¸°')
    print('=' * 50)
    print('ğŸ¯ ëª©ì : 2014ë…„ ì‹œì‘ì‹œì  í™•ì¸')
    print('ğŸ“… ë²”ìœ„: 2014-2025ë…„ ì‹œê³„ì—´')
    print('ğŸ” ëŒ€ìƒ: ì „ì²´ ìˆ˜ì§‘ í†µê³„ ë°ì´í„°')
    print('=' * 50)
    
    try:
        print('\nğŸš€ ì‹œê³„ì—´ ê²€ì¦ ì‹¤í–‰...')
        
        # ì‹œê³„ì—´ ê²€ì¦ ë³´ê³ ì„œ ìƒì„±
        report_file = validator.generate_timeline_validation_report()
        
        if report_file:
            print(f'\nğŸ‰ ì‹œê³„ì—´ ê²€ì¦ ì™„ë£Œ!')
            print(f'ğŸ“„ ë³´ê³ ì„œ: {report_file}')
            
            # ë³´ê³ ì„œ ìš”ì•½ ì¶œë ¥
            with open(report_file, 'r', encoding='utf-8') as f:
                report = json.load(f)
            
            summary = report['timeline_verification_summary']
            findings = report['key_findings']
            
            print(f'\nğŸ† ì‹œê³„ì—´ ê²€ì¦ ê²°ê³¼:')
            print(f'  ğŸ“Š ë¶„ì„ íŒŒì¼: {summary["files_analyzed"]}ê°œ')
            print(f'  â° ì‹œê³„ì—´ íŒŒì¼: {summary["files_with_timeline"]}ê°œ')
            print(f'  ğŸ“… ìµœì´ˆ ì—°ë„: {summary["earliest_year_found"]}ë…„')
            print(f'  ğŸ“… ìµœì‹  ì—°ë„: {summary["latest_year_found"]}ë…„')
            print(f'  ğŸ¯ 2014ë…„ ì‹œì‘: {summary["is_2014_start_confirmed"]}')
            print(f'  ğŸ“Š ì‹œê³„ì—´ ì™„ì„±ë„: {summary["timeline_completeness"]:.1%}')
            
            start_verification = report['start_point_verification']
            print(f'\nğŸ“… 2014ë…„ ì‹œì‘ì‹œì  ê²€ì¦:')
            print(f'  ğŸ¯ í™•ì¸ ìƒíƒœ: {start_verification["start_point_assessment"]}')
            print(f'  ğŸ“Š 2014ë…„ ë°ì´í„°: {start_verification["year_2014_coverage"]}ê°œ íŒŒì¼')
            print(f'  âœ… 2014ë…„ í¬í•¨ ì¹´í…Œê³ ë¦¬: {len(start_verification["categories_with_2014"])}ê°œ')
            print(f'  âŒ 2014ë…„ ëˆ„ë½ ì¹´í…Œê³ ë¦¬: {len(start_verification["categories_without_2014"])}ê°œ')
            
            if start_verification['categories_with_2014']:
                print(f'\nâœ… 2014ë…„ í¬í•¨ ì¹´í…Œê³ ë¦¬:')
                for cat in start_verification['categories_with_2014'][:3]:
                    print(f'  ğŸ“Š {cat["category"]}: {cat["files"]}ê°œ íŒŒì¼, {cat["year_span"]}ë…„ ìŠ¤íŒ¬')
            
            if start_verification['categories_without_2014']:
                print(f'\nâŒ 2014ë…„ ëˆ„ë½ ì¹´í…Œê³ ë¦¬:')
                for cat in start_verification['categories_without_2014'][:3]:
                    earliest = cat["earliest"] if cat["earliest"] else "N/A"
                    print(f'  ğŸ“Š {cat["category"]}: ìµœì´ˆ {earliest}ë…„')
            
            # ê¶Œì¥ì‚¬í•­
            recommendations = findings.get('recommendations', [])
            if recommendations:
                print(f'\nğŸ’¡ ê¶Œì¥ì‚¬í•­:')
                for rec in recommendations[:3]:
                    print(f'  ğŸ¯ {rec}')
            
        else:
            print('\nâŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨')
            
    except Exception as e:
        print(f'\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}')

if __name__ == '__main__':
    main()
