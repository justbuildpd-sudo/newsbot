#!/usr/bin/env python3
"""
ë„¤ì´ë²„ ë‰´ìŠ¤ API + ë°ì´í„°ë© ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ API í†µí•© ì„œë¹„ìŠ¤
"""

import requests
import json
import time
import re
from datetime import datetime, timedelta
from urllib.parse import quote
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class IntegratedNaverService:
    def __init__(self):
        # ë„¤ì´ë²„ ê°œë°œì API ì •ë³´
        self.client_id = "kXwlSsFmb055ku9rWyx1"
        self.client_secret = "JZqw_LTiq_"
        
        # API ì—”ë“œí¬ì¸íŠ¸
        self.news_api_url = "https://openapi.naver.com/v1/search/news.json"
        self.datalab_api_url = "https://openapi.naver.com/v1/datalab/search"
        
        # ê³µí†µ í—¤ë”
        self.common_headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret,
            "User-Agent": "NewsBot/1.0"
        }
        
        # ë°ì´í„°ë© ì „ìš© í—¤ë”
        self.datalab_headers = {
            **self.common_headers,
            "Content-Type": "application/json"
        }
        
        # ì •ì¹˜ì¸ ëª©ë¡ ë¡œë“œ
        self.load_politicians()
        
        # API ì‚¬ìš©ëŸ‰ ì¶”ì 
        self.news_requests = 0
        self.datalab_requests = 0
        
    def load_politicians(self):
        """22ëŒ€ êµ­íšŒì˜ì› ëª©ë¡ ë¡œë“œ"""
        try:
            with open('22nd_assembly_members_300.json', 'r', encoding='utf-8') as f:
                members = json.load(f)
            self.politicians = [member.get('naas_nm', '') for member in members if member.get('naas_nm')]
            self.politicians_info = {member.get('naas_nm', ''): member for member in members if member.get('naas_nm')}
            logger.info(f"ì •ì¹˜ì¸ ëª©ë¡ ë¡œë“œ ì™„ë£Œ: {len(self.politicians)}ëª…")
        except FileNotFoundError:
            try:
                with open('../22nd_assembly_members_300.json', 'r', encoding='utf-8') as f:
                    members = json.load(f)
                self.politicians = [member.get('naas_nm', '') for member in members if member.get('naas_nm')]
                self.politicians_info = {member.get('naas_nm', ''): member for member in members if member.get('naas_nm')}
                logger.info(f"ì •ì¹˜ì¸ ëª©ë¡ ë¡œë“œ ì™„ë£Œ: {len(self.politicians)}ëª…")
            except FileNotFoundError:
                self.politicians = ["ì´ì¬ëª…", "í•œë™í›ˆ", "ì¡°êµ­", "ì •ì²­ë˜", "ê¹€ê¸°í˜„"]
                self.politicians_info = {}
                logger.warning("ì •ì¹˜ì¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ëª©ë¡ ì‚¬ìš©")
    
    def search_news(self, query, display=10, sort="sim"):
        """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰"""
        try:
            params = {
                "query": query,
                "display": display,
                "start": 1,
                "sort": sort
            }
            
            response = requests.get(
                self.news_api_url,
                headers=self.common_headers,
                params=params,
                timeout=10
            )
            
            self.news_requests += 1
            
            if response.status_code == 200:
                data = response.json()
                logger.info(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì„±ê³µ: '{query}' - {len(data.get('items', []))}ê±´")
                return data
            else:
                logger.error(f"ë‰´ìŠ¤ API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return None
        
        finally:
            time.sleep(0.1)  # API í˜¸ì¶œ ê°„ê²©
    
    def get_search_trend(self, keywords, start_date, end_date, time_unit="date"):
        """
        ë„¤ì´ë²„ ë°ì´í„°ë© ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ ì¡°íšŒ
        
        POST /v1/datalab/search
        HOST: openapi.naver.com
        Content-Type: application/json
        X-Naver-Client-Id: kXwlSsFmb055ku9rWyx1
        X-Naver-Client-Secret: JZqw_LTiq_
        """
        try:
            # ìš”ì²­ ë°”ë”” êµ¬ì„± (ì •í™•í•œ API ìŠ¤í™ì— ë”°ë¼)
            request_body = {
                "startDate": start_date,
                "endDate": end_date,
                "timeUnit": time_unit,  # date, week, month
                "keywordGroups": []
            }
            
            # í‚¤ì›Œë“œ ê·¸ë£¹ ìƒì„± (ìµœëŒ€ 5ê°œê¹Œì§€)
            for keyword in keywords[:5]:
                request_body["keywordGroups"].append({
                    "groupName": keyword,
                    "keywords": [keyword]
                })
            
            logger.info(f"ë°ì´í„°ë© API ìš”ì²­: {len(keywords)}ê°œ í‚¤ì›Œë“œ, {start_date}~{end_date}")
            
            response = requests.post(
                self.datalab_api_url,
                headers=self.datalab_headers,
                data=json.dumps(request_body, ensure_ascii=False).encode('utf-8'),
                timeout=15
            )
            
            self.datalab_requests += 1
            
            if response.status_code == 200:
                data = response.json()
                logger.info(f"ë°ì´í„°ë© API ì„±ê³µ: {len(data.get('results', []))}ê°œ ê²°ê³¼")
                return data
            else:
                logger.error(f"ë°ì´í„°ë© API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"ë°ì´í„°ë© API ìš”ì²­ ì˜¤ë¥˜: {e}")
            return None
        
        finally:
            time.sleep(0.2)  # API í˜¸ì¶œ ê°„ê²©
    
    def collect_politician_data(self, politician_name, days=30, max_news=10):
        """ì •ì¹˜ì¸ë³„ ë‰´ìŠ¤ + íŠ¸ë Œë“œ í†µí•© ìˆ˜ì§‘"""
        try:
            logger.info(f"ğŸ” {politician_name} í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            
            # 1. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            news_data = self.collect_politician_news(politician_name, max_news)
            
            # 2. ê²€ìƒ‰ íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘
            trend_data = self.collect_politician_trend(politician_name, days)
            
            # 3. í†µí•© ë°ì´í„° êµ¬ì„±
            integrated_data = {
                'politician': politician_name,
                'party': self.politicians_info.get(politician_name, {}).get('party_name', 'ë¬´ì†Œì†'),
                'collected_at': datetime.now().isoformat(),
                'news': news_data,
                'trend': trend_data,
                'summary': self.create_summary(news_data, trend_data)
            }
            
            logger.info(f"âœ… {politician_name} í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
            return integrated_data
            
        except Exception as e:
            logger.error(f"{politician_name} í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return None
    
    def collect_politician_news(self, politician_name, max_results=10):
        """ì •ì¹˜ì¸ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        try:
            # ìµœì í™”ëœ ê²€ìƒ‰ì–´ë“¤
            queries = [
                f'{politician_name} ì˜ì›',
                f'{politician_name} êµ­íšŒ',
                f'{politician_name} ì •ì¹˜'
            ]
            
            all_news = []
            seen_titles = set()
            
            for query in queries:
                if len(all_news) >= max_results:
                    break
                
                news_result = self.search_news(query, display=min(10, max_results))
                if not news_result:
                    continue
                
                for item in news_result.get('items', []):
                    title = self.clean_html(item.get('title', ''))
                    
                    # ì¤‘ë³µ ì œê±°
                    if title in seen_titles:
                        continue
                    
                    # ì •ì¹˜ ê´€ë ¨ì„± ì²´í¬
                    if not self.is_political_news(title, item.get('description', '')):
                        continue
                    
                    seen_titles.add(title)
                    
                    news_item = {
                        'title': title,
                        'description': self.clean_html(item.get('description', '')),
                        'link': item.get('link', ''),
                        'pub_date': item.get('pubDate', ''),
                        'sentiment': self.analyze_sentiment(title + ' ' + item.get('description', ''))
                    }
                    
                    all_news.append(news_item)
                    
                    if len(all_news) >= max_results:
                        break
            
            logger.info(f"{politician_name} ë‰´ìŠ¤ ìˆ˜ì§‘: {len(all_news)}ê±´")
            return all_news
            
        except Exception as e:
            logger.error(f"{politician_name} ë‰´ìŠ¤ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return []
    
    def collect_politician_trend(self, politician_name, days=30):
        """ì •ì¹˜ì¸ ê²€ìƒ‰ íŠ¸ë Œë“œ ìˆ˜ì§‘"""
        try:
            # ë‚ ì§œ ë²”ìœ„ ì„¤ì •
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            start_date_str = start_date.strftime("%Y-%m-%d")
            end_date_str = end_date.strftime("%Y-%m-%d")
            
            # ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ ì¡°íšŒ
            trend_result = self.get_search_trend(
                [politician_name],
                start_date_str,
                end_date_str,
                time_unit="date"
            )
            
            if trend_result and trend_result.get('results'):
                result = trend_result['results'][0]
                trend_points = result.get('data', [])
                
                # í†µê³„ ê³„ì‚°
                if trend_points:
                    values = [point.get('ratio', 0) for point in trend_points]
                    stats = {
                        'average': sum(values) / len(values),
                        'max': max(values),
                        'min': min(values),
                        'total_points': len(values),
                        'trend_direction': self.calculate_trend_direction(values)
                    }
                else:
                    stats = {'average': 0, 'max': 0, 'min': 0, 'total_points': 0, 'trend_direction': 'stable'}
                
                trend_data = {
                    'period': {'start': start_date_str, 'end': end_date_str},
                    'data_points': trend_points,
                    'statistics': stats
                }
                
                logger.info(f"{politician_name} íŠ¸ë Œë“œ ìˆ˜ì§‘: {len(trend_points)}ì¼, í‰ê·  {stats['average']:.2f}")
                return trend_data
            else:
                logger.warning(f"{politician_name} íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ")
                return None
                
        except Exception as e:
            logger.error(f"{politician_name} íŠ¸ë Œë“œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return None
    
    def collect_multiple_politicians_comparison(self, politicians, days=30):
        """ì—¬ëŸ¬ ì •ì¹˜ì¸ ê²€ìƒ‰ëŸ‰ ë¹„êµ"""
        try:
            # ìµœëŒ€ 5ëª…ê¹Œì§€ ë¹„êµ (API ì œí•œ)
            compare_list = politicians[:5]
            
            # ë‚ ì§œ ë²”ìœ„ ì„¤ì •
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            start_date_str = start_date.strftime("%Y-%m-%d")
            end_date_str = end_date.strftime("%Y-%m-%d")
            
            # ë¹„êµ íŠ¸ë Œë“œ ì¡°íšŒ
            comparison_result = self.get_search_trend(
                compare_list,
                start_date_str,
                end_date_str,
                time_unit="date"
            )
            
            if comparison_result and comparison_result.get('results'):
                processed_comparison = {
                    'period': {'start': start_date_str, 'end': end_date_str},
                    'politicians': [],
                    'chart_data': self.create_chart_data(comparison_result),
                    'ranking': []
                }
                
                # ê° ì •ì¹˜ì¸ë³„ ë°ì´í„° ì²˜ë¦¬
                for result in comparison_result['results']:
                    politician = result.get('title')
                    trend_points = result.get('data', [])
                    
                    if trend_points:
                        values = [point.get('ratio', 0) for point in trend_points]
                        avg_search = sum(values) / len(values)
                        
                        politician_data = {
                            'politician': politician,
                            'party': self.politicians_info.get(politician, {}).get('party_name', 'ë¬´ì†Œì†'),
                            'average_search': round(avg_search, 2),
                            'max_search': max(values),
                            'trend_direction': self.calculate_trend_direction(values),
                            'data_points': trend_points
                        }
                        
                        processed_comparison['politicians'].append(politician_data)
                
                # ê²€ìƒ‰ëŸ‰ ê¸°ì¤€ ë­í‚¹
                processed_comparison['ranking'] = sorted(
                    processed_comparison['politicians'],
                    key=lambda x: x['average_search'],
                    reverse=True
                )
                
                # ìˆœìœ„ ë¶€ì—¬
                for i, item in enumerate(processed_comparison['ranking']):
                    item['rank'] = i + 1
                
                logger.info(f"ì •ì¹˜ì¸ ë¹„êµ íŠ¸ë Œë“œ ìˆ˜ì§‘: {len(compare_list)}ëª…")
                return processed_comparison
            else:
                logger.warning("ë¹„êµ íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ")
                return None
                
        except Exception as e:
            logger.error(f"ì •ì¹˜ì¸ ë¹„êµ íŠ¸ë Œë“œ ì˜¤ë¥˜: {e}")
            return None
    
    def calculate_trend_direction(self, values):
        """íŠ¸ë Œë“œ ë°©í–¥ ê³„ì‚°"""
        if len(values) < 2:
            return 'stable'
        
        # ìµœê·¼ 3ì¼ê³¼ ì´ì „ 3ì¼ ë¹„êµ
        recent_avg = sum(values[-3:]) / min(3, len(values[-3:]))
        previous_avg = sum(values[-6:-3]) / min(3, len(values[-6:-3])) if len(values) >= 6 else recent_avg
        
        if recent_avg > previous_avg * 1.2:
            return 'rising'
        elif recent_avg < previous_avg * 0.8:
            return 'falling'
        else:
            return 'stable'
    
    def create_chart_data(self, datalab_result):
        """ì°¨íŠ¸ ë°ì´í„° ìƒì„± (Chart.js í˜•ì‹)"""
        try:
            results = datalab_result.get('results', [])
            if not results:
                return None
            
            # ë‚ ì§œ ë¼ë²¨ ìƒì„± (ì²« ë²ˆì§¸ ê²°ê³¼ì˜ ë‚ ì§œ ì‚¬ìš©)
            first_result = results[0]
            dates = [point.get('period') for point in first_result.get('data', [])]
            
            # ë°ì´í„°ì…‹ ìƒì„±
            datasets = []
            colors = ['#3B82F6', '#EF4444', '#8B5CF6', '#10B981', '#F59E0B']
            
            for i, result in enumerate(results):
                politician = result.get('title')
                values = [point.get('ratio', 0) for point in result.get('data', [])]
                
                dataset = {
                    'label': politician,
                    'data': values,
                    'borderColor': colors[i % len(colors)],
                    'backgroundColor': colors[i % len(colors)] + '20',
                    'tension': 0.4,
                    'fill': False
                }
                
                datasets.append(dataset)
            
            chart_data = {
                'labels': dates,
                'datasets': datasets
            }
            
            return chart_data
            
        except Exception as e:
            logger.error(f"ì°¨íŠ¸ ë°ì´í„° ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    
    def create_summary(self, news_data, trend_data):
        """ë‰´ìŠ¤ + íŠ¸ë Œë“œ í†µí•© ìš”ì•½"""
        summary = {
            'news_count': len(news_data) if news_data else 0,
            'trend_available': trend_data is not None,
            'sentiment_distribution': {'positive': 0, 'negative': 0, 'neutral': 0}
        }
        
        # ë‰´ìŠ¤ ê°ì • ë¶„ì„
        if news_data:
            for news in news_data:
                sentiment = news.get('sentiment', 'neutral')
                summary['sentiment_distribution'][sentiment] += 1
        
        # íŠ¸ë Œë“œ ì •ë³´
        if trend_data and trend_data.get('statistics'):
            stats = trend_data['statistics']
            summary.update({
                'average_search': stats.get('average', 0),
                'search_trend': stats.get('trend_direction', 'stable'),
                'peak_search': stats.get('max', 0)
            })
        
        return summary
    
    def is_political_news(self, title, description):
        """ì •ì¹˜ ê´€ë ¨ ë‰´ìŠ¤ íŒë‹¨"""
        political_keywords = [
            'ì˜ì›', 'êµ­íšŒ', 'ì •ì¹˜', 'ì •ë¶€', 'ì •ë‹¹', 'ë²•ì•ˆ', 'ë°œì˜', 'ìœ„ì›íšŒ',
            'ì„ ê±°', 'ì •ì±…', 'êµ­ì •ê°ì‚¬', 'ë³¸íšŒì˜', 'ë¯¼ì£¼ë‹¹', 'êµ­ë¯¼ì˜í˜', 'ì¡°êµ­í˜ì‹ ë‹¹',
            'ëŒ€í†µë ¹', 'ì´ë¦¬', 'ì¥ê´€', 'ì—¬ë‹¹', 'ì•¼ë‹¹', 'ì›ë‚´ëŒ€í‘œ'
        ]
        
        # ê°•í•œ ì œì™¸ í‚¤ì›Œë“œ
        exclude_keywords = ['ì˜í™”', 'ë“œë¼ë§ˆ', 'ì˜ˆëŠ¥', 'ë°°ìš°', 'ê°€ìˆ˜', 'ì—°ì˜ˆì¸']
        
        text = title + ' ' + description
        
        # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
        if any(keyword in text for keyword in exclude_keywords):
            return False
        
        # ì •ì¹˜ í‚¤ì›Œë“œ ì²´í¬
        return any(keyword in text for keyword in political_keywords)
    
    def analyze_sentiment(self, text):
        """ê°ì • ë¶„ì„"""
        positive_words = [
            'ì„±ê³µ', 'ë°œì „', 'ê°œì„ ', 'ê¸ì •', 'ì¢‹ì€', 'í›Œë¥­', 'ì„±ê³¼', 
            'ì§€ì§€', 'ì°¬ì„±', 'í˜‘ë ¥', 'í•©ì˜', 'í†µê³¼', 'ìŠ¹ì¸', 'ì¶”ì§„'
        ]
        
        negative_words = [
            'ì‹¤íŒ¨', 'ë¬¸ì œ', 'ë¹„íŒ', 'ë°˜ëŒ€', 'ê°ˆë“±', 'ë…¼ë€', 'ìš°ë ¤', 'ìœ„ê¸°',
            'ë¶€ì •', 'ê±°ë¶€', 'ë°˜ë°œ', 'ì¶©ëŒ', 'íê¸°', 'ì¤‘ë‹¨', 'ì·¨ì†Œ', 'êµ¬ì†'
        ]
        
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)
        
        if positive_count > negative_count:
            return 'positive'
        elif negative_count > positive_count:
            return 'negative'
        else:
            return 'neutral'
    
    def clean_html(self, text):
        """HTML íƒœê·¸ ì œê±°"""
        clean = re.sub('<.*?>', '', text)
        clean = clean.replace('&lt;', '<').replace('&gt;', '>')
        clean = clean.replace('&amp;', '&').replace('&quot;', '"')
        clean = clean.replace('&#39;', "'").replace('&nbsp;', ' ')
        return clean.strip()
    
    def get_api_usage(self):
        """API ì‚¬ìš©ëŸ‰ í˜„í™©"""
        return {
            'news_requests': self.news_requests,
            'datalab_requests': self.datalab_requests,
            'total_requests': self.news_requests + self.datalab_requests,
            'news_limit': 25000,  # ì¼ì¼ í•œë„
            'datalab_limit': 1000   # ì¼ì¼ í•œë„ (ì¶”ì •)
        }
    
    def save_integrated_data(self, data, filename=None):
        """í†µí•© ë°ì´í„° ì €ì¥"""
        if filename is None:
            filename = f"integrated_naver_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"í†µí•© ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"í†µí•© ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {e}")
            return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    service = IntegratedNaverService()
    
    print("ğŸŒ ë„¤ì´ë²„ ë‰´ìŠ¤ + ë°ì´í„°ë© í†µí•© ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")
    print(f"ğŸ“Š ì •ì¹˜ì¸ ìˆ˜: {len(service.politicians)}ëª…")
    
    # ì£¼ìš” ì •ì¹˜ì¸ í†µí•© ë°ì´í„° ìˆ˜ì§‘
    major_politicians = ["ì´ì¬ëª…", "í•œë™í›ˆ", "ì¡°êµ­"]
    all_integrated_data = {}
    
    for politician in major_politicians:
        print(f"\n{'='*50}")
        print(f"ğŸ” {politician} í†µí•© ë°ì´í„° ìˆ˜ì§‘")
        print('='*50)
        
        integrated_data = service.collect_politician_data(politician, days=30, max_news=5)
        
        if integrated_data:
            all_integrated_data[politician] = integrated_data
            
            # ê²°ê³¼ ì¶œë ¥
            summary = integrated_data['summary']
            print(f"âœ… ë‰´ìŠ¤: {summary['news_count']}ê±´")
            print(f"âœ… íŠ¸ë Œë“œ: {'ìˆìŒ' if summary['trend_available'] else 'ì—†ìŒ'}")
            
            if summary['trend_available']:
                print(f"ğŸ“ˆ í‰ê·  ê²€ìƒ‰ëŸ‰: {summary.get('average_search', 0):.2f}")
                print(f"ğŸ“Š íŠ¸ë Œë“œ: {summary.get('search_trend', 'stable')}")
            
            print(f"ğŸ˜Š ê°ì • ë¶„ì„: ê¸ì • {summary['sentiment_distribution']['positive']}ê±´, "
                  f"ë¶€ì • {summary['sentiment_distribution']['negative']}ê±´, "
                  f"ì¤‘ë¦½ {summary['sentiment_distribution']['neutral']}ê±´")
        else:
            print(f"âŒ {politician} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
    
    # ì •ì¹˜ì¸ ë¹„êµ íŠ¸ë Œë“œ
    print(f"\n{'='*50}")
    print("ğŸ“Š ì •ì¹˜ì¸ ê²€ìƒ‰ëŸ‰ ë¹„êµ íŠ¸ë Œë“œ")
    print('='*50)
    
    comparison_data = service.collect_multiple_politicians_comparison(major_politicians, days=30)
    if comparison_data:
        print("âœ… ë¹„êµ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì„±ê³µ")
        
        print("\nğŸ† ê²€ìƒ‰ëŸ‰ ë­í‚¹:")
        for item in comparison_data['ranking']:
            print(f"  {item['rank']}. {item['politician']} ({item['party']})")
            print(f"     í‰ê·  ê²€ìƒ‰ëŸ‰: {item['average_search']:.2f}")
            print(f"     íŠ¸ë Œë“œ: {item['trend_direction']}")
        
        all_integrated_data['comparison'] = comparison_data
    else:
        print("âŒ ë¹„êµ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì‹¤íŒ¨")
    
    # ìµœì¢… ë°ì´í„° ì €ì¥
    if all_integrated_data:
        filename = service.save_integrated_data(all_integrated_data, 'naver_integrated_data.json')
        if filename:
            print(f"\nğŸ’¾ í†µí•© ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filename}")
    
    # API ì‚¬ìš©ëŸ‰ ì¶œë ¥
    usage = service.get_api_usage()
    print(f"\nğŸ“Š API ì‚¬ìš©ëŸ‰:")
    print(f"  ë‰´ìŠ¤ API: {usage['news_requests']}íšŒ")
    print(f"  ë°ì´í„°ë© API: {usage['datalab_requests']}íšŒ")
    print(f"  ì´ ìš”ì²­: {usage['total_requests']}íšŒ")

if __name__ == "__main__":
    main()

