#!/usr/bin/env python3
"""
ê°œë³„ ì§€ìì²´ë³„ ìƒì„¸ í† í”½ ë° ê³µì•½ ë¶„ì„ê¸°
ì •ì±…ì„ ê±°ë¬¸í™” ë¬¸ì„œì—ì„œ ì‹œêµ°êµ¬, ìë©´ë™ ë‹¨ìœ„ê¹Œì§€ ì„¸ë°€í•˜ê²Œ ë¶„ì„
"""

import os
import json
import re
import logging
from datetime import datetime
from collections import Counter, defaultdict
from typing import Dict, List, Tuple, Any
import fitz

logger = logging.getLogger(__name__)

class DetailedLocalGovernmentAnalyzer:
    """ê°œë³„ ì§€ìì²´ë³„ ìƒì„¸ ë¶„ì„ê¸°"""
    
    def __init__(self, pdf_file_path: str):
        self.pdf_file = pdf_file_path
        self.analysis_results = {}
        
        # ëª¨ë“  ì§€ìì²´ ë§¤í•‘ (ê´‘ì—­ì‹œë„ â†’ ì‹œêµ°êµ¬ â†’ ìë©´ë™)
        self.local_government_structure = self._load_local_government_structure()
        
        # ì •ì±… ê³µì•½ íŒ¨í„´
        self.policy_promise_patterns = [
            # ê±´ì„¤/ê°œë°œ ê´€ë ¨
            r'([ê°€-í£]+ê±´ì„¤|[ê°€-í£]+ê°œë°œ|[ê°€-í£]+ì¡°ì„±|[ê°€-í£]+êµ¬ì¶•|[ê°€-í£]+ì„¤ì¹˜)',
            r'([ê°€-í£]+ì„\s*ìœ„í•œ\s*[ê°€-í£]+)',
            r'([ê°€-í£]+ë¥¼\s*ìœ„í•œ\s*[ê°€-í£]+)',
            r'([ê°€-í£]+ì„\s*í†µí•œ\s*[ê°€-í£]+)',
            r'([ê°€-í£]+ë¥¼\s*í†µí•œ\s*[ê°€-í£]+)',
            # ì§€ì›/í˜œíƒ ê´€ë ¨
            r'([ê°€-í£]+ì§€ì›|[ê°€-í£]+í˜œíƒ|[ê°€-í£]+ë³´ì¡°|[ê°€-í£]+í• ì¸)',
            r'([ê°€-í£]+í™•ì¶©|[ê°€-í£]+ê°•í™”|[ê°€-í£]+ê°œì„ |[ê°€-í£]+ì¦ëŒ€)',
            # ì •ì±… ê´€ë ¨
            r'([ê°€-í£]+ì •ì±…|[ê°€-í£]+ì œë„|[ê°€-í£]+ì‚¬ì—…|[ê°€-í£]+í”„ë¡œê·¸ë¨)',
            r'([ê°€-í£]+ì„¼í„°|[ê°€-í£]+ë³µì§€ê´€|[ê°€-í£]+ë¬¸í™”ê´€|[ê°€-í£]+ë„ì„œê´€)',
            # ì¸í”„ë¼ ê´€ë ¨
            r'([ê°€-í£]+ë„ë¡œ|[ê°€-í£]+êµí†µ|[ê°€-í£]+ì§€í•˜ì² |[ê°€-í£]+ë²„ìŠ¤)',
            r'([ê°€-í£]+ê³µì›|[ê°€-í£]+ì²´ìœ¡ê´€|[ê°€-í£]+ë³‘ì›|[ê°€-í£]+í•™êµ)',
        ]
        
        # í† í”½ë³„ í‚¤ì›Œë“œ í™•ì¥
        self.enhanced_topic_keywords = {
            "ê²½ì œì •ì±…": {
                "keywords": ["ì¼ìë¦¬", "ì·¨ì—…", "ì°½ì—…", "ê²½ì œì„±ì¥", "ì†Œë“", "ì„ê¸ˆ", "ê³ ìš©", "ì‹¤ì—…", "ê²½ì œí™œë™", "ì‚¬ì—…", "íˆ¬ì", "ê¸ˆìœµ", "ì¤‘ì†Œê¸°ì—…", "ìŠ¤íƒ€íŠ¸ì—…", "ë²¤ì²˜", "ê²½ì œì§€ì›", "ê²½ì œê°œë°œ", "ì‚°ì—…ìœ¡ì„±", "ìˆ˜ì¶œ", "ìˆ˜ì…", "ë¬´ì—­", "ê²½ì œí˜‘ë ¥", "ê³ ìš©ì°½ì¶œ", "ì¼ìë¦¬ì°½ì¶œ", "ì·¨ì—…ì§€ì›", "ì°½ì—…ì§€ì›", "ê²½ì œì§€ì›", "ì‚°ì—…ì§€ì›", "ê¸°ì—…ì§€ì›", "ë²¤ì²˜ì§€ì›", "ìŠ¤íƒ€íŠ¸ì—…ì§€ì›", "ì¤‘ì†Œê¸°ì—…ì§€ì›"],
                "promise_keywords": ["ì¼ìë¦¬ì°½ì¶œ", "ì·¨ì—…ì§€ì›", "ì°½ì—…ì§€ì›", "ê²½ì œì§€ì›", "ì‚°ì—…ìœ¡ì„±", "ê¸°ì—…ì§€ì›", "ë²¤ì²˜ì§€ì›", "ìŠ¤íƒ€íŠ¸ì—…ì§€ì›"]
            },
            "ì£¼ê±°ì •ì±…": {
                "keywords": ["ì£¼íƒ", "ë¶€ë™ì‚°", "ì„ëŒ€", "ì „ì„¸", "ì›”ì„¸", "ì•„íŒŒíŠ¸", "ì§‘ê°’", "ì£¼ê±°", "ë¶„ì–‘", "ë§¤ë§¤", "ì£¼íƒê³µê¸‰", "ê³µê³µì£¼íƒ", "ì„ëŒ€ì£¼íƒ", "ì²­ë…„ì£¼íƒ", "ì‹ ì¶•", "ì¬ê°œë°œ", "ì¬ê±´ì¶•", "ë„ì‹œê³„íš", "íƒì§€ê°œë°œ", "ì£¼ê±°ë³µì§€", "ì£¼ê±°ì§€ì›", "ì£¼íƒì§€ì›", "ì„ëŒ€ì§€ì›", "ì „ì„¸ì§€ì›", "ì›”ì„¸ì§€ì›", "ê³µê³µì£¼íƒê±´ì„¤", "ì„ëŒ€ì£¼íƒê±´ì„¤", "ì²­ë…„ì£¼íƒê±´ì„¤"],
                "promise_keywords": ["ì£¼íƒê³µê¸‰", "ê³µê³µì£¼íƒê±´ì„¤", "ì„ëŒ€ì£¼íƒê±´ì„¤", "ì²­ë…„ì£¼íƒê±´ì„¤", "ì£¼ê±°ì§€ì›", "ì„ëŒ€ì§€ì›", "ì „ì„¸ì§€ì›"]
            },
            "êµìœ¡ì •ì±…": {
                "keywords": ["êµìœ¡", "í•™êµ", "ëŒ€í•™", "ì…ì‹œ", "ì‚¬êµìœ¡", "êµìœ¡ë¹„", "í•™ìŠµ", "í•™ìƒ", "êµì‚¬", "êµìœ¡ê³¼ì •", "í•™ì›", "ë³´ìŠµ", "êµìœ¡í˜ì‹ ", "ë””ì§€í„¸êµìœ¡", "ì˜¨ë¼ì¸êµìœ¡", "êµìœ¡ì‹œì„¤", "êµìœ¡í™˜ê²½", "êµìœ¡ì§€ì›", "ì¥í•™ê¸ˆ", "êµìœ¡ë³µì§€", "êµìœ¡ì‹œì„¤ê±´ì„¤", "í•™êµê±´ì„¤", "êµìœ¡ì§€ì›", "ì‚¬êµìœ¡ë¹„ì§€ì›", "êµìœ¡ë¹„ì§€ì›", "ì¥í•™ê¸ˆì§€ì›", "êµìœ¡ë³µì§€ì§€ì›"],
                "promise_keywords": ["êµìœ¡ì‹œì„¤ê±´ì„¤", "í•™êµê±´ì„¤", "êµìœ¡ì§€ì›", "ì‚¬êµìœ¡ë¹„ì§€ì›", "êµìœ¡ë¹„ì§€ì›", "ì¥í•™ê¸ˆì§€ì›", "êµìœ¡ë³µì§€ì§€ì›"]
            },
            "ë³µì§€ì •ì±…": {
                "keywords": ["ë³µì§€", "ì˜ë£Œ", "ê±´ê°•ë³´í—˜", "ì—°ê¸ˆ", "ìœ¡ì•„", "ë³´ìœ¡", "ì‚¬íšŒë³´ì¥", "ë³µì§€í˜œíƒ", "ì§€ì›ê¸ˆ", "ëŒë´„", "ë…¸ì¸ë³µì§€", "ì¥ì• ì¸ë³µì§€", "ê¸°ì´ˆìƒí™œë³´ì¥", "ìƒí™œë³´ì¡°", "ì˜ë£Œë¹„ì§€ì›", "ì¹˜ë£Œë¹„", "ê°„ë³‘", "ìš”ì–‘", "ë³µì§€ì‹œì„¤", "ë³µì§€ì„¼í„°", "ë³µì§€ê´€", "ë³µì§€ì§€ì›", "ì˜ë£Œì§€ì›", "ëŒë´„ì§€ì›", "ìœ¡ì•„ì§€ì›", "ë³´ìœ¡ì§€ì›", "ë…¸ì¸ì§€ì›", "ì¥ì• ì¸ì§€ì›"],
                "promise_keywords": ["ë³µì§€ì‹œì„¤ê±´ì„¤", "ë³µì§€ì„¼í„°ê±´ì„¤", "ë³µì§€ê´€ê±´ì„¤", "ë³µì§€ì§€ì›", "ì˜ë£Œì§€ì›", "ëŒë´„ì§€ì›", "ìœ¡ì•„ì§€ì›", "ë³´ìœ¡ì§€ì›"]
            },
            "í™˜ê²½ì •ì±…": {
                "keywords": ["í™˜ê²½", "ê¸°í›„", "ì—ë„ˆì§€", "ë¯¸ì„¸ë¨¼ì§€", "ì¬ìƒì—ë„ˆì§€", "ì¹œí™˜ê²½", "íƒ„ì†Œ", "ì˜¤ì—¼", "ë…¹ìƒ‰", "ì§€ì†ê°€ëŠ¥", "ëŒ€ê¸°ì§ˆ", "ìˆ˜ì§ˆ", "í† ì–‘", "íê¸°ë¬¼", "ì¬í™œìš©", "ì—ë„ˆì§€ì ˆì•½", "ì‹ ì¬ìƒì—ë„ˆì§€", "íƒœì–‘ê´‘", "í’ë ¥", "í™˜ê²½ë³´ì „", "í™˜ê²½ê°œì„ ", "í™˜ê²½ì •í™”", "í™˜ê²½ì§€ì›", "ì¬ìƒì—ë„ˆì§€ì§€ì›", "ì¹œí™˜ê²½ì§€ì›", "í™˜ê²½ë³´ì „ì§€ì›"],
                "promise_keywords": ["í™˜ê²½ê°œì„ ", "í™˜ê²½ì •í™”", "í™˜ê²½ë³´ì „", "ì¬ìƒì—ë„ˆì§€ì§€ì›", "ì¹œí™˜ê²½ì§€ì›", "í™˜ê²½ë³´ì „ì§€ì›"]
            },
            "êµí†µì •ì±…": {
                "keywords": ["êµí†µ", "ëŒ€ì¤‘êµí†µ", "ì§€í•˜ì² ", "ë²„ìŠ¤", "ë„ë¡œ", "ì£¼ì°¨", "êµí†µì²´ì¦", "ì´ë™", "ì ‘ê·¼ì„±", "ì¸í”„ë¼", "ëŒ€ì¤‘êµí†µë§", "êµí†µë§", "ì§€í•˜ì² ì—°ì¥", "ë²„ìŠ¤ë…¸ì„ ", "ë„ì‹œì² ë„", "ê³ ì†ë„ë¡œ", "êµ­ë„", "ì§€ë°©ë„", "êµí†µê°œì„ ", "êµí†µì§€ì›", "ëŒ€ì¤‘êµí†µì§€ì›", "ì§€í•˜ì² ì§€ì›", "ë²„ìŠ¤ì§€ì›", "ë„ë¡œì§€ì›", "êµí†µì¸í”„ë¼ì§€ì›"],
                "promise_keywords": ["êµí†µê°œì„ ", "ëŒ€ì¤‘êµí†µê°œì„ ", "ì§€í•˜ì² ì—°ì¥", "ë²„ìŠ¤ë…¸ì„ ê°œì„ ", "ë„ë¡œê°œì„ ", "êµí†µì¸í”„ë¼ì§€ì›"]
            },
            "ë¬¸í™”ì •ì±…": {
                "keywords": ["ë¬¸í™”", "ì˜ˆìˆ ", "ê³µì—°", "ì „ì‹œ", "ì¶•ì œ", "ê´€ê´‘", "ì—¬ê°€", "ìŠ¤í¬ì¸ ", "ì²´ìœ¡", "ë„ì„œê´€", "ë°•ë¬¼ê´€", "ë¬¸í™”ì‹œì„¤", "ë¬¸í™”ê³µê°„", "ë¬¸í™”í–‰ì‚¬", "ë¬¸í™”í”„ë¡œê·¸ë¨", "ë¬¸í™”ìœ ì‚°", "ì „í†µë¬¸í™”", "í˜„ëŒ€ë¬¸í™”", "ë¬¸í™”ì§€ì›", "ì˜ˆìˆ ì§€ì›", "ê³µì—°ì§€ì›", "ì „ì‹œì§€ì›", "ì¶•ì œì§€ì›", "ê´€ê´‘ì§€ì›", "ìŠ¤í¬ì¸ ì§€ì›", "ì²´ìœ¡ì§€ì›"],
                "promise_keywords": ["ë¬¸í™”ì‹œì„¤ê±´ì„¤", "ë¬¸í™”ì„¼í„°ê±´ì„¤", "ë„ì„œê´€ê±´ì„¤", "ë°•ë¬¼ê´€ê±´ì„¤", "ë¬¸í™”ì§€ì›", "ì˜ˆìˆ ì§€ì›", "ê³µì—°ì§€ì›", "ì¶•ì œì§€ì›"]
            },
            "ì•ˆì „ì •ì±…": {
                "keywords": ["ì•ˆì „", "ì¬ë‚œ", "ì¬í•´", "ì†Œë°©", "ì‘ê¸‰", "ë²”ì£„", "ì‚¬ê³ ", "ìœ„í—˜", "ë³´ì•ˆ", "ì¹˜ì•ˆ", "ë°©ë²”", "CCTV", "ì•ˆì „ì‹œì„¤", "ì¬ë‚œëŒ€ì‘", "ì‘ê¸‰ì˜ë£Œ", "êµ¬ì¡°", "êµ¬ê¸‰", "í™”ì¬", "ì§€ì§„", "íƒœí’", "ì•ˆì „ì§€ì›", "ì¬ë‚œì§€ì›", "ì†Œë°©ì§€ì›", "ì‘ê¸‰ì§€ì›", "ì¹˜ì•ˆì§€ì›", "ë°©ë²”ì§€ì›"],
                "promise_keywords": ["ì•ˆì „ì‹œì„¤ê±´ì„¤", "ì†Œë°©ì‹œì„¤ê±´ì„¤", "ì‘ê¸‰ì‹œì„¤ê±´ì„¤", "CCTVì„¤ì¹˜", "ì•ˆì „ì§€ì›", "ì¬ë‚œì§€ì›", "ì†Œë°©ì§€ì›", "ì‘ê¸‰ì§€ì›"]
            }
        }
    
    def _load_local_government_structure(self) -> Dict[str, Any]:
        """ì§€ë°©ìì¹˜ë‹¨ì²´ êµ¬ì¡° ë¡œë“œ"""
        return {
            "ì„œìš¸íŠ¹ë³„ì‹œ": {
                "level": "ê´‘ì—­ì‹œë„",
                "sigungu": [
                    "ê°•ë‚¨êµ¬", "ê°•ë™êµ¬", "ê°•ë¶êµ¬", "ê°•ì„œêµ¬", "ê´€ì•…êµ¬", "ê´‘ì§„êµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬", "ë…¸ì›êµ¬", "ë„ë´‰êµ¬", 
                    "ë™ëŒ€ë¬¸êµ¬", "ë™ì‘êµ¬", "ë§ˆí¬êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ì„œì´ˆêµ¬", "ì„±ë™êµ¬", "ì„±ë¶êµ¬", "ì†¡íŒŒêµ¬", "ì–‘ì²œêµ¬", 
                    "ì˜ë“±í¬êµ¬", "ìš©ì‚°êµ¬", "ì€í‰êµ¬", "ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ì¤‘ë‘êµ¬"
                ]
            },
            "ë¶€ì‚°ê´‘ì—­ì‹œ": {
                "level": "ê´‘ì—­ì‹œë„", 
                "sigungu": [
                    "ê°•ì„œêµ¬", "ê¸ˆì •êµ¬", "ê¸°ì¥êµ°", "ë‚¨êµ¬", "ë™êµ¬", "ë™ë˜êµ¬", "ë¶€ì‚°ì§„êµ¬", "ë¶êµ¬", "ì‚¬ìƒêµ¬", "ì‚¬í•˜êµ¬", 
                    "ì„œêµ¬", "ìˆ˜ì˜êµ¬", "ì—°ì œêµ¬", "ì˜ë„êµ¬", "ì¤‘êµ¬", "í•´ìš´ëŒ€êµ¬"
                ]
            },
            "ëŒ€êµ¬ê´‘ì—­ì‹œ": {
                "level": "ê´‘ì—­ì‹œë„",
                "sigungu": ["êµ°ìœ„êµ°", "ë‚¨êµ¬", "ë‹¬ì„œêµ¬", "ë‹¬ì„±êµ°", "ë™êµ¬", "ë¶êµ¬", "ì„œêµ¬", "ìˆ˜ì„±êµ¬", "ì¤‘êµ¬"]
            },
            "ì¸ì²œê´‘ì—­ì‹œ": {
                "level": "ê´‘ì—­ì‹œë„",
                "sigungu": ["ê°•í™”êµ°", "ê³„ì–‘êµ¬", "ë‚¨ë™êµ¬", "ë™êµ¬", "ë¯¸ì¶”í™€êµ¬", "ë¶€í‰êµ¬", "ì„œêµ¬", "ì—°ìˆ˜êµ¬", "ì˜¹ì§„êµ°", "ì¤‘êµ¬"]
            },
            "ê´‘ì£¼ê´‘ì—­ì‹œ": {
                "level": "ê´‘ì—­ì‹œë„",
                "sigungu": ["ê´‘ì‚°êµ¬", "ë‚¨êµ¬", "ë™êµ¬", "ë¶êµ¬", "ì„œêµ¬"]
            },
            "ëŒ€ì „ê´‘ì—­ì‹œ": {
                "level": "ê´‘ì—­ì‹œë„",
                "sigungu": ["ëŒ€ë•êµ¬", "ë™êµ¬", "ì„œêµ¬", "ìœ ì„±êµ¬", "ì¤‘êµ¬"]
            },
            "ìš¸ì‚°ê´‘ì—­ì‹œ": {
                "level": "ê´‘ì—­ì‹œë„",
                "sigungu": ["ë‚¨êµ¬", "ë™êµ¬", "ë¶êµ¬", "ìš¸ì£¼êµ°", "ì¤‘êµ¬"]
            },
            "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": {
                "level": "ê´‘ì—­ì‹œë„",
                "sigungu": ["ì„¸ì¢…ì‹œ"]
            },
            "ê²½ê¸°ë„": {
                "level": "ë„",
                "sigungu": [
                    "ê°€í‰êµ°", "ê³ ì–‘ì‹œ", "ê³¼ì²œì‹œ", "ê´‘ëª…ì‹œ", "ê´‘ì£¼ì‹œ", "êµ¬ë¦¬ì‹œ", "êµ°í¬ì‹œ", "ê¹€í¬ì‹œ", "ë‚¨ì–‘ì£¼ì‹œ", "ë™ë‘ì²œì‹œ",
                    "ë¶€ì²œì‹œ", "ì„±ë‚¨ì‹œ", "ìˆ˜ì›ì‹œ", "ì‹œí¥ì‹œ", "ì•ˆì‚°ì‹œ", "ì•ˆì„±ì‹œ", "ì•ˆì–‘ì‹œ", "ì–‘ì£¼ì‹œ", "ì–‘í‰êµ°", "ì—¬ì£¼ì‹œ",
                    "ì—°ì²œêµ°", "ì˜¤ì‚°ì‹œ", "ìš©ì¸ì‹œ", "ì˜ì™•ì‹œ", "ì˜ì •ë¶€ì‹œ", "ì´ì²œì‹œ", "íŒŒì£¼ì‹œ", "í‰íƒì‹œ", "í¬ì²œì‹œ", "í•˜ë‚¨ì‹œ", "í™”ì„±ì‹œ"
                ]
            },
            "ê°•ì›ë„": {
                "level": "ë„",
                "sigungu": [
                    "ê°•ë¦‰ì‹œ", "ê³ ì„±êµ°", "ë™í•´ì‹œ", "ì‚¼ì²™ì‹œ", "ì†ì´ˆì‹œ", "ì–‘êµ¬êµ°", "ì–‘ì–‘êµ°", "ì˜ì›”êµ°", "ì›ì£¼ì‹œ", "ì¸ì œêµ°",
                    "ì •ì„ êµ°", "ì² ì›êµ°", "ì¶˜ì²œì‹œ", "íƒœë°±ì‹œ", "í‰ì°½êµ°", "í™ì²œêµ°", "í™”ì²œêµ°", "íš¡ì„±êµ°"
                ]
            },
            "ì¶©ì²­ë¶ë„": {
                "level": "ë„",
                "sigungu": ["ê´´ì‚°êµ°", "ë‹¨ì–‘êµ°", "ë³´ì€êµ°", "ì˜ë™êµ°", "ì˜¥ì²œêµ°", "ìŒì„±êµ°", "ì œì²œì‹œ", "ì¦í‰êµ°", "ì§„ì²œêµ°", "ì²­ì£¼ì‹œ", "ì¶©ì£¼ì‹œ"]
            },
            "ì¶©ì²­ë‚¨ë„": {
                "level": "ë„", 
                "sigungu": ["ê³„ë£¡ì‹œ", "ê³µì£¼ì‹œ", "ê¸ˆì‚°êµ°", "ë…¼ì‚°ì‹œ", "ë‹¹ì§„ì‹œ", "ë³´ë ¹ì‹œ", "ë¶€ì—¬êµ°", "ì„œì‚°ì‹œ", "ì„œì²œêµ°", "ì•„ì‚°ì‹œ", "ì˜ˆì‚°êµ°", "ì²œì•ˆì‹œ", "ì²­ì–‘êµ°", "íƒœì•ˆêµ°", "í™ì„±êµ°"]
            },
            "ì „ë¼ë¶ë„": {
                "level": "ë„",
                "sigungu": ["ê³ ì°½êµ°", "êµ°ì‚°ì‹œ", "ê¹€ì œì‹œ", "ë‚¨ì›ì‹œ", "ë¬´ì£¼êµ°", "ë¶€ì•ˆêµ°", "ìˆœì°½êµ°", "ì™„ì£¼êµ°", "ìµì‚°ì‹œ", "ì„ì‹¤êµ°", "ì¥ìˆ˜êµ°", "ì „ì£¼ì‹œ", "ì •ìì‹œ", "ì§„ì•ˆêµ°"]
            },
            "ì „ë¼ë‚¨ë„": {
                "level": "ë„",
                "sigungu": ["ê°•ì§„êµ°", "ê³ í¥êµ°", "ê³¡ì„±êµ°", "ê´‘ì–‘ì‹œ", "êµ¬ë¡€êµ°", "ë‚˜ì£¼ì‹œ", "ë‹´ì–‘êµ°", "ëª©í¬ì‹œ", "ë¬´ì•ˆêµ°", "ë³´ì„±êµ°", "ìˆœì²œì‹œ", "ì‹ ì•ˆêµ°", "ì—¬ìˆ˜ì‹œ", "ì˜ê´‘êµ°", "ì˜ì•”êµ°", "ì™„ë„êµ°", "ì¥ì„±êµ°", "ì¥í¥êµ°", "ì§„ë„êµ°", "í•¨í‰êµ°", "í•´ë‚¨êµ°", "í™”ìˆœêµ°"]
            },
            "ê²½ìƒë¶ë„": {
                "level": "ë„",
                "sigungu": ["ê²½ì‚°ì‹œ", "ê²½ì£¼ì‹œ", "ê³ ë ¹êµ°", "êµ¬ë¯¸ì‹œ", "ê¹€ì²œì‹œ", "ë¬¸ê²½ì‹œ", "ë´‰í™”êµ°", "ìƒì£¼ì‹œ", "ì„±ì£¼êµ°", "ì•ˆë™ì‹œ", "ì˜ë•êµ°", "ì˜ì–‘êµ°", "ì˜ì£¼ì‹œ", "ì˜ì²œì‹œ", "ì˜ˆì²œêµ°", "ìš¸ë¦‰êµ°", "ìš¸ì§„êµ°", "ì˜ì„±êµ°", "ì²­ë„êµ°", "ì²­ì†¡êµ°", "ì¹ ê³¡êµ°", "í¬í•­ì‹œ"]
            },
            "ê²½ìƒë‚¨ë„": {
                "level": "ë„",
                "sigungu": ["ê±°ì œì‹œ", "ê±°ì°½êµ°", "ê³ ì„±êµ°", "ê¹€í•´ì‹œ", "ë‚¨í•´êµ°", "ë°€ì–‘ì‹œ", "ì‚¬ì²œì‹œ", "ì‚°ì²­êµ°", "ì–‘ì‚°ì‹œ", "ì˜ë ¹êµ°", "ì§„ì£¼ì‹œ", "ì°½ë…•êµ°", "ì°½ì›ì‹œ", "í†µì˜ì‹œ", "í•˜ë™êµ°", "í•¨ì•ˆêµ°", "í•¨ì–‘êµ°", "í•©ì²œêµ°"]
            },
            "ì œì£¼íŠ¹ë³„ìì¹˜ë„": {
                "level": "ë„",
                "sigungu": ["ì œì£¼ì‹œ", "ì„œê·€í¬ì‹œ"]
            }
        }
    
    def extract_document_structure(self) -> Dict[str, Any]:
        """ë¬¸ì„œ êµ¬ì¡° ë¶„ì„"""
        print("ğŸ“„ ë¬¸ì„œ êµ¬ì¡° ìƒì„¸ ë¶„ì„ ì¤‘...")
        
        doc = fitz.open(self.pdf_file)
        document_structure = {
            "total_pages": len(doc),
            "local_government_pages": defaultdict(list),
            "individual_sigungu_pages": defaultdict(list),
            "topic_structure": []
        }
        
        for page_num in range(len(doc)):
            page = doc[page_num]
            text = page.get_text()
            
            # ê´‘ì—­ ì§€ìì²´ íŒ¨í„´ ì°¾ê¸°
            for gov_name in self.local_government_structure.keys():
                if gov_name in text:
                    document_structure["local_government_pages"][gov_name].append(page_num + 1)
            
            # ê°œë³„ ì‹œêµ°êµ¬ íŒ¨í„´ ì°¾ê¸°
            for gov_name, gov_info in self.local_government_structure.items():
                if "sigungu" in gov_info:
                    for sigungu in gov_info["sigungu"]:
                        if sigungu in text:
                            document_structure["individual_sigungu_pages"][sigungu].append({
                                "page": page_num + 1,
                                "parent_government": gov_name,
                                "text_preview": text[:300] + "..." if len(text) > 300 else text
                            })
            
            # í† í”½ êµ¬ì¡° ë¶„ì„
            if any(topic in text for topic in ["í† í”½", "ì •ì±…", "ê³µì•½", "ë¯¼ìƒ", "ì´ìŠˆ"]):
                document_structure["topic_structure"].append({
                    "page": page_num + 1,
                    "has_topic_content": True,
                    "text_preview": text[:200] + "..." if len(text) > 200 else text
                })
        
        doc.close()
        
        print(f"âœ… ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì™„ë£Œ:")
        print(f"  ğŸ“Š ì´ í˜ì´ì§€: {document_structure['total_pages']}ê°œ")
        print(f"  ğŸ›ï¸ ê´‘ì—­ ì§€ìì²´ ì–¸ê¸‰: {len(document_structure['local_government_pages'])}ê°œ")
        print(f"  ğŸ˜ï¸ ê°œë³„ ì‹œêµ°êµ¬ ì–¸ê¸‰: {len(document_structure['individual_sigungu_pages'])}ê°œ")
        print(f"  ğŸ“‹ í† í”½ ê´€ë ¨ í˜ì´ì§€: {len(document_structure['topic_structure'])}ê°œ")
        
        return document_structure
    
    def extract_local_government_topics(self, document_structure: Dict[str, Any]) -> Dict[str, Any]:
        """ê°œë³„ ì§€ìì²´ë³„ í† í”½ ì¶”ì¶œ"""
        print("ğŸ—ºï¸ ê°œë³„ ì§€ìì²´ë³„ í† í”½ ì¶”ì¶œ ì¤‘...")
        
        doc = fitz.open(self.pdf_file)
        local_government_analysis = {}
        
        # ê° ì‹œêµ°êµ¬ë³„ ë¶„ì„
        for sigungu, page_info_list in document_structure["individual_sigungu_pages"].items():
            print(f"  ğŸ“ {sigungu} ë¶„ì„ ì¤‘...")
            
            sigungu_text = ""
            sigungu_pages = []
            
            # í•´ë‹¹ ì‹œêµ°êµ¬ê°€ ì–¸ê¸‰ëœ ëª¨ë“  í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            for page_info in page_info_list:
                page_num = page_info["page"] - 1  # 0-based index
                page = doc[page_num]
                page_text = page.get_text()
                sigungu_text += page_text + "\n"
                sigungu_pages.append(page_num + 1)
            
            if not sigungu_text:
                continue
            
            # í† í”½ë³„ ì ìˆ˜ ê³„ì‚°
            topic_scores = {}
            topic_sentences = defaultdict(list)
            
            for topic_name, topic_info in self.enhanced_topic_keywords.items():
                score = 0
                sentences = []
                
                for keyword in topic_info["keywords"]:
                    if keyword in sigungu_text:
                        # í•´ë‹¹ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ë“¤ ì°¾ê¸°
                        sentences_with_keyword = self._extract_sentences_with_keyword(sigungu_text, keyword)
                        sentences.extend(sentences_with_keyword)
                        score += len(sentences_with_keyword)
                
                if score > 0:
                    topic_scores[topic_name] = score
                    topic_sentences[topic_name] = sentences[:10]  # ìƒìœ„ 10ê°œ ë¬¸ì¥
            
            # ì •ì±… ê³µì•½ ì¶”ì¶œ
            promises = self._extract_detailed_promises(sigungu_text)
            
            # ìƒìœ„ í† í”½ ì„ ì •
            dominant_topics = sorted(topic_scores.items(), key=lambda x: x[1], reverse=True)[:5]
            dominant_topic_names = [topic for topic, score in dominant_topics]
            
            local_government_analysis[sigungu] = {
                "sigungu_name": sigungu,
                "parent_government": page_info_list[0]["parent_government"] if page_info_list else "Unknown",
                "level": "ì‹œêµ°êµ¬",
                "analyzed_pages": sigungu_pages,
                "mention_count": len(sigungu_pages),
                "dominant_topics": dominant_topic_names,
                "topic_scores": topic_scores,
                "topic_sentences": dict(topic_sentences),
                "promises": promises[:15],  # ìƒìœ„ 15ê°œ ê³µì•½
                "confidence_score": self._calculate_confidence_score(topic_scores),
                "interpretation": self._generate_detailed_interpretation(sigungu, dominant_topics, topic_scores),
                "text_length": len(sigungu_text)
            }
        
        doc.close()
        
        print(f"âœ… ê°œë³„ ì§€ìì²´ ë¶„ì„ ì™„ë£Œ: {len(local_government_analysis)}ê°œ ì‹œêµ°êµ¬")
        return local_government_analysis
    
    def _extract_sentences_with_keyword(self, text: str, keyword: str) -> List[str]:
        """í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ë“¤ ì¶”ì¶œ"""
        sentences = []
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
        text_sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ\n]', text)
        
        for sentence in text_sentences:
            sentence = sentence.strip()
            if keyword in sentence and len(sentence) > 10:
                sentences.append(sentence)
        
        return sentences
    
    def _extract_detailed_promises(self, text: str) -> List[str]:
        """ìƒì„¸í•œ ì •ì±… ê³µì•½ ì¶”ì¶œ"""
        promises = []
        
        for pattern in self.policy_promise_patterns:
            matches = re.findall(pattern, text)
            promises.extend(matches)
        
        # í† í”½ë³„ ê³µì•½ í‚¤ì›Œë“œë¡œ ì¶”ê°€ ì¶”ì¶œ
        for topic_name, topic_info in self.enhanced_topic_keywords.items():
            if "promise_keywords" in topic_info:
                for promise_keyword in topic_info["promise_keywords"]:
                    if promise_keyword in text:
                        # í•´ë‹¹ í‚¤ì›Œë“œ ì£¼ë³€ ë¬¸ë§¥ ì¶”ì¶œ
                        context = self._extract_context_around_keyword(text, promise_keyword)
                        promises.extend(context)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ì œ
        unique_promises = list(set(promises))
        filtered_promises = []
        
        for promise in unique_promises:
            # ê¸¸ì´ ë° í’ˆì§ˆ í•„í„°ë§
            if 3 <= len(promise) <= 100 and not re.match(r'^[0-9\s\-\.]+$', promise):
                filtered_promises.append(promise)
        
        return filtered_promises
    
    def _extract_context_around_keyword(self, text: str, keyword: str) -> List[str]:
        """í‚¤ì›Œë“œ ì£¼ë³€ ë¬¸ë§¥ ì¶”ì¶œ"""
        contexts = []
        
        # í‚¤ì›Œë“œ ìœ„ì¹˜ ì°¾ê¸°
        start = 0
        while True:
            pos = text.find(keyword, start)
            if pos == -1:
                break
            
            # í‚¤ì›Œë“œ ì•ë’¤ë¡œ 50ìì”© ì¶”ì¶œ
            context_start = max(0, pos - 50)
            context_end = min(len(text), pos + len(keyword) + 50)
            context = text[context_start:context_end].strip()
            
            if len(context) > 10:
                contexts.append(context)
            
            start = pos + 1
        
        return contexts
    
    def _calculate_confidence_score(self, topic_scores: Dict[str, int]) -> int:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        if not topic_scores:
            return 0
        
        max_score = max(topic_scores.values())
        total_score = sum(topic_scores.values())
        
        if total_score >= 50:
            return min(10, max_score // 3)
        elif total_score >= 30:
            return min(8, max_score // 2)
        elif total_score >= 15:
            return min(6, max_score)
        else:
            return min(4, max_score)
    
    def _generate_detailed_interpretation(self, sigungu: str, dominant_topics: List[Tuple[str, int]], topic_scores: Dict[str, int]) -> str:
        """ìƒì„¸í•œ í•´ì„ ìƒì„±"""
        if not dominant_topics:
            return f"{sigungu}ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ì±… ë…¼ì˜ê°€ í™•ì¸ë˜ì§€ ì•ŠìŒ"
        
        top_topic, top_score = dominant_topics[0]
        
        if top_score >= 20:
            return f"{sigungu}ì€ {top_topic} ë¶„ì•¼ì—ì„œ ë§¤ìš° ê°•í•œ ê´€ì‹¬ì„ ë³´ì´ë©°, ì´ëŠ” í•´ë‹¹ ì§€ì—­ì˜ í•µì‹¬ ì •ì±… ì´ìŠˆë¡œ íŒë‹¨ë¨"
        elif top_score >= 10:
            return f"{sigungu}ì€ {top_topic} ë¶„ì•¼ì—ì„œ ìƒë‹¹í•œ ê´€ì‹¬ì„ ë³´ì´ë©°, ê´€ë ¨ ì •ì±… ê°œë°œì´ í™œë°œíˆ ì§„í–‰ë˜ê³  ìˆìŒ"
        elif top_score >= 5:
            return f"{sigungu}ì€ {top_topic} ë¶„ì•¼ì— ê´€ì‹¬ì„ ë³´ì´ë©°, ê´€ë ¨ ì •ì±… ë…¼ì˜ê°€ ì´ë£¨ì–´ì§€ê³  ìˆìŒ"
        else:
            return f"{sigungu}ì€ {top_topic} ë¶„ì•¼ì— ê¸°ë³¸ì ì¸ ê´€ì‹¬ì„ ë³´ì´ë©°, í–¥í›„ ì •ì±… ê°œë°œì´ í•„ìš”í•¨"
    
    def run_detailed_analysis(self) -> Dict[str, Any]:
        """ìƒì„¸ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ ê°œë³„ ì§€ìì²´ë³„ ìƒì„¸ ë¶„ì„ ì‹œì‘!")
        print("=" * 60)
        
        # 1. ë¬¸ì„œ êµ¬ì¡° ë¶„ì„
        document_structure = self.extract_document_structure()
        
        # 2. ê°œë³„ ì§€ìì²´ë³„ í† í”½ ì¶”ì¶œ
        local_government_analysis = self.extract_local_government_topics(document_structure)
        
        # 3. ì „ì²´ í†µê³„ ê³„ì‚°
        overall_statistics = self._calculate_overall_statistics(local_government_analysis)
        
        # 4. ê²°ê³¼ í†µí•©
        detailed_results = {
            "document_info": {
                "file_path": self.pdf_file,
                "analysis_date": datetime.now().isoformat(),
                "total_pages": document_structure["total_pages"]
            },
            "document_structure": document_structure,
            "local_government_analysis": local_government_analysis,
            "overall_statistics": overall_statistics,
            "enhanced_topic_keywords": self.enhanced_topic_keywords
        }
        
        print("=" * 60)
        print("ğŸ‰ ìƒì„¸ ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
        print(f"  â€¢ ë¶„ì„ëœ ì‹œêµ°êµ¬: {len(local_government_analysis)}ê°œ")
        print(f"  â€¢ ì´ í† í”½ ì¹´í…Œê³ ë¦¬: {len(self.enhanced_topic_keywords)}ê°œ")
        print(f"  â€¢ ì´ ì •ì±… ê³µì•½: {sum(len(gov['promises']) for gov in local_government_analysis.values())}ê°œ")
        
        return detailed_results
    
    def _calculate_overall_statistics(self, local_government_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ì²´ í†µê³„ ê³„ì‚°"""
        statistics = {
            "total_sigungu_analyzed": len(local_government_analysis),
            "topic_frequency": defaultdict(int),
            "topic_total_scores": defaultdict(int),
            "parent_government_distribution": defaultdict(int),
            "average_promises_per_sigungu": 0,
            "most_active_sigungu": None,
            "topic_concentration": {}
        }
        
        total_promises = 0
        max_activity = 0
        
        for sigungu, analysis in local_government_analysis.items():
            # í† í”½ ë¹ˆë„ ê³„ì‚°
            for topic in analysis["dominant_topics"]:
                statistics["topic_frequency"][topic] += 1
            
            # í† í”½ ì ìˆ˜ í•©ê³„
            for topic, score in analysis["topic_scores"].items():
                statistics["topic_total_scores"][topic] += score
            
            # ìƒìœ„ ì§€ìì²´ ë¶„í¬
            statistics["parent_government_distribution"][analysis["parent_government"]] += 1
            
            # ê³µì•½ ìˆ˜ ì§‘ê³„
            promise_count = len(analysis["promises"])
            total_promises += promise_count
            
            # ê°€ì¥ í™œë°œí•œ ì‹œêµ°êµ¬
            if promise_count > max_activity:
                max_activity = promise_count
                statistics["most_active_sigungu"] = sigungu
        
        statistics["average_promises_per_sigungu"] = total_promises / len(local_government_analysis) if local_government_analysis else 0
        
        # í† í”½ ì§‘ì¤‘ë„ ê³„ì‚°
        for topic, freq in statistics["topic_frequency"].items():
            statistics["topic_concentration"][topic] = freq / len(local_government_analysis)
        
        return statistics
    
    def save_results(self, results: Dict[str, Any], output_dir: str = None) -> str:
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        if output_dir is None:
            output_dir = os.path.join(os.path.dirname(__file__), "detailed_local_government_analysis")
        
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        json_file = os.path.join(output_dir, f"detailed_local_government_analysis_{timestamp}.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {json_file}")
        return json_file

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    pdf_file_path = "/Users/hopidaay/Desktop/231215_ì •ì±…ì„ ê±°ë¬¸í™”_í™•ì‚°ì„_ìœ„í•œ_ì–¸ë¡ ê¸°ì‚¬_ë¹…ë°ì´í„°_ë¶„ì„.pdf"
    
    if not os.path.exists(pdf_file_path):
        print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_file_path}")
        return
    
    analyzer = DetailedLocalGovernmentAnalyzer(pdf_file_path)
    results = analyzer.run_detailed_analysis()
    analyzer.save_results(results)
    
    print("\nğŸŠ ê°œë³„ ì§€ìì²´ë³„ ìƒì„¸ ë¶„ì„ ì™„ë£Œ!")
    print("ğŸ“ˆ ì‹œêµ°êµ¬ ë‹¨ìœ„ê¹Œì§€ ì„¸ë°€í•œ í† í”½ê³¼ ê³µì•½ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()
