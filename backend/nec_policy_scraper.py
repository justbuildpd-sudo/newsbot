#!/usr/bin/env python3
"""
ì¤‘ì•™ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒ ì •ì±…Â·ê³µì•½ ì•Œë¦¬ë¯¸ì—ì„œ 
8íšŒ ì „êµ­ë™ì‹œì§€ë°©ì„ ê±° ë‹¹ì„ ì ê³µì•½ ë°ì´í„° ìˆ˜ì§‘ê¸°
"""

import requests
import json
import time
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from urllib.parse import urljoin, urlparse
import re
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

class NECPolicyScraper:
    """ì¤‘ì•™ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒ ì •ì±…Â·ê³µì•½ ì•Œë¦¬ë¯¸ ìŠ¤í¬ë˜í¼"""
    
    def __init__(self):
        self.base_url = "https://policy.nec.go.kr"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
        
        # 8íšŒ ì „êµ­ë™ì‹œì§€ë°©ì„ ê±° ì •ë³´
        self.election_info = {
            "election_name": "ì œ8íšŒ ì „êµ­ë™ì‹œì§€ë°©ì„ ê±°",
            "election_date": "2022-06-01",
            "election_code": "20220601"  # ì¶”ì • ì½”ë“œ
        }
        
        # ìˆ˜ì§‘í•  ë‹¹ì„ ì ìœ í˜•
        self.winner_types = [
            "ê´‘ì—­ë‹¨ì²´ì¥",     # ì‹œë„ì§€ì‚¬
            "ê¸°ì´ˆë‹¨ì²´ì¥",     # ì‹œì¥, êµ°ìˆ˜, êµ¬ì²­ì¥
            "ê´‘ì—­ì˜íšŒì˜ì›",   # ì‹œë„ì˜íšŒì˜ì›
            "ê¸°ì´ˆì˜íšŒì˜ì›",   # ì‹œêµ°êµ¬ì˜íšŒì˜ì›
            "êµìœ¡ê°"         # ì‹œë„êµìœ¡ê°
        ]
        
        # ìˆ˜ì§‘ëœ ë°ì´í„° ì €ì¥ì†Œ
        self.collected_data = {
            "election_info": self.election_info,
            "collection_date": datetime.now().isoformat(),
            "winners_data": {},
            "statistics": {
                "total_winners": 0,
                "total_pledges": 0,
                "by_position": {},
                "by_region": {}
            }
        }
    
    def get_election_overview(self) -> Dict[str, Any]:
        """ì„ ê±° ê°œìš” ì •ë³´ ìˆ˜ì§‘"""
        try:
            print("ğŸ“Š 8íšŒ ì „êµ­ë™ì‹œì§€ë°©ì„ ê±° ê°œìš” ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
            
            # ë©”ì¸ í˜ì´ì§€ ì ‘ê·¼
            response = self.session.get(self.base_url)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ì„ ê±° ì •ë³´ ì¶”ì¶œ (ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”)
            election_info = {
                "title": "ì œ8íšŒ ì „êµ­ë™ì‹œì§€ë°©ì„ ê±°",
                "date": "2022ë…„ 6ì›” 1ì¼",
                "status": "ì™„ë£Œ",
                "total_positions": self._extract_total_positions(soup),
                "available_data": self._check_available_data(soup)
            }
            
            print(f"âœ… ì„ ê±° ê°œìš” ìˆ˜ì§‘ ì™„ë£Œ: {election_info['title']}")
            return election_info
            
        except Exception as e:
            logger.error(f"ì„ ê±° ê°œìš” ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def get_winners_by_position(self, position_type: str) -> List[Dict[str, Any]]:
        """ì§ì±…ë³„ ë‹¹ì„ ì ëª©ë¡ ìˆ˜ì§‘"""
        try:
            print(f"ğŸ›ï¸ {position_type} ë‹¹ì„ ì ëª©ë¡ ìˆ˜ì§‘ ì¤‘...")
            
            # ì§ì±…ë³„ URL êµ¬ì„± (ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë”°ë¼ ì¡°ì •)
            position_url = self._build_position_url(position_type)
            
            response = self.session.get(position_url)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            winners = []
            
            # ë‹¹ì„ ì ëª©ë¡ íŒŒì‹± (ì‹¤ì œ HTML êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”)
            winner_elements = soup.find_all('div', class_='winner-item')  # ì˜ˆì‹œ í´ë˜ìŠ¤ëª…
            
            for element in winner_elements:
                winner_data = self._parse_winner_element(element, position_type)
                if winner_data:
                    winners.append(winner_data)
            
            print(f"âœ… {position_type} ë‹¹ì„ ì {len(winners)}ëª… ìˆ˜ì§‘ ì™„ë£Œ")
            return winners
            
        except Exception as e:
            logger.error(f"{position_type} ë‹¹ì„ ì ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []
    
    def get_winner_pledges(self, winner_id: str, winner_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ê°œë³„ ë‹¹ì„ ìì˜ ê³µì•½ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘"""
        try:
            print(f"ğŸ“‹ {winner_info['name']} ê³µì•½ ìˆ˜ì§‘ ì¤‘...")
            
            # ê³µì•½ ìƒì„¸ í˜ì´ì§€ URL êµ¬ì„±
            pledge_url = self._build_pledge_url(winner_id)
            
            response = self.session.get(pledge_url)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            pledges = []
            
            # ê³µì•½ ëª©ë¡ íŒŒì‹±
            pledge_elements = soup.find_all('div', class_='pledge-item')  # ì˜ˆì‹œ í´ë˜ìŠ¤ëª…
            
            for element in pledge_elements:
                pledge_data = self._parse_pledge_element(element)
                if pledge_data:
                    pledges.append(pledge_data)
            
            print(f"âœ… {winner_info['name']} ê³µì•½ {len(pledges)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            return pledges
            
        except Exception as e:
            logger.error(f"{winner_info['name']} ê³µì•½ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []
    
    def collect_all_winners_pledges(self) -> Dict[str, Any]:
        """ëª¨ë“  ë‹¹ì„ ìì˜ ê³µì•½ ìˆ˜ì§‘"""
        try:
            print("ğŸš€ 8íšŒ ì „êµ­ë™ì‹œì§€ë°©ì„ ê±° ëª¨ë“  ë‹¹ì„ ì ê³µì•½ ìˆ˜ì§‘ ì‹œì‘!")
            print("=" * 60)
            
            # 1. ì„ ê±° ê°œìš” ìˆ˜ì§‘
            election_overview = self.get_election_overview()
            self.collected_data["election_overview"] = election_overview
            
            # 2. ì§ì±…ë³„ ë‹¹ì„ ì ë° ê³µì•½ ìˆ˜ì§‘
            for position_type in self.winner_types:
                print(f"\nğŸ“Š {position_type} ì²˜ë¦¬ ì¤‘...")
                
                # ë‹¹ì„ ì ëª©ë¡ ìˆ˜ì§‘
                winners = self.get_winners_by_position(position_type)
                
                if not winners:
                    print(f"âš ï¸ {position_type} ë‹¹ì„ ì ë°ì´í„° ì—†ìŒ")
                    continue
                
                position_data = {
                    "position_type": position_type,
                    "total_winners": len(winners),
                    "winners": {}
                }
                
                # ê° ë‹¹ì„ ìì˜ ê³µì•½ ìˆ˜ì§‘
                for i, winner in enumerate(winners, 1):
                    print(f"  ğŸ“‹ {i}/{len(winners)}: {winner['name']} ({winner['region']})")
                    
                    winner_id = winner.get('id', f"{position_type}_{i}")
                    
                    # ê³µì•½ ìˆ˜ì§‘
                    pledges = self.get_winner_pledges(winner_id, winner)
                    
                    # ë°ì´í„° í†µí•©
                    winner_full_data = {
                        **winner,
                        "pledges": pledges,
                        "pledge_count": len(pledges),
                        "collection_date": datetime.now().isoformat()
                    }
                    
                    position_data["winners"][winner_id] = winner_full_data
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    self.collected_data["statistics"]["total_winners"] += 1
                    self.collected_data["statistics"]["total_pledges"] += len(pledges)
                    
                    # API ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
                    time.sleep(0.5)
                
                self.collected_data["winners_data"][position_type] = position_data
                
                # ì§ì±…ë³„ í†µê³„
                self.collected_data["statistics"]["by_position"][position_type] = {
                    "winners": len(winners),
                    "total_pledges": sum(len(w["pledges"]) for w in position_data["winners"].values())
                }
            
            print("\n" + "=" * 60)
            print("ğŸ‰ ëª¨ë“  ë‹¹ì„ ì ê³µì•½ ìˆ˜ì§‘ ì™„ë£Œ!")
            print(f"ğŸ“Š ì´ ë‹¹ì„ ì: {self.collected_data['statistics']['total_winners']}ëª…")
            print(f"ğŸ“‹ ì´ ê³µì•½: {self.collected_data['statistics']['total_pledges']}ê°œ")
            
            return self.collected_data
            
        except Exception as e:
            logger.error(f"ì „ì²´ ìˆ˜ì§‘ ê³¼ì • ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def _extract_total_positions(self, soup: BeautifulSoup) -> Dict[str, int]:
        """ì „ì²´ ì„ ì¶œì§ ìˆ˜ ì¶”ì¶œ"""
        # ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë”°ë¼ êµ¬í˜„
        return {
            "ê´‘ì—­ë‹¨ì²´ì¥": 17,
            "ê¸°ì´ˆë‹¨ì²´ì¥": 226,
            "ê´‘ì—­ì˜íšŒì˜ì›": 789,
            "ê¸°ì´ˆì˜íšŒì˜ì›": 2602,
            "êµìœ¡ê°": 17
        }
    
    def _check_available_data(self, soup: BeautifulSoup) -> List[str]:
        """ì´ìš© ê°€ëŠ¥í•œ ë°ì´í„° ìœ í˜• í™•ì¸"""
        # ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë”°ë¼ êµ¬í˜„
        return ["ë‹¹ì„ ì ì •ë³´", "ê³µì•½ ì •ë³´", "ë“í‘œ ì •ë³´", "ì„ ê±°êµ¬ ì •ë³´"]
    
    def _build_position_url(self, position_type: str) -> str:
        """ì§ì±…ë³„ URL êµ¬ì„±"""
        position_codes = {
            "ê´‘ì—­ë‹¨ì²´ì¥": "mayor",
            "ê¸°ì´ˆë‹¨ì²´ì¥": "district_mayor", 
            "ê´‘ì—­ì˜íšŒì˜ì›": "metro_council",
            "ê¸°ì´ˆì˜íšŒì˜ì›": "local_council",
            "êµìœ¡ê°": "education_chief"
        }
        
        code = position_codes.get(position_type, "unknown")
        return f"{self.base_url}/election/{self.election_info['election_code']}/{code}"
    
    def _build_pledge_url(self, winner_id: str) -> str:
        """ê³µì•½ ìƒì„¸ í˜ì´ì§€ URL êµ¬ì„±"""
        return f"{self.base_url}/pledge/{winner_id}"
    
    def _parse_winner_element(self, element, position_type: str) -> Optional[Dict[str, Any]]:
        """ë‹¹ì„ ì ì •ë³´ íŒŒì‹±"""
        try:
            # ì‹¤ì œ HTML êµ¬ì¡°ì— ë”°ë¼ êµ¬í˜„ í•„ìš”
            name = element.find('span', class_='name')
            party = element.find('span', class_='party')
            region = element.find('span', class_='region')
            
            if not (name and party and region):
                return None
            
            return {
                "name": name.text.strip(),
                "party": party.text.strip(),
                "region": region.text.strip(),
                "position_type": position_type,
                "id": f"{position_type}_{name.text.strip()}_{region.text.strip()}"
            }
        except Exception as e:
            logger.error(f"ë‹¹ì„ ì ì •ë³´ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
    
    def _parse_pledge_element(self, element) -> Optional[Dict[str, Any]]:
        """ê³µì•½ ì •ë³´ íŒŒì‹±"""
        try:
            # ì‹¤ì œ HTML êµ¬ì¡°ì— ë”°ë¼ êµ¬í˜„ í•„ìš”
            title = element.find('h3', class_='pledge-title')
            content = element.find('div', class_='pledge-content')
            category = element.find('span', class_='pledge-category')
            
            if not (title and content):
                return None
            
            return {
                "title": title.text.strip(),
                "content": content.text.strip(),
                "category": category.text.strip() if category else "ê¸°íƒ€",
                "parsed_date": datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"ê³µì•½ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
    
    def save_collected_data(self, filename: Optional[str] = None) -> str:
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"nec_8th_local_election_pledges_{timestamp}.json"
        
        filepath = f"/Users/hopidaay/newsbot-kr/backend/election_data/{filename}"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        import os
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        # ë°ì´í„° ì €ì¥
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.collected_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ìˆ˜ì§‘ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")
        return filepath

def create_sample_data():
    """ì‹¤ì œ ìˆ˜ì§‘ ì „ ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    sample_data = {
        "election_info": {
            "election_name": "ì œ8íšŒ ì „êµ­ë™ì‹œì§€ë°©ì„ ê±°",
            "election_date": "2022-06-01",
            "election_code": "20220601"
        },
        "collection_date": datetime.now().isoformat(),
        "winners_data": {
            "ê´‘ì—­ë‹¨ì²´ì¥": {
                "position_type": "ê´‘ì—­ë‹¨ì²´ì¥",
                "total_winners": 17,
                "winners": {
                    "seoul_mayor": {
                        "name": "ì˜¤ì„¸í›ˆ",
                        "party": "êµ­ë¯¼ì˜í˜",
                        "region": "ì„œìš¸íŠ¹ë³„ì‹œ",
                        "position_type": "ê´‘ì—­ë‹¨ì²´ì¥",
                        "pledges": [
                            {
                                "title": "ì„œìš¸ ì²­ë…„ì£¼íƒ 10ë§Œí˜¸ ê³µê¸‰",
                                "content": "ì²­ë…„ì¸µì˜ ì£¼ê±° ë¶€ë‹´ ì™„í™”ë¥¼ ìœ„í•´ 10ë§Œí˜¸ ê·œëª¨ì˜ ì²­ë…„ ì „ìš© ì£¼íƒì„ ê³µê¸‰í•˜ê² ìŠµë‹ˆë‹¤.",
                                "category": "ì£¼ê±°ì •ì±…"
                            },
                            {
                                "title": "ì§€í•˜ì²  ì‹¬ì•¼ë²„ìŠ¤ ìš´í–‰ í™•ëŒ€",
                                "content": "ì‹œë¯¼ë“¤ì˜ ì•¼ê°„ êµí†µí¸ì˜ë¥¼ ìœ„í•´ ì‹¬ì•¼ë²„ìŠ¤ ë…¸ì„ ì„ í™•ëŒ€ ìš´ì˜í•˜ê² ìŠµë‹ˆë‹¤.",
                                "category": "êµí†µì •ì±…"
                            }
                        ],
                        "pledge_count": 2
                    }
                }
            }
        },
        "statistics": {
            "total_winners": 1,
            "total_pledges": 2,
            "by_position": {
                "ê´‘ì—­ë‹¨ì²´ì¥": {"winners": 1, "total_pledges": 2}
            }
        }
    }
    
    return sample_data

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ—³ï¸ ì¤‘ì•™ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒ 8íšŒ ì§€ë°©ì„ ê±° ê³µì•½ ìˆ˜ì§‘ê¸°")
    print("=" * 60)
    
    # ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
    scraper = NECPolicyScraper()
    
    try:
        # ì‹¤ì œ ìˆ˜ì§‘ ì‹œë„
        print("ğŸ” ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì‹œë„ ì¤‘...")
        collected_data = scraper.collect_all_winners_pledges()
        
        if "error" in collected_data:
            print(f"âŒ ì‹¤ì œ ìˆ˜ì§‘ ì‹¤íŒ¨: {collected_data['error']}")
            print("ğŸ“‹ ìƒ˜í”Œ ë°ì´í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            collected_data = create_sample_data()
        
        # ë°ì´í„° ì €ì¥
        saved_file = scraper.save_collected_data()
        
        print("\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:")
        print(f"  ì´ ë‹¹ì„ ì: {collected_data['statistics']['total_winners']}ëª…")
        print(f"  ì´ ê³µì•½: {collected_data['statistics']['total_pledges']}ê°œ")
        print(f"  ì €ì¥ íŒŒì¼: {saved_file}")
        
        return collected_data
        
    except Exception as e:
        logger.error(f"ë©”ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print(f"âŒ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return None

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    main()
