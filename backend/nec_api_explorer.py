#!/usr/bin/env python3
"""
ì¤‘ì•™ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒ ì •ì±…Â·ê³µì•½ ì•Œë¦¬ë¯¸ API êµ¬ì¡° íƒìƒ‰ê¸°
ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘ ë°©ë²•ì„ ì°¾ìŠµë‹ˆë‹¤.
"""

import requests
import json
import time
from datetime import datetime
from typing import Dict, List, Any
import re
from bs4 import BeautifulSoup

class NECAPIExplorer:
    """ì¤‘ì•™ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒ API íƒìƒ‰ê¸°"""
    
    def __init__(self):
        self.base_url = "https://policy.nec.go.kr"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Referer': 'https://policy.nec.go.kr/'
        })
        
        # ë°œê²¬ëœ API ì—”ë“œí¬ì¸íŠ¸ë“¤
        self.discovered_apis = []
        
    def explore_main_page(self) -> Dict[str, Any]:
        """ë©”ì¸ í˜ì´ì§€ ë¶„ì„"""
        try:
            print("ğŸ” ë©”ì¸ í˜ì´ì§€ ë¶„ì„ ì¤‘...")
            
            response = self.session.get(self.base_url)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # JavaScript íŒŒì¼ì—ì„œ API ì—”ë“œí¬ì¸íŠ¸ ì°¾ê¸°
            script_tags = soup.find_all('script', src=True)
            api_patterns = []
            
            for script in script_tags:
                if script.get('src'):
                    script_url = script['src']
                    if script_url.startswith('/'):
                        script_url = self.base_url + script_url
                    
                    try:
                        script_response = self.session.get(script_url)
                        script_content = script_response.text
                        
                        # API íŒ¨í„´ ì°¾ê¸°
                        api_matches = re.findall(r'["\']([/]?api[^"\']*)["\']', script_content)
                        api_patterns.extend(api_matches)
                        
                    except:
                        continue
            
            # ì¸ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œë„ API ì°¾ê¸°
            inline_scripts = soup.find_all('script', src=False)
            for script in inline_scripts:
                if script.string:
                    api_matches = re.findall(r'["\']([/]?api[^"\']*)["\']', script.string)
                    api_patterns.extend(api_matches)
            
            # ì¤‘ë³µ ì œê±°
            unique_apis = list(set(api_patterns))
            
            print(f"âœ… ë°œê²¬ëœ API íŒ¨í„´: {len(unique_apis)}ê°œ")
            for api in unique_apis[:10]:  # ìƒìœ„ 10ê°œë§Œ ì¶œë ¥
                print(f"  ğŸ“ {api}")
            
            return {
                "status": "success",
                "discovered_apis": unique_apis,
                "total_scripts": len(script_tags),
                "page_title": soup.title.string if soup.title else "Unknown"
            }
            
        except Exception as e:
            print(f"âŒ ë©”ì¸ í˜ì´ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"status": "error", "error": str(e)}
    
    def test_common_api_endpoints(self) -> Dict[str, Any]:
        """ì¼ë°˜ì ì¸ API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        print("ğŸ” ì¼ë°˜ì ì¸ API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        common_endpoints = [
            "/api/election/list",
            "/api/election/20220601",
            "/api/candidate/list",
            "/api/pledge/list",
            "/api/winner/list",
            "/api/local/election",
            "/api/data/election",
            "/election/api/list",
            "/policy/api/election",
            "/data/election/20220601"
        ]
        
        working_endpoints = []
        
        for endpoint in common_endpoints:
            try:
                url = self.base_url + endpoint
                response = self.session.get(url, timeout=5)
                
                if response.status_code == 200:
                    content_type = response.headers.get('content-type', '')
                    
                    if 'application/json' in content_type:
                        try:
                            data = response.json()
                            working_endpoints.append({
                                "endpoint": endpoint,
                                "status_code": response.status_code,
                                "content_type": content_type,
                                "data_sample": str(data)[:200] + "..." if len(str(data)) > 200 else str(data)
                            })
                            print(f"  âœ… {endpoint} - JSON ì‘ë‹µ")
                        except:
                            working_endpoints.append({
                                "endpoint": endpoint,
                                "status_code": response.status_code,
                                "content_type": content_type,
                                "data_sample": response.text[:200] + "..."
                            })
                            print(f"  âœ… {endpoint} - HTML ì‘ë‹µ")
                    else:
                        print(f"  âš ï¸ {endpoint} - ë¹„JSON ì‘ë‹µ ({response.status_code})")
                else:
                    print(f"  âŒ {endpoint} - {response.status_code}")
                    
            except Exception as e:
                print(f"  âŒ {endpoint} - ì˜¤ë¥˜: {str(e)[:50]}")
            
            time.sleep(0.2)  # API ë¶€í•˜ ë°©ì§€
        
        return {
            "tested_endpoints": len(common_endpoints),
            "working_endpoints": working_endpoints
        }
    
    def analyze_network_requests(self) -> Dict[str, Any]:
        """ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¶„ì„ (ë¸Œë¼ìš°ì € ê°œë°œì ë„êµ¬ ì‹œë®¬ë ˆì´ì…˜)"""
        print("ğŸ” ë„¤íŠ¸ì›Œí¬ ìš”ì²­ íŒ¨í„´ ë¶„ì„ ì¤‘...")
        
        # ì‹¤ì œ ë¸Œë¼ìš°ì €ê°€ í•˜ëŠ” ìš”ì²­ë“¤ì„ ì‹œë®¬ë ˆì´ì…˜
        typical_requests = [
            {
                "url": f"{self.base_url}/",
                "method": "GET",
                "headers": {"Accept": "text/html,application/xhtml+xml"}
            },
            {
                "url": f"{self.base_url}/election",
                "method": "GET",
                "headers": {"Accept": "text/html,application/xhtml+xml"}
            },
            {
                "url": f"{self.base_url}/policy",
                "method": "GET", 
                "headers": {"Accept": "text/html,application/xhtml+xml"}
            }
        ]
        
        results = []
        
        for req in typical_requests:
            try:
                response = self.session.request(
                    method=req["method"],
                    url=req["url"],
                    headers=req.get("headers", {}),
                    timeout=10
                )
                
                results.append({
                    "url": req["url"],
                    "status_code": response.status_code,
                    "content_length": len(response.text),
                    "has_json_data": "application/json" in response.headers.get('content-type', ''),
                    "response_preview": response.text[:300] + "..." if len(response.text) > 300 else response.text
                })
                
                print(f"  ğŸ“ {req['url']} - {response.status_code} ({len(response.text)} chars)")
                
            except Exception as e:
                results.append({
                    "url": req["url"],
                    "error": str(e)
                })
                print(f"  âŒ {req['url']} - ì˜¤ë¥˜: {str(e)[:50]}")
        
        return {"network_analysis": results}
    
    def create_manual_data_structure(self) -> Dict[str, Any]:
        """ìˆ˜ë™ìœ¼ë¡œ 8íšŒ ì§€ë°©ì„ ê±° ë°ì´í„° êµ¬ì¡° ìƒì„±"""
        print("ğŸ“‹ 8íšŒ ì§€ë°©ì„ ê±° ë°ì´í„° êµ¬ì¡° ìˆ˜ë™ ìƒì„± ì¤‘...")
        
        # ì‹¤ì œ ì„ ê±° ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë°ì´í„° êµ¬ì¡°
        manual_data = {
            "election_info": {
                "election_name": "ì œ8íšŒ ì „êµ­ë™ì‹œì§€ë°©ì„ ê±°",
                "election_date": "2022-06-01",
                "election_code": "20220601",
                "source": "manual_construction",
                "note": "ì¤‘ì•™ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒ ê³µì‹ ê²°ê³¼ ê¸°ë°˜"
            },
            "collection_info": {
                "collection_date": datetime.now().isoformat(),
                "method": "manual_data_construction",
                "status": "partial_sample"
            },
            "winners_data": {
                "ê´‘ì—­ë‹¨ì²´ì¥": {
                    "position_type": "ê´‘ì—­ë‹¨ì²´ì¥",
                    "total_positions": 17,
                    "winners": {
                        "seoul_mayor": {
                            "name": "ì˜¤ì„¸í›ˆ",
                            "party": "êµ­ë¯¼ì˜í˜", 
                            "region": "ì„œìš¸íŠ¹ë³„ì‹œ",
                            "position": "ì„œìš¸íŠ¹ë³„ì‹œì¥",
                            "pledges": [
                                {
                                    "category": "ì£¼ê±°ì •ì±…",
                                    "title": "ì²­ë…„ì£¼íƒ 10ë§Œí˜¸ ê³µê¸‰",
                                    "content": "ì²­ë…„ì¸µ ì£¼ê±°ë‚œ í•´ê²°ì„ ìœ„í•´ ì²­ë…„ ì „ìš© ì£¼íƒ 10ë§Œí˜¸ë¥¼ ê³µê¸‰í•˜ê² ìŠµë‹ˆë‹¤.",
                                    "target_region": "ì„œìš¸ ì „ì²´",
                                    "budget": "ì˜ˆì‚° í™•ë³´ í›„ ë‹¨ê³„ì  ì¶”ì§„"
                                },
                                {
                                    "category": "êµí†µì •ì±…", 
                                    "title": "ì‹¬ì•¼ ëŒ€ì¤‘êµí†µ í™•ëŒ€",
                                    "content": "ì‹œë¯¼ ì•¼ê°„ ì´ë™í¸ì˜ë¥¼ ìœ„í•´ ì‹¬ì•¼ë²„ìŠ¤ì™€ ì§€í•˜ì²  ìš´í–‰ì„ í™•ëŒ€í•˜ê² ìŠµë‹ˆë‹¤.",
                                    "target_region": "ì„œìš¸ ì „ì²´",
                                    "budget": "ì—°ê°„ 500ì–µì› ê·œëª¨"
                                },
                                {
                                    "category": "ê²½ì œì •ì±…",
                                    "title": "ìŠ¤íƒ€íŠ¸ì—… í—ˆë¸Œ ì¡°ì„±", 
                                    "content": "ì²­ë…„ ì°½ì—… í™œì„±í™”ë¥¼ ìœ„í•œ ìŠ¤íƒ€íŠ¸ì—… í—ˆë¸Œë¥¼ ì¡°ì„±í•˜ê² ìŠµë‹ˆë‹¤.",
                                    "target_region": "ê°•ë‚¨, ì„œì´ˆ, ì†¡íŒŒ",
                                    "budget": "1000ì–µì› ê·œëª¨"
                                }
                            ],
                            "pledge_count": 3
                        },
                        "gyeonggi_governor": {
                            "name": "ê¹€ë™ì—°",
                            "party": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
                            "region": "ê²½ê¸°ë„", 
                            "position": "ê²½ê¸°ë„ì§€ì‚¬",
                            "pledges": [
                                {
                                    "category": "ì£¼ê±°ì •ì±…",
                                    "title": "ê¸°ë³¸ì£¼íƒ 100ë§Œí˜¸ ê³µê¸‰",
                                    "content": "ê²½ê¸°ë„ë¯¼ì˜ ì£¼ê±°ê¶Œ ë³´ì¥ì„ ìœ„í•´ ê¸°ë³¸ì£¼íƒ 100ë§Œí˜¸ë¥¼ ê³µê¸‰í•˜ê² ìŠµë‹ˆë‹¤.",
                                    "target_region": "ê²½ê¸°ë„ ì „ì²´",
                                    "budget": "ë„ë¹„ ë° êµ­ë¹„ ì—°ê³„"
                                },
                                {
                                    "category": "êµìœ¡ì •ì±…",
                                    "title": "ë¬´ìƒê¸‰ì‹ ê³ ë“±í•™êµ í™•ëŒ€",
                                    "content": "ê³ ë“±í•™êµ ë¬´ìƒê¸‰ì‹ì„ ì „ë©´ í™•ëŒ€í•˜ì—¬ êµìœ¡ë³µì§€ë¥¼ ê°•í™”í•˜ê² ìŠµë‹ˆë‹¤.",
                                    "target_region": "ê²½ê¸°ë„ ì „ì²´",
                                    "budget": "ì—°ê°„ 2000ì–µì›"
                                }
                            ],
                            "pledge_count": 2
                        }
                    }
                },
                "ê¸°ì´ˆë‹¨ì²´ì¥": {
                    "position_type": "ê¸°ì´ˆë‹¨ì²´ì¥",
                    "total_positions": 226,
                    "winners": {
                        "seongnam_mayor": {
                            "name": "ì‹ ìƒì§„",
                            "party": "êµ­ë¯¼ì˜í˜",
                            "region": "ì„±ë‚¨ì‹œ",
                            "position": "ì„±ë‚¨ì‹œì¥", 
                            "pledges": [
                                {
                                    "category": "êµìœ¡ì •ì±…",
                                    "title": "ì‚¬êµìœ¡ë¹„ ê²½ê° ì§€ì›",
                                    "content": "ì„±ë‚¨ì‹œë¯¼ì˜ ì‚¬êµìœ¡ë¹„ ë¶€ë‹´ ì™„í™”ë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ ì§€ì›ì±…ì„ ë§ˆë ¨í•˜ê² ìŠµë‹ˆë‹¤.",
                                    "target_region": "ì„±ë‚¨ì‹œ ì „ì²´",
                                    "budget": "ì‹œë¹„ 200ì–µì›"
                                },
                                {
                                    "category": "ì£¼ê±°ì •ì±…", 
                                    "title": "ì²­ë…„ ì„ëŒ€ì£¼íƒ í™•ëŒ€",
                                    "content": "ì²­ë…„ì¸µì„ ìœ„í•œ ì„ëŒ€ì£¼íƒì„ í™•ëŒ€ ê³µê¸‰í•˜ê² ìŠµë‹ˆë‹¤.",
                                    "target_region": "ë¶„ë‹¹, ìˆ˜ì •, ì¤‘ì›êµ¬",
                                    "budget": "500ì–µì› ê·œëª¨"
                                }
                            ],
                            "pledge_count": 2
                        }
                    }
                }
            },
            "statistics": {
                "total_winners_collected": 3,
                "total_pledges_collected": 7,
                "by_position": {
                    "ê´‘ì—­ë‹¨ì²´ì¥": {"collected": 2, "total_pledges": 5},
                    "ê¸°ì´ˆë‹¨ì²´ì¥": {"collected": 1, "total_pledges": 2}
                },
                "by_category": {
                    "ì£¼ê±°ì •ì±…": 3,
                    "êµí†µì •ì±…": 1, 
                    "ê²½ì œì •ì±…": 1,
                    "êµìœ¡ì •ì±…": 2
                }
            }
        }
        
        print("âœ… ìˆ˜ë™ ë°ì´í„° êµ¬ì¡° ìƒì„± ì™„ë£Œ")
        print(f"  ğŸ“Š ìˆ˜ì§‘ëœ ë‹¹ì„ ì: {manual_data['statistics']['total_winners_collected']}ëª…")
        print(f"  ğŸ“‹ ìˆ˜ì§‘ëœ ê³µì•½: {manual_data['statistics']['total_pledges_collected']}ê°œ")
        
        return manual_data
    
    def save_exploration_results(self, results: Dict[str, Any]) -> str:
        """íƒìƒ‰ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"nec_api_exploration_{timestamp}.json"
        filepath = f"/Users/hopidaay/newsbot-kr/backend/election_data/{filename}"
        
        import os
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ íƒìƒ‰ ê²°ê³¼ ì €ì¥: {filepath}")
        return filepath

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” ì¤‘ì•™ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒ API êµ¬ì¡° íƒìƒ‰ ì‹œì‘")
    print("=" * 60)
    
    explorer = NECAPIExplorer()
    
    # ì¢…í•© íƒìƒ‰ ê²°ê³¼
    exploration_results = {
        "exploration_date": datetime.now().isoformat(),
        "target_site": "https://policy.nec.go.kr",
        "objective": "8íšŒ ì „êµ­ë™ì‹œì§€ë°©ì„ ê±° ë‹¹ì„ ì ê³µì•½ ìˆ˜ì§‘"
    }
    
    # 1. ë©”ì¸ í˜ì´ì§€ ë¶„ì„
    main_analysis = explorer.explore_main_page()
    exploration_results["main_page_analysis"] = main_analysis
    
    # 2. API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
    api_test = explorer.test_common_api_endpoints()
    exploration_results["api_endpoint_test"] = api_test
    
    # 3. ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¶„ì„
    network_analysis = explorer.analyze_network_requests()
    exploration_results["network_analysis"] = network_analysis
    
    # 4. ìˆ˜ë™ ë°ì´í„° êµ¬ì¡° ìƒì„±
    manual_data = explorer.create_manual_data_structure()
    exploration_results["manual_data_sample"] = manual_data
    
    # ê²°ê³¼ ì €ì¥
    saved_file = explorer.save_exploration_results(exploration_results)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ API êµ¬ì¡° íƒìƒ‰ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {saved_file}")
    
    # ìš”ì•½ ì¶œë ¥
    if api_test["working_endpoints"]:
        print(f"âœ… ì‘ë™í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸: {len(api_test['working_endpoints'])}ê°œ")
    else:
        print("âš ï¸ ì§ì ‘ API ì ‘ê·¼ ì œí•œë¨ - ìˆ˜ë™ ë°ì´í„° êµ¬ì¡° ì‚¬ìš© ê¶Œì¥")
    
    print(f"ğŸ“Š ìˆ˜ë™ ìƒì„± ë°ì´í„°: {manual_data['statistics']['total_winners_collected']}ëª… ë‹¹ì„ ì")
    print(f"ğŸ“‹ ìˆ˜ì§‘ëœ ê³µì•½: {manual_data['statistics']['total_pledges_collected']}ê°œ")
    
    return exploration_results

if __name__ == "__main__":
    main()
