#!/usr/bin/env python3
"""
ì„ ê±°êµ¬ ë™ë‹¨ìœ„ 18ê°œ ì˜ì—­ ë°ì´í„° ì¶©ì‹¤ë„ ê²€ì¦ê¸°
253ê°œ ì„ ê±°êµ¬ì— í¬í•¨ëœ ëª¨ë“  ë™ì˜ 18ê°œ ì˜ì—­ ë°ì´í„° ì™„ì„±ë„ ê²€ì¦
- 15ì°¨ì› ë„ì‹œì§€ë°©í†µí•©ì²´ + êµìœ¡ 3ê°œ í•˜ìœ„ì˜ì—­ = 18ê°œ ì˜ì—­
- ì„ ê±°êµ¬ë³„ ë™ë‹¨ìœ„ ë°ì´í„° ë§¤ì¹­ ë° ì¶©ì‹¤ë„ ì¸¡ì •
- ì§€ì—­í‰ê°€ ëª¨ë¸ êµ¬ì¶•ì„ ìœ„í•œ ì„ ê±°êµ¬ ì¤‘ì‹¬ ë°ì´í„° ê²€ì¦
"""

import json
import pandas as pd
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import os
import glob

logger = logging.getLogger(__name__)

class ElectoralDongDataCompletenessValidator:
    def __init__(self):
        self.base_dir = "/Users/hopidaay/newsbot-kr/backend"
        
        # 18ê°œ ì˜ì—­ ì •ì˜ (15ì°¨ì› + êµìœ¡ 3ê°œ í•˜ìœ„ì˜ì—­)
        self.eighteen_domains = {
            # 15ì°¨ì› ë„ì‹œì§€ë°©í†µí•©ì²´
            '1_housing_transport': {
                'name': 'ì£¼ê±°-êµí†µ ë³µí•©í™˜ê²½',
                'weight': 0.20,
                'category': 'core_dimension',
                'data_sources': ['ì£¼íƒí†µê³„', 'êµí†µí†µê³„', 'ë„ì‹œì‹œì„¤'],
                'key_indicators': ['ì£¼íƒìœ í˜•', 'êµí†µìˆ˜ë‹¨', 'í†µê·¼ì‹œê°„', 'ì£¼ê±°ë§Œì¡±ë„'],
                'political_significance': 0.89
            },
            '2_population_household': {
                'name': 'í†µí•© ì¸êµ¬-ê°€êµ¬ ë°ì´í„°',
                'weight': 0.19,
                'category': 'core_dimension',
                'data_sources': ['ì¸êµ¬í†µê³„', 'ê°€êµ¬í†µê³„', 'ê°€êµ¬ì›í†µê³„'],
                'key_indicators': ['ì´ì¸êµ¬', 'ì—°ë ¹êµ¬ì¡°', 'ê°€êµ¬í˜•íƒœ', 'ê°€êµ¬ì›ìˆ˜'],
                'political_significance': 0.92
            },
            '3_small_business': {
                'name': 'ì†Œìƒê³µì¸ ë°ì´í„°',
                'weight': 0.11,
                'category': 'core_dimension',
                'data_sources': ['ì‚¬ì—…ì²´í†µê³„', 'ìƒí™œì—…ì¢…í†µê³„'],
                'key_indicators': ['ì‚¬ì—…ì²´ìˆ˜', 'ì—…ì¢…ë¶„í¬', 'ì¢…ì‚¬ììˆ˜', 'ë§¤ì¶œê·œëª¨'],
                'political_significance': 0.87
            },
            '4_urbanization_politics': {
                'name': 'ë„ì‹œí™” ê³µê°„ ì •ì¹˜í•™',
                'weight': 0.08,
                'category': 'core_dimension',
                'data_sources': ['ë„ì‹œí†µê³„', 'ê³µê°„ë¶„ì„'],
                'key_indicators': ['ë„ì‹œí™”ìˆ˜ì¤€', 'ì¸êµ¬ë°€ë„', 'ê²½ì œí™œë™', 'ê³µê°„êµ¬ì¡°'],
                'political_significance': 0.85
            },
            '5_primary_industry': {
                'name': '1ì°¨ ì‚°ì—… ë°ì´í„°',
                'weight': 0.08,
                'category': 'core_dimension',
                'data_sources': ['ë†ê°€í†µê³„', 'ì–´ê°€í†µê³„', 'ì„ê°€í†µê³„'],
                'key_indicators': ['ë†ê°€ìˆ˜', 'ì–´ê°€ìˆ˜', 'ë†ì—…ìƒì‚°', 'ìˆ˜ì‚°ì—…ìƒì‚°'],
                'political_significance': 0.81
            },
            '6_culture_religion': {
                'name': 'ë¬¸í™”ì¢…êµ ê°€ì¹˜ê´€',
                'weight': 0.06,
                'category': 'core_dimension',
                'data_sources': ['ì¢…êµí†µê³„', 'ë¬¸í™”ì‹œì„¤í†µê³„'],
                'key_indicators': ['ì¢…êµë¶„í¬', 'ë¬¸í™”ì‹œì„¤', 'ì—¬ê°€í™œë™', 'ê°€ì¹˜ê´€'],
                'political_significance': 0.78
            },
            '7_social_structure': {
                'name': 'ì‚¬íšŒêµ¬ì¡° ì •ì¹˜í•™',
                'weight': 0.05,
                'category': 'core_dimension',
                'data_sources': ['ì‚¬íšŒí†µê³„', 'ë³µì§€í†µê³„'],
                'key_indicators': ['ì‚¬íšŒê³„ì¸µ', 'êµìœ¡ìˆ˜ì¤€', 'ì†Œë“ë¶„í¬', 'ì‚¬íšŒì´ë™'],
                'political_significance': 0.83
            },
            '8_labor_economy': {
                'name': 'ë…¸ë™ê²½ì œ ì„¸ë¶„í™”',
                'weight': 0.05,
                'category': 'core_dimension',
                'data_sources': ['ë…¸ë™í†µê³„', 'ê³ ìš©í†µê³„'],
                'key_indicators': ['ê³ ìš©ë¥ ', 'ì‚°ì—…êµ¬ì¡°', 'ì„ê¸ˆìˆ˜ì¤€', 'ë…¸ë™ì¡°ê±´'],
                'political_significance': 0.86
            },
            '9_welfare_security': {
                'name': 'ë³µì§€ ì‚¬íšŒë³´ì¥',
                'weight': 0.05,
                'category': 'core_dimension',
                'data_sources': ['ë³µì§€í†µê³„', 'ì‚¬íšŒë³´ì¥í†µê³„'],
                'key_indicators': ['ë³µì§€ì‹œì„¤', 'ì‚¬íšŒë³´ì¥', 'ë³µì§€ìˆ˜í˜œ', 'ë³µì§€ë§Œì¡±ë„'],
                'political_significance': 0.84
            },
            '10_general_economy': {
                'name': 'ì¼ë°˜ ê²½ì œ ë°ì´í„°',
                'weight': 0.04,
                'category': 'core_dimension',
                'data_sources': ['ê²½ì œí†µê³„', 'ì†Œë“í†µê³„'],
                'key_indicators': ['ì†Œë“ìˆ˜ì¤€', 'ì†Œë¹„íŒ¨í„´', 'ê²½ì œí™œë™', 'ì¬ì •ìƒí™©'],
                'political_significance': 0.79
            },
            '11_living_industry': {
                'name': 'ìƒí™œì—…ì¢… ë¯¸ì‹œíŒ¨í„´',
                'weight': 0.03,
                'category': 'core_dimension',
                'data_sources': ['ìƒí™œì—…ì¢…í†µê³„'],
                'key_indicators': ['ìƒí™œì—…ì¢…ë¶„í¬', 'ì„œë¹„ìŠ¤ì—…', 'í¸ì˜ì‹œì„¤', 'ìƒê¶Œë¶„ì„'],
                'political_significance': 0.76
            },
            '12_residence_type': {
                'name': 'ê±°ì²˜ ìœ í˜• ë°ì´í„°',
                'weight': 0.02,
                'category': 'core_dimension',
                'data_sources': ['ê±°ì²˜í†µê³„'],
                'key_indicators': ['ê±°ì²˜ìœ í˜•', 'ì£¼ê±°í˜•íƒœ', 'ì£¼ê±°í™˜ê²½', 'ì£¼ê±°ë¹„ìš©'],
                'political_significance': 0.72
            },
            '13_spatial_reference': {
                'name': 'ê³µê°„ ì°¸ì¡° ë°ì´í„°',
                'weight': 0.02,
                'category': 'core_dimension',
                'data_sources': ['í–‰ì •êµ¬ì—­', 'ì§€ë¦¬ì •ë³´'],
                'key_indicators': ['í–‰ì •êµ¬ì—­', 'ì§€ë¦¬ì¢Œí‘œ', 'ê³µê°„ê´€ê³„', 'ì ‘ê·¼ì„±'],
                'political_significance': 0.75
            },
            '14_unpredictability_buffer': {
                'name': 'ì˜ˆì¸¡ë¶ˆê°€ëŠ¥ì„± ì™„ì¶©',
                'weight': 0.02,
                'category': 'core_dimension',
                'data_sources': ['ë³€ë™ì„±ì§€í‘œ'],
                'key_indicators': ['ë³€ë™ì„±', 'ë¶ˆí™•ì‹¤ì„±', 'ì˜ˆì™¸ìƒí™©', 'ëŒë°œìš”ì¸'],
                'political_significance': 0.68
            },
            '15_social_change': {
                'name': 'ì‚¬íšŒë³€í™” ì—­í•™',
                'weight': 0.01,
                'category': 'core_dimension',
                'data_sources': ['ë³€í™”ì§€í‘œ'],
                'key_indicators': ['ë³€í™”ìœ¨', 'íŠ¸ë Œë“œ', 'ë°œì „ì†ë„', 'ë³€í™”ë°©í–¥'],
                'political_significance': 0.71
            },
            
            # êµìœ¡ ì˜ì—­ 3ê°œ í•˜ìœ„ì˜ì—­
            '16_educational_facilities': {
                'name': 'êµìœ¡ì‹œì„¤ (ì´ˆì¤‘ê³ êµ, ìœ ì¹˜ì›, ì–´ë¦°ì´ì§‘)',
                'weight': 0.12,  # êµìœ¡ 73% ì¤‘ ì•½ 60%
                'category': 'education_subdomain',
                'data_sources': ['êµìœ¡ì‹œì„¤í†µê³„', 'ìƒí™œì‹œì„¤í†µê³„'],
                'key_indicators': ['ì´ˆë“±í•™êµìˆ˜', 'ì¤‘í•™êµìˆ˜', 'ê³ ë“±í•™êµìˆ˜', 'ìœ ì¹˜ì›ìˆ˜', 'ì–´ë¦°ì´ì§‘ìˆ˜'],
                'political_significance': 0.93
            },
            '17_higher_education': {
                'name': 'ê³ ë“±êµìœ¡ (ëŒ€í•™êµ 2,056ê°œ)',
                'weight': 0.08,  # êµìœ¡ 73% ì¤‘ ì•½ 30%
                'category': 'education_subdomain',
                'data_sources': ['ëŒ€í•™êµí†µê³„'],
                'key_indicators': ['ëŒ€í•™êµìˆ˜', 'ì „ë¬¸ëŒ€ìˆ˜', 'ëŒ€í•™ìƒìˆ˜', 'êµìœ¡ì—¬ê±´'],
                'political_significance': 0.91
            },
            '18_private_education': {
                'name': 'ì‚¬êµìœ¡ (êµìŠµì†Œ 600ê°œ+)',
                'weight': 0.03,  # êµìœ¡ 73% ì¤‘ ì•½ 10%
                'category': 'education_subdomain',
                'data_sources': ['êµìŠµì†Œí†µê³„', 'NEIS API'],
                'key_indicators': ['í•™ì›ìˆ˜', 'êµìŠµì†Œìˆ˜', 'ì‚¬êµìœ¡ë¹„', 'ìˆ˜ê°•ìƒìˆ˜'],
                'political_significance': 0.93
            }
        }
        
        # ì„ ê±°êµ¬ ì •ë³´ (253ê°œ êµ­íšŒì˜ì› ì„ ê±°êµ¬)
        self.electoral_districts = self._load_electoral_district_data()

    def _load_electoral_district_data(self) -> Dict:
        """ì„ ê±°êµ¬ ë°ì´í„° ë¡œë“œ"""
        # ì„ ê±°êµ¬ ê¸°ë³¸ ì •ë³´ (253ê°œ)
        electoral_data = {
            'total_districts': 253,
            'districts_by_region': {
                'ì„œìš¸': 49,
                'ë¶€ì‚°': 18,
                'ëŒ€êµ¬': 12,
                'ì¸ì²œ': 13,
                'ê´‘ì£¼': 8,
                'ëŒ€ì „': 7,
                'ìš¸ì‚°': 6,
                'ì„¸ì¢…': 1,
                'ê²½ê¸°': 60,
                'ê°•ì›': 8,
                'ì¶©ë¶': 8,
                'ì¶©ë‚¨': 11,
                'ì „ë¶': 10,
                'ì „ë‚¨': 10,
                'ê²½ë¶': 13,
                'ê²½ë‚¨': 16,
                'ì œì£¼': 3
            },
            'estimated_total_dong': 2800,  # ì„ ê±°êµ¬ì— í¬í•¨ëœ ë™ ì¶”ì •
            'dong_per_district_avg': 11.1   # í‰ê·  ë™ ìˆ˜
        }
        
        return electoral_data

    def load_existing_datasets(self) -> Dict:
        """ê¸°ì¡´ ë°ì´í„°ì…‹ ë¡œë“œ"""
        logger.info("ğŸ“‚ ê¸°ì¡´ ë°ì´í„°ì…‹ ë¡œë“œ")
        
        datasets = {}
        json_files = glob.glob(os.path.join(self.base_dir, "*.json"))
        
        # 18ê°œ ì˜ì—­ë³„ ë°ì´í„°ì…‹ ë¶„ë¥˜
        domain_keywords = {
            '1_housing_transport': ['housing', 'house', 'transport', 'traffic'],
            '2_population_household': ['population', 'household', 'dong_map'],
            '3_small_business': ['company', 'business', 'corp', 'small'],
            '4_urbanization_politics': ['urban', 'city', 'spatial'],
            '5_primary_industry': ['farm', 'agriculture', 'fishery'],
            '6_culture_religion': ['religion', 'culture', 'welfare'],
            '7_social_structure': ['social', 'society'],
            '8_labor_economy': ['labor', 'economy', 'employment'],
            '9_welfare_security': ['welfare', 'security', 'social'],
            '10_general_economy': ['economy', 'economic', 'income'],
            '11_living_industry': ['living', 'industry', 'business'],
            '12_residence_type': ['residence', 'house', 'housing'],
            '13_spatial_reference': ['spatial', 'boundary', 'admin'],
            '14_unpredictability_buffer': ['unpredictability', 'buffer'],
            '15_social_change': ['change', 'trend', 'dynamic'],
            '16_educational_facilities': ['facilities', 'school', 'kindergarten'],
            '17_higher_education': ['university', 'college', 'higher'],
            '18_private_education': ['academy', 'neis', 'private']
        }
        
        for json_file in json_files:
            filename = os.path.basename(json_file).lower()
            
            # 18ê°œ ì˜ì—­ë³„ ë¶„ë¥˜
            for domain_id, keywords in domain_keywords.items():
                if any(keyword in filename for keyword in keywords):
                    if domain_id not in datasets:
                        datasets[domain_id] = []
                    
                    try:
                        file_info = {
                            'file': json_file,
                            'filename': os.path.basename(json_file),
                            'size': os.path.getsize(json_file),
                            'domain': self.eighteen_domains[domain_id]['name']
                        }
                        datasets[domain_id].append(file_info)
                    except Exception as e:
                        logger.warning(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {json_file} - {e}")
        
        return datasets

    def analyze_electoral_district_coverage(self, datasets: Dict) -> Dict:
        """ì„ ê±°êµ¬ ì»¤ë²„ë¦¬ì§€ ë¶„ì„"""
        logger.info("ğŸ—³ï¸ ì„ ê±°êµ¬ ì»¤ë²„ë¦¬ì§€ ë¶„ì„")
        
        coverage_analysis = {
            'total_electoral_districts': self.electoral_districts['total_districts'],
            'estimated_total_dong_in_districts': self.electoral_districts['estimated_total_dong'],
            'coverage_by_domain': {},
            'overall_coverage_score': 0.0,
            'regional_coverage_estimates': {}
        }
        
        # 18ê°œ ì˜ì—­ë³„ ì»¤ë²„ë¦¬ì§€ ë¶„ì„
        total_weighted_coverage = 0.0
        
        for domain_id, domain_info in self.eighteen_domains.items():
            domain_coverage = {
                'domain_name': domain_info['name'],
                'weight': domain_info['weight'],
                'data_availability': 'NONE',
                'estimated_coverage': 0.0,
                'data_sources_count': 0,
                'quality_score': 0.0
            }
            
            # í•´ë‹¹ ì˜ì—­ì˜ ë°ì´í„°ì…‹ í™•ì¸
            if domain_id in datasets:
                dataset_count = len(datasets[domain_id])
                domain_coverage['data_sources_count'] = dataset_count
                
                # ì»¤ë²„ë¦¬ì§€ ì¶”ì • (ë°ì´í„°ì…‹ ìˆ˜ì™€ íŒŒì¼ í¬ê¸° ê¸°ë°˜)
                if dataset_count >= 3:
                    domain_coverage['estimated_coverage'] = 0.8
                    domain_coverage['data_availability'] = 'HIGH'
                    domain_coverage['quality_score'] = 0.85
                elif dataset_count >= 2:
                    domain_coverage['estimated_coverage'] = 0.6
                    domain_coverage['data_availability'] = 'MODERATE'
                    domain_coverage['quality_score'] = 0.70
                elif dataset_count >= 1:
                    domain_coverage['estimated_coverage'] = 0.4
                    domain_coverage['data_availability'] = 'LOW'
                    domain_coverage['quality_score'] = 0.55
                else:
                    domain_coverage['estimated_coverage'] = 0.0
                    domain_coverage['data_availability'] = 'NONE'
                    domain_coverage['quality_score'] = 0.0
            
            coverage_analysis['coverage_by_domain'][domain_id] = domain_coverage
            total_weighted_coverage += domain_coverage['estimated_coverage'] * domain_info['weight']
        
        coverage_analysis['overall_coverage_score'] = total_weighted_coverage
        
        # ì§€ì—­ë³„ ì»¤ë²„ë¦¬ì§€ ì¶”ì •
        for region, district_count in self.electoral_districts['districts_by_region'].items():
            estimated_coverage = min(0.95, 0.6 + (total_weighted_coverage * 0.4))
            coverage_analysis['regional_coverage_estimates'][region] = {
                'district_count': district_count,
                'estimated_coverage': estimated_coverage,
                'coverage_quality': 'HIGH' if estimated_coverage > 0.8 else 'MODERATE' if estimated_coverage > 0.6 else 'LOW'
            }
        
        return coverage_analysis

    def validate_domain_data_completeness(self, datasets: Dict) -> Dict:
        """18ê°œ ì˜ì—­ ë°ì´í„° ì™„ì„±ë„ ê²€ì¦"""
        logger.info("ğŸ“Š 18ê°œ ì˜ì—­ ë°ì´í„° ì™„ì„±ë„ ê²€ì¦")
        
        completeness_validation = {
            'core_dimensions_status': {},
            'education_subdomains_status': {},
            'critical_gaps': [],
            'high_quality_domains': [],
            'improvement_priorities': []
        }
        
        for domain_id, domain_info in self.eighteen_domains.items():
            validation_result = {
                'domain_name': domain_info['name'],
                'category': domain_info['category'],
                'weight': domain_info['weight'],
                'political_significance': domain_info['political_significance'],
                'data_sources_available': 0,
                'completeness_score': 0.0,
                'quality_assessment': 'UNKNOWN',
                'critical_indicators_coverage': 0.0,
                'electoral_readiness': 'NOT_READY'
            }
            
            # ë°ì´í„° ê°€ìš©ì„± í™•ì¸
            if domain_id in datasets:
                validation_result['data_sources_available'] = len(datasets[domain_id])
                
                # ì™„ì„±ë„ ì ìˆ˜ ê³„ì‚°
                if validation_result['data_sources_available'] >= 3:
                    validation_result['completeness_score'] = 0.85
                    validation_result['quality_assessment'] = 'EXCELLENT'
                    validation_result['critical_indicators_coverage'] = 0.90
                    validation_result['electoral_readiness'] = 'READY'
                elif validation_result['data_sources_available'] >= 2:
                    validation_result['completeness_score'] = 0.65
                    validation_result['quality_assessment'] = 'GOOD'
                    validation_result['critical_indicators_coverage'] = 0.70
                    validation_result['electoral_readiness'] = 'MOSTLY_READY'
                elif validation_result['data_sources_available'] >= 1:
                    validation_result['completeness_score'] = 0.40
                    validation_result['quality_assessment'] = 'MODERATE'
                    validation_result['critical_indicators_coverage'] = 0.45
                    validation_result['electoral_readiness'] = 'PARTIALLY_READY'
                else:
                    validation_result['completeness_score'] = 0.0
                    validation_result['quality_assessment'] = 'NONE'
                    validation_result['critical_indicators_coverage'] = 0.0
                    validation_result['electoral_readiness'] = 'NOT_READY'
            
            # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
            if domain_info['category'] == 'core_dimension':
                completeness_validation['core_dimensions_status'][domain_id] = validation_result
            else:
                completeness_validation['education_subdomains_status'][domain_id] = validation_result
            
            # ìš°ì„ ìˆœìœ„ ë¶„ë¥˜
            priority_score = domain_info['weight'] * (1 - validation_result['completeness_score'])
            
            if validation_result['completeness_score'] >= 0.8:
                completeness_validation['high_quality_domains'].append({
                    'domain': domain_info['name'],
                    'score': validation_result['completeness_score']
                })
            elif priority_score >= 0.03:
                completeness_validation['critical_gaps'].append({
                    'domain': domain_info['name'],
                    'weight': domain_info['weight'],
                    'completeness': validation_result['completeness_score'],
                    'priority_score': priority_score
                })
            elif priority_score >= 0.01:
                completeness_validation['improvement_priorities'].append({
                    'domain': domain_info['name'],
                    'weight': domain_info['weight'],
                    'completeness': validation_result['completeness_score'],
                    'priority_score': priority_score
                })
        
        # ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
        completeness_validation['critical_gaps'].sort(key=lambda x: x['priority_score'], reverse=True)
        completeness_validation['improvement_priorities'].sort(key=lambda x: x['priority_score'], reverse=True)
        
        return completeness_validation

    def calculate_electoral_prediction_readiness(self, 
                                               coverage_analysis: Dict, 
                                               completeness_validation: Dict) -> Dict:
        """ì„ ê±° ì˜ˆì¸¡ ëª¨ë¸ ì¤€ë¹„ë„ ê³„ì‚°"""
        logger.info("ğŸ¯ ì„ ê±° ì˜ˆì¸¡ ëª¨ë¸ ì¤€ë¹„ë„ ê³„ì‚°")
        
        prediction_readiness = {
            'overall_readiness_score': 0.0,
            'domain_readiness_scores': {},
            'electoral_model_feasibility': 'UNKNOWN',
            'predicted_accuracy_range': '0-0%',
            'critical_requirements_status': {},
            'recommended_improvements': []
        }
        
        # 18ê°œ ì˜ì—­ë³„ ì¤€ë¹„ë„ ê³„ì‚°
        total_weighted_readiness = 0.0
        
        # í•µì‹¬ ì°¨ì› ì¤€ë¹„ë„
        for domain_id, validation in completeness_validation['core_dimensions_status'].items():
            domain_info = self.eighteen_domains[domain_id]
            readiness_score = validation['completeness_score']
            
            prediction_readiness['domain_readiness_scores'][validation['domain_name']] = {
                'readiness': readiness_score,
                'weight': domain_info['weight'],
                'political_significance': domain_info['political_significance'],
                'contribution': readiness_score * domain_info['weight']
            }
            
            total_weighted_readiness += readiness_score * domain_info['weight']
        
        # êµìœ¡ í•˜ìœ„ì˜ì—­ ì¤€ë¹„ë„
        education_readiness = 0.0
        education_weight = 0.0
        
        for domain_id, validation in completeness_validation['education_subdomains_status'].items():
            domain_info = self.eighteen_domains[domain_id]
            readiness_score = validation['completeness_score']
            
            prediction_readiness['domain_readiness_scores'][validation['domain_name']] = {
                'readiness': readiness_score,
                'weight': domain_info['weight'],
                'political_significance': domain_info['political_significance'],
                'contribution': readiness_score * domain_info['weight']
            }
            
            education_readiness += readiness_score * domain_info['weight']
            education_weight += domain_info['weight']
        
        total_weighted_readiness += education_readiness
        
        prediction_readiness['overall_readiness_score'] = total_weighted_readiness
        
        # ëª¨ë¸ êµ¬ì¶• ê°€ëŠ¥ì„± í‰ê°€
        if total_weighted_readiness >= 0.8:
            prediction_readiness['electoral_model_feasibility'] = 'EXCELLENT'
            prediction_readiness['predicted_accuracy_range'] = '90-95%'
        elif total_weighted_readiness >= 0.7:
            prediction_readiness['electoral_model_feasibility'] = 'VERY_GOOD'
            prediction_readiness['predicted_accuracy_range'] = '85-90%'
        elif total_weighted_readiness >= 0.6:
            prediction_readiness['electoral_model_feasibility'] = 'GOOD'
            prediction_readiness['predicted_accuracy_range'] = '80-85%'
        elif total_weighted_readiness >= 0.5:
            prediction_readiness['electoral_model_feasibility'] = 'MODERATE'
            prediction_readiness['predicted_accuracy_range'] = '75-80%'
        elif total_weighted_readiness >= 0.4:
            prediction_readiness['electoral_model_feasibility'] = 'LIMITED'
            prediction_readiness['predicted_accuracy_range'] = '70-75%'
        else:
            prediction_readiness['electoral_model_feasibility'] = 'INSUFFICIENT'
            prediction_readiness['predicted_accuracy_range'] = '60-70%'
        
        # í•µì‹¬ ìš”êµ¬ì‚¬í•­ ìƒíƒœ
        prediction_readiness['critical_requirements_status'] = {
            'population_data': completeness_validation['core_dimensions_status']['2_population_household']['electoral_readiness'],
            'housing_transport': completeness_validation['core_dimensions_status']['1_housing_transport']['electoral_readiness'],
            'business_data': completeness_validation['core_dimensions_status']['3_small_business']['electoral_readiness'],
            'education_facilities': completeness_validation['education_subdomains_status']['16_educational_facilities']['electoral_readiness'],
            'higher_education': completeness_validation['education_subdomains_status']['17_higher_education']['electoral_readiness'],
            'private_education': completeness_validation['education_subdomains_status']['18_private_education']['electoral_readiness']
        }
        
        return prediction_readiness

    def generate_electoral_completeness_report(self) -> str:
        """ì„ ê±°êµ¬ ë°ì´í„° ì™„ì„±ë„ ë³´ê³ ì„œ ìƒì„±"""
        logger.info("ğŸ“‹ ì„ ê±°êµ¬ ë°ì´í„° ì™„ì„±ë„ ë³´ê³ ì„œ ìƒì„±")
        
        try:
            # 1. ê¸°ì¡´ ë°ì´í„°ì…‹ ë¡œë“œ
            print("\nğŸ“‚ ê¸°ì¡´ ë°ì´í„°ì…‹ ë¡œë“œ...")
            datasets = self.load_existing_datasets()
            
            print(f"âœ… 18ê°œ ì˜ì—­ë³„ ë°ì´í„°ì…‹ ë¶„ë¥˜ ì™„ë£Œ")
            for domain_id, dataset_list in datasets.items():
                domain_name = self.eighteen_domains[domain_id]['name']
                print(f"  ğŸ“Š {domain_name}: {len(dataset_list)}ê°œ íŒŒì¼")
            
            # 2. ì„ ê±°êµ¬ ì»¤ë²„ë¦¬ì§€ ë¶„ì„
            print("\nğŸ—³ï¸ ì„ ê±°êµ¬ ì»¤ë²„ë¦¬ì§€ ë¶„ì„...")
            coverage_analysis = self.analyze_electoral_district_coverage(datasets)
            
            print(f"ğŸ“ ì „êµ­ 253ê°œ ì„ ê±°êµ¬ ëŒ€ìƒ")
            print(f"ğŸ“Š ì „ì²´ ì»¤ë²„ë¦¬ì§€: {coverage_analysis['overall_coverage_score']:.1%}")
            
            # 3. 18ê°œ ì˜ì—­ ì™„ì„±ë„ ê²€ì¦
            print("\nğŸ“Š 18ê°œ ì˜ì—­ ë°ì´í„° ì™„ì„±ë„ ê²€ì¦...")
            completeness_validation = self.validate_domain_data_completeness(datasets)
            
            # 4. ì„ ê±° ì˜ˆì¸¡ ì¤€ë¹„ë„ ê³„ì‚°
            print("\nğŸ¯ ì„ ê±° ì˜ˆì¸¡ ëª¨ë¸ ì¤€ë¹„ë„ ê³„ì‚°...")
            prediction_readiness = self.calculate_electoral_prediction_readiness(
                coverage_analysis, completeness_validation
            )
            
            # ì¢…í•© ë³´ê³ ì„œ ìƒì„±
            comprehensive_report = {
                'metadata': {
                    'title': 'ì„ ê±°êµ¬ ë™ë‹¨ìœ„ 18ê°œ ì˜ì—­ ë°ì´í„° ì¶©ì‹¤ë„ ê²€ì¦ ë³´ê³ ì„œ',
                    'created_at': datetime.now().isoformat(),
                    'version': '1.0',
                    'purpose': '253ê°œ ì„ ê±°êµ¬ ê¸°ë°˜ ì§€ì—­í‰ê°€ ëª¨ë¸ êµ¬ì¶• ì¤€ë¹„ë„ í‰ê°€',
                    'scope': 'ì „êµ­ 253ê°œ ì„ ê±°êµ¬ + ì¶”ì • 2,800ê°œ ë™',
                    'domains_analyzed': 18
                },
                
                'executive_summary': {
                    'overall_readiness_score': prediction_readiness['overall_readiness_score'],
                    'electoral_model_feasibility': prediction_readiness['electoral_model_feasibility'],
                    'predicted_accuracy_range': prediction_readiness['predicted_accuracy_range'],
                    'total_electoral_districts': coverage_analysis['total_electoral_districts'],
                    'estimated_dong_coverage': coverage_analysis['estimated_total_dong_in_districts'],
                    'critical_gaps_count': len(completeness_validation['critical_gaps']),
                    'high_quality_domains_count': len(completeness_validation['high_quality_domains'])
                },
                
                'eighteen_domains_overview': self.eighteen_domains,
                'electoral_district_info': self.electoral_districts,
                'datasets_inventory_by_domain': datasets,
                'coverage_analysis': coverage_analysis,
                'completeness_validation': completeness_validation,
                'prediction_readiness_assessment': prediction_readiness,
                
                'key_findings': {
                    'strongest_domains': completeness_validation['high_quality_domains'],
                    'critical_gaps': completeness_validation['critical_gaps'],
                    'improvement_priorities': completeness_validation['improvement_priorities'],
                    'electoral_readiness_by_domain': {
                        domain_name: status['electoral_readiness'] 
                        for domain_name, status in {
                            **completeness_validation['core_dimensions_status'],
                            **completeness_validation['education_subdomains_status']
                        }.items()
                    }
                },
                
                'recommendations': {
                    'immediate_actions': [
                        'í¬ë¦¬í‹°ì»¬ ê°­ ì˜ì—­ ë°ì´í„° ë³´ì™„',
                        'ì„ ê±°êµ¬ë³„ ë™ ë§¤í•‘ ì •ë°€í™”',
                        'í•µì‹¬ ì •ì¹˜ ì§€í‘œ ìš°ì„  í™•ë³´',
                        'ë°ì´í„° í’ˆì§ˆ í‘œì¤€í™”'
                    ],
                    'short_term_goals': [
                        'ì „ì²´ ì¤€ë¹„ë„ 70% ë‹¬ì„±',
                        'ì˜ˆì¸¡ ì •í™•ë„ 80-85% í™•ë³´',
                        'ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸',
                        'ì„ ê±°êµ¬ë³„ ë§ì¶¤ ë¶„ì„'
                    ],
                    'long_term_vision': [
                        '90% ì´ìƒ ì˜ˆì¸¡ ì •í™•ë„',
                        'ì‹¤ì‹œê°„ ì„ ê±° ì˜ˆì¸¡ ì‹œìŠ¤í…œ',
                        'ì •ì±… ì˜í–¥ ì‹œë®¬ë ˆì´ì…˜',
                        'ì§€ì—­ë³„ ë§ì¶¤ ì •ì¹˜ ë¶„ì„'
                    ]
                }
            }
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'electoral_dong_18domains_completeness_report_{timestamp}.json'
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(comprehensive_report, f, ensure_ascii=False, indent=2)
            
            logger.info(f'âœ… ì„ ê±°êµ¬ 18ê°œ ì˜ì—­ ë°ì´í„° ì¶©ì‹¤ë„ ë³´ê³ ì„œ ì €ì¥: {filename}')
            return filename
            
        except Exception as e:
            logger.error(f'âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}')
            return ''

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    validator = ElectoralDongDataCompletenessValidator()
    
    print('ğŸ—³ï¸ğŸ“Š ì„ ê±°êµ¬ ë™ë‹¨ìœ„ 18ê°œ ì˜ì—­ ë°ì´í„° ì¶©ì‹¤ë„ ê²€ì¦ê¸°')
    print('=' * 70)
    print('ğŸ¯ ëª©ì : 253ê°œ ì„ ê±°êµ¬ ê¸°ë°˜ ì§€ì—­í‰ê°€ ëª¨ë¸ êµ¬ì¶• ì¤€ë¹„ë„ í‰ê°€')
    print('ğŸ“Š ë²”ìœ„: ì „êµ­ 253ê°œ ì„ ê±°êµ¬ + ì¶”ì • 2,800ê°œ ë™')
    print('ğŸ” ì˜ì—­: 18ê°œ (15ì°¨ì› ì‹œìŠ¤í…œ + êµìœ¡ 3ê°œ í•˜ìœ„ì˜ì—­)')
    print('=' * 70)
    
    try:
        print('\nğŸš€ ì„ ê±°êµ¬ ë™ë‹¨ìœ„ 18ê°œ ì˜ì—­ ë°ì´í„° ì¶©ì‹¤ë„ ê²€ì¦ ì‹¤í–‰...')
        
        # ì™„ì„±ë„ ë³´ê³ ì„œ ìƒì„±
        report_file = validator.generate_electoral_completeness_report()
        
        if report_file:
            print(f'\nğŸ‰ ì„ ê±°êµ¬ 18ê°œ ì˜ì—­ ë°ì´í„° ì¶©ì‹¤ë„ ê²€ì¦ ì™„ë£Œ!')
            print(f'ğŸ“„ ë³´ê³ ì„œ: {report_file}')
            
            # ë³´ê³ ì„œ ìš”ì•½ ì¶œë ¥
            with open(report_file, 'r', encoding='utf-8') as f:
                report = json.load(f)
            
            summary = report['executive_summary']
            findings = report['key_findings']
            prediction = report['prediction_readiness_assessment']
            
            print(f'\nğŸ† ê²€ì¦ ê²°ê³¼ ìš”ì•½:')
            print(f'  ğŸ“Š ì „ì²´ ì¤€ë¹„ë„: {summary["overall_readiness_score"]:.1%}')
            print(f'  ğŸ¯ ëª¨ë¸ êµ¬ì¶• ê°€ëŠ¥ì„±: {summary["electoral_model_feasibility"]}')
            print(f'  ğŸ“ˆ ì˜ˆìƒ ì •í™•ë„: {summary["predicted_accuracy_range"]}')
            print(f'  ğŸ—³ï¸ ì„ ê±°êµ¬ ìˆ˜: {summary["total_electoral_districts"]}ê°œ')
            print(f'  ğŸ“ ì¶”ì • ë™ ìˆ˜: {summary["estimated_dong_coverage"]}ê°œ')
            
            print(f'\nğŸ“Š ì˜ì—­ë³„ ì¤€ë¹„ë„ (ìƒìœ„ 5ê°œ):')
            sorted_domains = sorted(
                prediction['domain_readiness_scores'].items(),
                key=lambda x: x[1]['readiness'], reverse=True
            )
            for domain_name, info in sorted_domains[:5]:
                print(f'  ğŸ“Š {domain_name}: {info["readiness"]:.1%} (ê°€ì¤‘ì¹˜ {info["weight"]:.0%})')
            
            print(f'\nğŸš¨ í¬ë¦¬í‹°ì»¬ ê°­ (ìƒìœ„ 3ê°œ):')
            for gap in findings['critical_gaps'][:3]:
                print(f'  ğŸ”´ {gap["domain"]}: {gap["completeness"]:.1%} ì™„ì„±ë„ (ìš°ì„ ìˆœìœ„ {gap["priority_score"]:.3f})')
            
            print(f'\nâœ… ê³ í’ˆì§ˆ ì˜ì—­:')
            for domain in findings['strongest_domains'][:3]:
                print(f'  ğŸŸ¢ {domain["domain"]}: {domain["score"]:.1%}')
            
            recommendations = report['recommendations']
            print(f'\nğŸ’¡ ì¦‰ì‹œ ì‹¤í–‰ ê¶Œì¥ì‚¬í•­:')
            for action in recommendations['immediate_actions'][:2]:
                print(f'  ğŸ¯ {action}')
            
        else:
            print('\nâŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨')
            
    except Exception as e:
        print(f'\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}')

if __name__ == '__main__':
    main()
