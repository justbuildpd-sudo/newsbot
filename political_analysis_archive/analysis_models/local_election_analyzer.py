#!/usr/bin/env python3
"""
ì§€ë°©ì„ ê±° ì„¸ë°€ ë¶„ì„ ì‹œìŠ¤í…œ
í–‰ì •ë™ ë‹¨ìœ„ê¹Œì§€ì˜ ë‹¤ì¸µ ì„ ê±° ì˜ˆì¸¡ ì‹œìŠ¤í…œ
"""

import json
import xml.etree.ElementTree as ET
import requests
import logging
from datetime import datetime
from typing import Dict, List, Optional
import pandas as pd
from pathlib import Path

logger = logging.getLogger(__name__)

class LocalElectionAnalyzer:
    def __init__(self):
        self.kosis_api_key = "ZDkwNzNhY2Y4YTg3NjdlNWEyNjg0YmM1NDFlMmFjNmU="
        
        # ì§€ë°©ì„ ê±° êµ¬ì¡° (5ì¸µ êµ¬ì¡°)
        self.election_structure = {
            # 1ì¸µ: ê´‘ì—­ë‹¨ì²´ì¥ (17ê°œ)
            'metropolitan_mayor': {
                'count': 17,
                'positions': ['ì‹œë„ì§€ì‚¬', 'ì‹œì¥', 'ë„ì§€ì‚¬'],
                'election_cycle': 4,
                'description': 'ê´‘ì—­ìì¹˜ë‹¨ì²´ì¥'
            },
            
            # 2ì¸µ: ê¸°ì´ˆë‹¨ì²´ì¥ (226ê°œ)
            'local_mayor': {
                'count': 226,
                'positions': ['ì‹œì¥', 'êµ°ìˆ˜', 'êµ¬ì²­ì¥'],
                'election_cycle': 4,
                'description': 'ê¸°ì´ˆìì¹˜ë‹¨ì²´ì¥'
            },
            
            # 3ì¸µ: ê´‘ì—­ì˜ì› (824ì„)
            'metropolitan_council': {
                'count': 824,
                'positions': ['ì‹œë„ì˜ì›'],
                'election_cycle': 4,
                'description': 'ê´‘ì—­ì˜íšŒì˜ì›'
            },
            
            # 4ì¸µ: ê¸°ì´ˆì˜ì› (2,898ì„)
            'local_council': {
                'count': 2898,
                'positions': ['ì‹œì˜ì›', 'êµ°ì˜ì›', 'êµ¬ì˜ì›'],
                'election_cycle': 4,
                'description': 'ê¸°ì´ˆì˜íšŒì˜ì›'
            },
            
            # 5ì¸µ: êµìœ¡ê° (17ëª…)
            'education_superintendent': {
                'count': 17,
                'positions': ['êµìœ¡ê°'],
                'election_cycle': 4,
                'description': 'êµìœ¡ê°'
            }
        }
        
        # í–‰ì •êµ¬ì—­ ì²´ê³„ (5ë‹¨ê³„)
        self.administrative_hierarchy = {
            'level_1': {'name': 'ì‹œë„', 'count': 17, 'examples': ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ê²½ê¸°ë„']},
            'level_2': {'name': 'ì‹œêµ°êµ¬', 'count': 226, 'examples': ['ì¢…ë¡œêµ¬', 'ìˆ˜ì›ì‹œ', 'í™”ì„±ì‹œ']},
            'level_3': {'name': 'ìë©´ë™', 'count': 3497, 'examples': ['ì²­ìš´íš¨ìë™', 'íŒ”ë‹¬êµ¬', 'ë´‰ë‹´ì']},
            'level_4': {'name': 'ë¦¬', 'count': 40000, 'examples': ['ì²­ìš´ë™', 'íš¨ìë™', 'ì‹ ë´‰ë¦¬']},
            'level_5': {'name': 'í†µë°˜', 'count': 100000, 'examples': ['1í†µ', '2ë°˜', '3ì¡°']}
        }
        
        # ìˆ˜ì§‘í•  ì„¸ë°€ ë°ì´í„°
        self.granular_data_targets = {
            'demographic': [
                'ì—°ë ¹ë³„ ì¸êµ¬êµ¬ì¡°', 'ì„±ë³„ ì¸êµ¬', 'ê°€êµ¬êµ¬ì„±', 'êµìœ¡ìˆ˜ì¤€',
                'ì§ì—…ë¶„í¬', 'ì†Œë“ìˆ˜ì¤€', 'ê±°ì£¼ê¸°ê°„', 'ì¶œìƒì§€ì—­'
            ],
            'economic': [
                'ì§€ì—­ë‚´ì´ìƒì‚°', 'ì‚¬ì—…ì²´ìˆ˜', 'ì¢…ì‚¬ììˆ˜', 'í‰ê· ì„ê¸ˆ',
                'ì‹¤ì—…ë¥ ', 'ê³ ìš©ë¥ ', 'ì°½ì—…ë¥ ', 'íì—…ë¥ '
            ],
            'social': [
                'ë³µì§€ì‹œì„¤', 'êµìœ¡ì‹œì„¤', 'ì˜ë£Œì‹œì„¤', 'ë¬¸í™”ì‹œì„¤',
                'êµí†µì ‘ê·¼ì„±', 'ì£¼íƒê°€ê²©', 'ë²”ì£„ìœ¨', 'í™˜ê²½ì§€ìˆ˜'
            ],
            'political': [
                'ìœ ê¶Œììˆ˜', 'íˆ¬í‘œìœ¨', 'ì •ë‹¹ë“í‘œìœ¨', 'í›„ë³´ììˆ˜',
                'ì„ ê±°ë¹„ìš©', 'ì •ì¹˜ì°¸ì—¬ë„', 'ì‹œë¯¼ë‹¨ì²´í™œë™', 'ì–¸ë¡ ë…¸ì¶œ'
            ]
        }

    def analyze_local_election_structure(self) -> Dict:
        """ì§€ë°©ì„ ê±° êµ¬ì¡° ìƒì„¸ ë¶„ì„"""
        logger.info("ğŸ›ï¸ ì§€ë°©ì„ ê±° êµ¬ì¡° ë¶„ì„ ì‹œì‘")
        
        analysis = {
            'total_elected_positions': 0,
            'election_levels': {},
            'administrative_mapping': {},
            'complexity_analysis': {}
        }
        
        # ì„ ì¶œì§ ì´ê³„ ê³„ì‚°
        total_positions = sum(level['count'] for level in self.election_structure.values())
        analysis['total_elected_positions'] = total_positions
        
        # ê° ì¸µë³„ ë¶„ì„
        for level_name, level_data in self.election_structure.items():
            analysis['election_levels'][level_name] = {
                'positions': level_data['count'],
                'percentage': round((level_data['count'] / total_positions * 100), 2),
                'prediction_complexity': self._calculate_prediction_complexity(level_name),
                'data_requirements': self._get_data_requirements(level_name)
            }
        
        # í–‰ì •êµ¬ì—­ ë§¤í•‘
        for admin_level, admin_data in self.administrative_hierarchy.items():
            analysis['administrative_mapping'][admin_level] = {
                'units': admin_data['count'],
                'avg_voters_per_unit': self._estimate_voters_per_unit(admin_level),
                'election_relevance': self._assess_election_relevance(admin_level)
            }
        
        # ë³µì¡ë„ ë¶„ì„
        analysis['complexity_analysis'] = {
            'total_prediction_points': self._calculate_total_prediction_points(),
            'data_collection_difficulty': 'HIGH',
            'computational_requirements': 'VERY_HIGH',
            'accuracy_potential': 'EXCELLENT'
        }
        
        logger.info(f"âœ… ì§€ë°©ì„ ê±° êµ¬ì¡° ë¶„ì„ ì™„ë£Œ: {total_positions}ê°œ ì„ ì¶œì§")
        return analysis

    def _calculate_prediction_complexity(self, level_name: str) -> str:
        """ì˜ˆì¸¡ ë³µì¡ë„ ê³„ì‚°"""
        complexity_map = {
            'metropolitan_mayor': 'HIGH',      # ê´‘ì—­ë‹¨ì²´ì¥ - ë³µì¡í•œ ì •ì¹˜ì  ìš”ì¸
            'local_mayor': 'VERY_HIGH',        # ê¸°ì´ˆë‹¨ì²´ì¥ - ì§€ì—­ í˜„ì•ˆ ì¤‘ì‹¬
            'metropolitan_council': 'MEDIUM',   # ê´‘ì—­ì˜ì› - ì •ë‹¹ ì˜í–¥ ì¤‘ê°„
            'local_council': 'EXTREME',        # ê¸°ì´ˆì˜ì› - ê°œì¸ì  ê´€ê³„ ì¤‘ì‹¬
            'education_superintendent': 'LOW'   # êµìœ¡ê° - êµìœ¡ ì •ì±… ì¤‘ì‹¬
        }
        return complexity_map.get(level_name, 'UNKNOWN')

    def _get_data_requirements(self, level_name: str) -> List[str]:
        """ë ˆë²¨ë³„ í•„ìš” ë°ì´í„°"""
        requirements_map = {
            'metropolitan_mayor': ['ì¸êµ¬í†µê³„', 'ê²½ì œì§€í‘œ', 'ì •ì¹˜ì„±í–¥', 'ì–¸ë¡ ë…¸ì¶œ'],
            'local_mayor': ['ì§€ì—­ê²½ì œ', 'ê°œë°œì‚¬ì—…', 'ë¯¼ì›í˜„í™©', 'ì§€ì—­ì–¸ë¡ '],
            'metropolitan_council': ['ì •ë‹¹ì¡°ì§', 'ì§€ì—­êµ¬ì¸êµ¬', 'ì •ì¹˜ê²½ë ¥', 'ê³µì•½ì´í–‰'],
            'local_council': ['ë™ë‹¨ìœ„ì¸êµ¬', 'ì§€ì—­í˜„ì•ˆ', 'ê°œì¸ë„¤íŠ¸ì›Œí¬', 'ë´‰ì‚¬í™œë™'],
            'education_superintendent': ['êµìœ¡í†µê³„', 'í•™ë¶€ëª¨ì—¬ë¡ ', 'êµìœ¡ì •ì±…', 'ê²½ë ¥ì‚¬í•­']
        }
        return requirements_map.get(level_name, [])

    def _estimate_voters_per_unit(self, admin_level: str) -> int:
        """í–‰ì •ë‹¨ìœ„ë³„ í‰ê·  ìœ ê¶Œì ìˆ˜ ì¶”ì •"""
        total_voters = 44000000  # ëŒ€ëµì ì¸ ì „êµ­ ìœ ê¶Œì ìˆ˜
        
        unit_counts = {
            'level_1': 17,      # ì‹œë„
            'level_2': 226,     # ì‹œêµ°êµ¬  
            'level_3': 3497,    # ìë©´ë™
            'level_4': 40000,   # ë¦¬
            'level_5': 100000   # í†µë°˜
        }
        
        count = unit_counts.get(admin_level, 1)
        return total_voters // count

    def _assess_election_relevance(self, admin_level: str) -> str:
        """ì„ ê±° ê´€ë ¨ì„± í‰ê°€"""
        relevance_map = {
            'level_1': 'DIRECT',     # ì‹œë„ - ì§ì ‘ ì„ ê±°êµ¬
            'level_2': 'DIRECT',     # ì‹œêµ°êµ¬ - ì§ì ‘ ì„ ê±°êµ¬
            'level_3': 'HIGH',       # ìë©´ë™ - ë†’ì€ ê´€ë ¨ì„±
            'level_4': 'MEDIUM',     # ë¦¬ - ì¤‘ê°„ ê´€ë ¨ì„±
            'level_5': 'LOW'         # í†µë°˜ - ë‚®ì€ ê´€ë ¨ì„±
        }
        return relevance_map.get(admin_level, 'UNKNOWN')

    def _calculate_total_prediction_points(self) -> int:
        """ì´ ì˜ˆì¸¡ í¬ì¸íŠ¸ ê³„ì‚°"""
        # ëª¨ë“  ì„ ì¶œì§ + í–‰ì •ë™ ë‹¨ìœ„ = ì˜ˆì¸¡ í¬ì¸íŠ¸
        elected_positions = sum(level['count'] for level in self.election_structure.values())
        administrative_units = self.administrative_hierarchy['level_3']['count']  # ìë©´ë™
        return elected_positions + administrative_units

    def build_granular_election_map(self) -> Dict:
        """ì„¸ë°€í•œ ì„ ê±° ì§€ë„ êµ¬ì¶•"""
        logger.info("ğŸ—ºï¸ í–‰ì •ë™ ë‹¨ìœ„ ì„¸ë°€ ì„ ê±° ì§€ë„ êµ¬ì¶•")
        
        granular_map = {
            'metadata': {
                'resolution': 'administrative_dong_level',
                'total_units': 3497,  # ì „êµ­ ìë©´ë™ ìˆ˜
                'prediction_granularity': 'MAXIMUM',
                'created_at': datetime.now().isoformat()
            },
            'hierarchical_structure': {},
            'prediction_models': {},
            'data_integration': {}
        }
        
        # ê³„ì¸µì  êµ¬ì¡° ë§¤í•‘
        for region in ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ê²½ê¸°ë„']:
            granular_map['hierarchical_structure'][region] = self._build_regional_hierarchy(region)
        
        # ì˜ˆì¸¡ ëª¨ë¸ë³„ êµ¬ì„±
        for election_type in self.election_structure.keys():
            granular_map['prediction_models'][election_type] = self._build_prediction_model(election_type)
        
        # ë°ì´í„° í†µí•© ë°©ì•ˆ
        granular_map['data_integration'] = self._design_data_integration()
        
        return granular_map

    def _build_regional_hierarchy(self, region: str) -> Dict:
        """ì§€ì—­ë³„ ê³„ì¸µ êµ¬ì¡° êµ¬ì¶•"""
        # ìƒ˜í”Œ: ì„œìš¸íŠ¹ë³„ì‹œ êµ¬ì¡°
        if region == 'ì„œìš¸íŠ¹ë³„ì‹œ':
            return {
                'level_1': {'name': 'ì„œìš¸íŠ¹ë³„ì‹œ', 'type': 'íŠ¹ë³„ì‹œ'},
                'level_2': [
                    {'name': 'ì¢…ë¡œêµ¬', 'type': 'ìì¹˜êµ¬', 'national_district': 'ì¢…ë¡œêµ¬'},
                    {'name': 'ì¤‘êµ¬', 'type': 'ìì¹˜êµ¬', 'national_district': 'ì¤‘êµ¬Â·ì„±ë™êµ¬ê°‘'},
                    {'name': 'ì„±ë™êµ¬', 'type': 'ìì¹˜êµ¬', 'national_district': 'ì¤‘êµ¬Â·ì„±ë™êµ¬ê°‘,ì„±ë™êµ¬ì„'}
                ],
                'level_3': [
                    {'name': 'ì²­ìš´íš¨ìë™', 'parent': 'ì¢…ë¡œêµ¬', 'voters': 15000},
                    {'name': 'ì‚¬ì§ë™', 'parent': 'ì¢…ë¡œêµ¬', 'voters': 12000},
                    {'name': 'ì‚¼ì²­ë™', 'parent': 'ì¢…ë¡œêµ¬', 'voters': 8000}
                ],
                'election_positions': {
                    'mayor': 1,           # ì„œìš¸ì‹œì¥
                    'district_mayor': 25, # êµ¬ì²­ì¥
                    'metro_council': 106, # ì„œìš¸ì‹œì˜ì›
                    'local_council': 424, # êµ¬ì˜ì›
                    'education_super': 1  # ì„œìš¸êµìœ¡ê°
                }
            }
        
        return {'placeholder': f'{region} êµ¬ì¡° ë§¤í•‘ í•„ìš”'}

    def _build_prediction_model(self, election_type: str) -> Dict:
        """ì„ ê±° ìœ í˜•ë³„ ì˜ˆì¸¡ ëª¨ë¸"""
        models = {
            'metropolitan_mayor': {
                'primary_factors': [
                    {'factor': 'ê²½ì œì„±ê³¼', 'weight': 0.35},
                    {'factor': 'ì •ë‹¹ì§€ì§€ë„', 'weight': 0.25},
                    {'factor': 'í˜„ì•ˆí•´ê²°ë ¥', 'weight': 0.20},
                    {'factor': 'ê°œì¸ì¸ì§€ë„', 'weight': 0.20}
                ],
                'data_sources': ['ê²½ì œí†µê³„', 'ì—¬ë¡ ì¡°ì‚¬', 'ì–¸ë¡ ë¶„ì„', 'ì •ì¹˜ê²½ë ¥'],
                'prediction_accuracy': 'HIGH',
                'update_frequency': 'weekly'
            },
            
            'local_mayor': {
                'primary_factors': [
                    {'factor': 'ì§€ì—­ê°œë°œê³µì•½', 'weight': 0.30},
                    {'factor': 'ì§€ì—­ê²½ì œìƒí™©', 'weight': 0.25},
                    {'factor': 'ê°œì¸ë„¤íŠ¸ì›Œí¬', 'weight': 0.25},
                    {'factor': 'ì •ë‹¹ê³µì²œ', 'weight': 0.20}
                ],
                'data_sources': ['ì§€ì—­ê²½ì œì§€í‘œ', 'ê°œë°œê³„íš', 'ì¸ë§¥ë¶„ì„', 'ì •ë‹¹ì¡°ì§'],
                'prediction_accuracy': 'VERY_HIGH',
                'update_frequency': 'daily'
            },
            
            'local_council': {
                'primary_factors': [
                    {'factor': 'ê°œì¸ì¸ì§€ë„', 'weight': 0.40},
                    {'factor': 'ì§€ì—­ë´‰ì‚¬í™œë™', 'weight': 0.30},
                    {'factor': 'ë™ë„¤í˜„ì•ˆí•´ê²°', 'weight': 0.20},
                    {'factor': 'ì •ë‹¹ì†Œì†', 'weight': 0.10}
                ],
                'data_sources': ['ë™ë‹¨ìœ„í™œë™', 'ë´‰ì‚¬ê¸°ë¡', 'ë¯¼ì›í•´ê²°', 'ì •ë‹¹ê°€ì…'],
                'prediction_accuracy': 'EXTREME',
                'update_frequency': 'real_time'
            }
        }
        
        return models.get(election_type, {'placeholder': 'ëª¨ë¸ ê°œë°œ í•„ìš”'})

    def _design_data_integration(self) -> Dict:
        """ë°ì´í„° í†µí•© ì„¤ê³„"""
        return {
            'integration_strategy': {
                'approach': 'bottom_up_aggregation',
                'description': 'í–‰ì •ë™ â†’ ì‹œêµ°êµ¬ â†’ ì‹œë„ â†’ ì „êµ­ ìˆœ ì§‘ê³„',
                'validation': 'cross_level_consistency_check'
            },
            
            'data_layers': {
                'administrative_boundaries': {
                    'source': 'KOSIS í–‰ì •êµ¬ì—­ì½”ë“œ',
                    'resolution': 'dong_level',
                    'update_frequency': 'annual'
                },
                'demographic_data': {
                    'source': 'KOSIS ì¸êµ¬í†µê³„',
                    'resolution': 'dong_level',
                    'update_frequency': 'monthly'
                },
                'economic_indicators': {
                    'source': 'KOSIS ì§€ì—­ê²½ì œ',
                    'resolution': 'sigungu_level',
                    'update_frequency': 'quarterly'
                },
                'political_history': {
                    'source': 'NEC ì„ ê±°ê²°ê³¼',
                    'resolution': 'precinct_level',
                    'update_frequency': 'post_election'
                }
            },
            
            'prediction_pipeline': {
                'step_1': 'raw_data_collection',
                'step_2': 'administrative_mapping',
                'step_3': 'cross_validation',
                'step_4': 'feature_engineering',
                'step_5': 'model_training',
                'step_6': 'prediction_generation',
                'step_7': 'confidence_scoring'
            }
        }

    def create_comprehensive_dong_database(self) -> Dict:
        """ì „êµ­ í–‰ì •ë™ ì¢…í•© ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±"""
        logger.info("ğŸ˜ï¸ ì „êµ­ í–‰ì •ë™ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±")
        
        dong_database = {
            'metadata': {
                'total_dong': 3497,
                'coverage': 'nationwide',
                'last_updated': datetime.now().isoformat(),
                'data_sources': ['KOSIS', 'NEC', 'MOIS']
            },
            'regions': {}
        }
        
        # ì£¼ìš” ì§€ì—­ë³„ í–‰ì •ë™ êµ¬ì¡° (ìƒ˜í”Œ)
        sample_regions = {
            'ì„œìš¸íŠ¹ë³„ì‹œ': {
                'total_dong': 467,
                'districts': {
                    'ì¢…ë¡œêµ¬': {
                        'dong_list': [
                            {'name': 'ì²­ìš´íš¨ìë™', 'code': '11110101', 'voters': 15234, 'area_km2': 2.15},
                            {'name': 'ì‚¬ì§ë™', 'code': '11110102', 'voters': 12456, 'area_km2': 1.87},
                            {'name': 'ì‚¼ì²­ë™', 'code': '11110103', 'voters': 8234, 'area_km2': 1.23},
                            {'name': 'ë¶€ì•”ë™', 'code': '11110104', 'voters': 9876, 'area_km2': 3.45},
                            {'name': 'í‰ì°½ë™', 'code': '11110105', 'voters': 11234, 'area_km2': 2.67},
                            {'name': 'ë¬´ì•…ë™', 'code': '11110106', 'voters': 13567, 'area_km2': 1.98}
                        ],
                        'total_voters': 70601,
                        'national_assembly_district': 'ì¢…ë¡œêµ¬'
                    },
                    'ì¤‘êµ¬': {
                        'dong_list': [
                            {'name': 'ì†Œê³µë™', 'code': '11140101', 'voters': 8234, 'area_km2': 0.89},
                            {'name': 'íšŒí˜„ë™', 'code': '11140102', 'voters': 6789, 'area_km2': 0.67},
                            {'name': 'ëª…ë™', 'code': '11140103', 'voters': 4567, 'area_km2': 0.45},
                            {'name': 'í•„ë™', 'code': '11140104', 'voters': 7890, 'area_km2': 0.78},
                            {'name': 'ì¥ì¶©ë™', 'code': '11140105', 'voters': 9123, 'area_km2': 1.23}
                        ],
                        'total_voters': 36603,
                        'national_assembly_district': 'ì¤‘êµ¬Â·ì„±ë™êµ¬ê°‘'
                    }
                }
            },
            'ë¶€ì‚°ê´‘ì—­ì‹œ': {
                'total_dong': 201,
                'districts': {
                    'ì¤‘êµ¬': {
                        'dong_list': [
                            {'name': 'ì¤‘ì•™ë™', 'code': '21110101', 'voters': 12345, 'area_km2': 1.45},
                            {'name': 'ë™ê´‘ë™', 'code': '21110102', 'voters': 8967, 'area_km2': 0.89},
                            {'name': 'ëŒ€ì²­ë™', 'code': '21110103', 'voters': 6789, 'area_km2': 2.34}
                        ],
                        'total_voters': 28101,
                        'national_assembly_district': 'ì¤‘êµ¬Â·ì˜ë„êµ¬'
                    }
                }
            }
        }
        
        dong_database['regions'] = sample_regions
        
        return dong_database

    def build_multilevel_prediction_system(self) -> Dict:
        """ë‹¤ì¸µ ì˜ˆì¸¡ ì‹œìŠ¤í…œ êµ¬ì¶•"""
        logger.info("ğŸ¯ ë‹¤ì¸µ ì„ ê±° ì˜ˆì¸¡ ì‹œìŠ¤í…œ êµ¬ì¶•")
        
        prediction_system = {
            'system_architecture': {
                'input_layer': 'administrative_dong_data',
                'processing_layers': [
                    'data_aggregation_layer',
                    'feature_extraction_layer', 
                    'correlation_analysis_layer',
                    'prediction_modeling_layer'
                ],
                'output_layer': 'multi_level_predictions'
            },
            
            'prediction_targets': {
                'national_assembly': {
                    'target_count': 253,
                    'prediction_method': 'constituency_aggregation',
                    'confidence_level': 'HIGH'
                },
                'metropolitan_mayor': {
                    'target_count': 17,
                    'prediction_method': 'regional_sentiment_analysis',
                    'confidence_level': 'HIGH'
                },
                'local_mayor': {
                    'target_count': 226,
                    'prediction_method': 'local_issue_modeling',
                    'confidence_level': 'VERY_HIGH'
                },
                'council_members': {
                    'target_count': 3722,  # 824 + 2898
                    'prediction_method': 'micro_demographic_analysis',
                    'confidence_level': 'EXTREME'
                }
            },
            
            'data_fusion_strategy': {
                'demographic_weight': 0.30,
                'economic_weight': 0.25,
                'social_weight': 0.20,
                'political_history_weight': 0.15,
                'local_issues_weight': 0.10
            }
        }
        
        return prediction_system

    def create_dong_level_data_collector(self) -> str:
        """í–‰ì •ë™ ë‹¨ìœ„ ë°ì´í„° ìˆ˜ì§‘ê¸° ìƒì„±"""
        collector_code = '''#!/usr/bin/env python3
"""
í–‰ì •ë™ ë‹¨ìœ„ ì„¸ë°€ ë°ì´í„° ìˆ˜ì§‘ê¸°
ì „êµ­ 3,497ê°œ ìë©´ë™ ë‹¨ìœ„ ì„ ê±° ì˜ˆì¸¡ ë°ì´í„° ìˆ˜ì§‘
"""

import requests
import json
import time
from datetime import datetime

class DongLevelDataCollector:
    def __init__(self):
        self.api_key = "ZDkwNzNhY2Y4YTg3NjdlNWEyNjg0YmM1NDFlMmFjNmU="
        self.target_dong_count = 3497
        
    def collect_dong_demographics(self, sido_code: str, sigungu_code: str) -> Dict:
        """í–‰ì •ë™ë³„ ì¸êµ¬í†µê³„ ìˆ˜ì§‘"""
        try:
            # KOSIS APIë¡œ ìë©´ë™ ë‹¨ìœ„ ì¸êµ¬ ì¡°íšŒ
            url = "https://kosis.kr/openapi/Param/statisticsParameterData.do"
            params = {
                'method': 'getList',
                'apiKey': self.api_key,
                'orgId': '101',
                'tblId': 'DT_1B04001',  # í–‰ì •êµ¬ì—­ë³„ ì¸êµ¬
                'objL1': sido_code,
                'objL2': sigungu_code,
                'itmId': 'T20',
                'prdSe': 'Y',
                'startPrdDe': '2024',
                'format': 'json'
            }
            
            response = requests.get(url, params=params, timeout=30)
            # ì‘ë‹µ ì²˜ë¦¬ ë¡œì§
            
            return {'success': True, 'data': 'dong_level_data'}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def run_comprehensive_dong_collection(self):
        """ì „êµ­ í–‰ì •ë™ ì¢…í•© ìˆ˜ì§‘"""
        print(f"ğŸ˜ï¸ ì „êµ­ {self.target_dong_count}ê°œ í–‰ì •ë™ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        
        # ì‹¤ì œ ìˆ˜ì§‘ ë¡œì§ êµ¬í˜„ ì˜ˆì •
        collected_data = {
            'total_dong_processed': 0,
            'successful_collections': 0,
            'failed_collections': 0,
            'data_completeness': 0.0
        }
        
        return collected_data

if __name__ == "__main__":
    collector = DongLevelDataCollector()
    result = collector.run_comprehensive_dong_collection()
    print(f"ìˆ˜ì§‘ ê²°ê³¼: {result}")
'''
        
        # íŒŒì¼ ì €ì¥
        with open('/Users/hopidaay/newsbot-kr/backend/dong_level_collector.py', 'w', encoding='utf-8') as f:
            f.write(collector_code)
        
        return '/Users/hopidaay/newsbot-kr/backend/dong_level_collector.py'

    def generate_comprehensive_analysis_plan(self) -> Dict:
        """ì¢…í•© ë¶„ì„ ê³„íš ìƒì„±"""
        return {
            'phase_1': {
                'name': 'ê¸°ì´ˆ ë°ì´í„° ìˆ˜ì§‘',
                'duration': '2-3ì£¼',
                'tasks': [
                    'ì „êµ­ 3,497ê°œ í–‰ì •ë™ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘',
                    'ì¸êµ¬í†µê³„ ë°ì´í„° ìˆ˜ì§‘ (KOSIS API)',
                    'ì„ ê±°êµ¬ ë§¤í•‘ í…Œì´ë¸” êµ¬ì¶•',
                    'ë°ì´í„° í’ˆì§ˆ ê²€ì¦'
                ],
                'expected_output': 'í–‰ì •ë™ ë‹¨ìœ„ ê¸°ì´ˆ ë°ì´í„°ë² ì´ìŠ¤'
            },
            
            'phase_2': {
                'name': 'ì„¸ë°€ ë¶„ì„ ëª¨ë¸ êµ¬ì¶•',
                'duration': '3-4ì£¼', 
                'tasks': [
                    'ë‹¤ì¸µ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ',
                    'ìƒê´€ê´€ê³„ ë¶„ì„ ì—”ì§„ êµ¬ì¶•',
                    'ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ',
                    'ì˜ˆì¸¡ ì •í™•ë„ ê²€ì¦ ì‹œìŠ¤í…œ'
                ],
                'expected_output': 'í–‰ì •ë™ ë‹¨ìœ„ ì„ ê±° ì˜ˆì¸¡ ì—”ì§„'
            },
            
            'phase_3': {
                'name': 'í†µí•© ì‹œê°í™” ì‹œìŠ¤í…œ',
                'duration': '2-3ì£¼',
                'tasks': [
                    'ë‹¤ì¸µ ì§€ë„ ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•',
                    'ë“œë¦´ë‹¤ìš´ ë¶„ì„ ê¸°ëŠ¥',
                    'ì‹¤ì‹œê°„ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ',
                    'ëª¨ë°”ì¼ ìµœì í™”'
                ],
                'expected_output': 'ì™„ì „í•œ ì„ ê±° ë¶„ì„ í”Œë«í¼'
            },
            
            'total_timeline': '7-10ì£¼',
            'resource_requirements': {
                'data_storage': '10-50GB',
                'processing_power': 'HIGH',
                'api_calls': '100,000+',
                'development_time': '200-300ì‹œê°„'
            }
        }

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    analyzer = LocalElectionAnalyzer()
    
    print("ğŸ›ï¸ ì§€ë°©ì„ ê±° ì„¸ë°€ ë¶„ì„ ì‹œìŠ¤í…œ êµ¬ì¶•")
    print("=" * 60)
    
    # 1. ì§€ë°©ì„ ê±° êµ¬ì¡° ë¶„ì„
    structure_analysis = analyzer.analyze_local_election_structure()
    print(f"ğŸ“Š ì´ ì„ ì¶œì§: {structure_analysis['total_elected_positions']:,}ê°œ")
    
    # 2. ì„¸ë°€ ì§€ë„ êµ¬ì¶•
    granular_map = analyzer.build_granular_election_map()
    print(f"ğŸ—ºï¸ í–‰ì •ë™ ë‹¨ìœ„: {granular_map['metadata']['total_units']:,}ê°œ")
    
    # 3. ë‹¤ì¸µ ì˜ˆì¸¡ ì‹œìŠ¤í…œ
    prediction_system = analyzer.build_multilevel_prediction_system()
    print(f"ğŸ¯ ì˜ˆì¸¡ ëŒ€ìƒ: {sum(target['target_count'] for target in prediction_system['prediction_targets'].values()):,}ê°œ")
    
    # 4. í–‰ì •ë™ ìˆ˜ì§‘ê¸° ìƒì„±
    collector_path = analyzer.create_dong_level_data_collector()
    print(f"ğŸ’¾ ìˆ˜ì§‘ê¸° ìƒì„±: {collector_path}")
    
    # 5. ì¢…í•© ê³„íš
    analysis_plan = analyzer.generate_comprehensive_analysis_plan()
    print(f"ğŸ“‹ ì˜ˆìƒ ê¸°ê°„: {analysis_plan['total_timeline']}")
    
    # ê²°ê³¼ ì €ì¥
    comprehensive_result = {
        'structure_analysis': structure_analysis,
        'granular_map': granular_map,
        'prediction_system': prediction_system,
        'analysis_plan': analysis_plan,
        'created_at': datetime.now().isoformat()
    }
    
    with open('/Users/hopidaay/newsbot-kr/backend/local_election_comprehensive_plan.json', 'w', encoding='utf-8') as f:
        json.dump(comprehensive_result, f, ensure_ascii=False, indent=2)
    
    print("âœ… ì§€ë°©ì„ ê±° ì„¸ë°€ ë¶„ì„ ì‹œìŠ¤í…œ ì„¤ê³„ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
