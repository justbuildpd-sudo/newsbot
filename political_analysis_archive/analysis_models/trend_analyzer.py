#!/usr/bin/env python3
"""
ë‰´ìŠ¤ ë°ì´í„° ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ
ë„¤ì´ë²„ ë‰´ìŠ¤ API ë°ì´í„°ë¡œ ì •ì¹˜ì¸ íŠ¸ë Œë“œ ì°¨íŠ¸ ìƒì„±
"""

import json
import re
from datetime import datetime, timedelta
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)

class TrendAnalyzer:
    def __init__(self):
        self.load_news_data()
        self.load_politicians_data()
    
    def load_news_data(self):
        """ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ"""
        try:
            with open('naver_news_collected.json', 'r', encoding='utf-8') as f:
                self.news_data = json.load(f)
            total_news = sum(len(news) for news in self.news_data.values())
            logger.info(f"ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ: {len(self.news_data)}ëª…, {total_news}ê±´")
        except FileNotFoundError:
            self.news_data = {}
            logger.warning("ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    
    def load_politicians_data(self):
        """ì •ì¹˜ì¸ ë°ì´í„° ë¡œë“œ"""
        try:
            with open('22nd_assembly_members_300.json', 'r', encoding='utf-8') as f:
                members = json.load(f)
            self.politicians_info = {member.get('naas_nm', ''): member for member in members if member.get('naas_nm')}
            logger.info(f"ì •ì¹˜ì¸ ì •ë³´ ë¡œë“œ: {len(self.politicians_info)}ëª…")
        except FileNotFoundError:
            self.politicians_info = {}
            logger.warning("ì •ì¹˜ì¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    
    def analyze_mention_trends(self):
        """ë‰´ìŠ¤ ì–¸ê¸‰ëŸ‰ ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„"""
        trends = {}
        
        for politician, news_list in self.news_data.items():
            if not news_list:
                continue
            
            # ì¼ë³„ ì–¸ê¸‰ëŸ‰ ê³„ì‚°
            daily_mentions = defaultdict(int)
            sentiment_by_date = defaultdict(lambda: {'positive': 0, 'negative': 0, 'neutral': 0})
            
            for news in news_list:
                # ë‚ ì§œ ì¶”ì¶œ (RFC 2822 í˜•ì‹)
                pub_date_str = news.get('pub_date', '')
                try:
                    from email.utils import parsedate_to_datetime
                    pub_date = parsedate_to_datetime(pub_date_str)
                    date_key = pub_date.strftime('%Y-%m-%d')
                    
                    daily_mentions[date_key] += 1
                    sentiment = news.get('sentiment', 'neutral')
                    sentiment_by_date[date_key][sentiment] += 1
                    
                except:
                    # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì²˜ë¦¬
                    today = datetime.now().strftime('%Y-%m-%d')
                    daily_mentions[today] += 1
                    sentiment = news.get('sentiment', 'neutral')
                    sentiment_by_date[today][sentiment] += 1
            
            # íŠ¸ë Œë“œ ë°ì´í„° êµ¬ì„±
            trend_points = []
            for date, count in sorted(daily_mentions.items()):
                sentiments = sentiment_by_date[date]
                trend_points.append({
                    'date': date,
                    'mentions': count,
                    'positive': sentiments['positive'],
                    'negative': sentiments['negative'], 
                    'neutral': sentiments['neutral'],
                    'sentiment_ratio': sentiments['positive'] / count if count > 0 else 0
                })
            
            # í†µê³„ ê³„ì‚°
            total_mentions = sum(point['mentions'] for point in trend_points)
            avg_mentions = total_mentions / len(trend_points) if trend_points else 0
            
            trends[politician] = {
                'politician': politician,
                'party': self.politicians_info.get(politician, {}).get('party_name', 'ë¬´ì†Œì†'),
                'total_mentions': total_mentions,
                'average_mentions': round(avg_mentions, 2),
                'trend_points': trend_points,
                'peak_date': max(trend_points, key=lambda x: x['mentions'])['date'] if trend_points else None,
                'sentiment_summary': {
                    'positive': sum(point['positive'] for point in trend_points),
                    'negative': sum(point['negative'] for point in trend_points),
                    'neutral': sum(point['neutral'] for point in trend_points)
                }
            }
        
        return trends
    
    def create_trending_ranking(self, trends):
        """íŠ¸ë Œë”© ë­í‚¹ ìƒì„±"""
        ranking = []
        
        for politician, trend_data in trends.items():
            ranking.append({
                'rank': 0,  # ë‚˜ì¤‘ì— ì„¤ì •
                'politician': politician,
                'party': trend_data['party'],
                'total_mentions': trend_data['total_mentions'],
                'average_mentions': trend_data['average_mentions'],
                'sentiment_ratio': trend_data['sentiment_summary']['positive'] / trend_data['total_mentions'] if trend_data['total_mentions'] > 0 else 0,
                'peak_date': trend_data['peak_date']
            })
        
        # ì´ ì–¸ê¸‰ëŸ‰ ê¸°ì¤€ ì •ë ¬
        ranking.sort(key=lambda x: x['total_mentions'], reverse=True)
        
        # ìˆœìœ„ ë¶€ì—¬
        for i, item in enumerate(ranking):
            item['rank'] = i + 1
        
        return ranking
    
    def generate_chart_data(self, trends, chart_type="mentions"):
        """ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
        chart_data = {
            'type': chart_type,
            'labels': [],
            'datasets': []
        }
        
        if not trends:
            return chart_data
        
        # ëª¨ë“  ë‚ ì§œ ìˆ˜ì§‘
        all_dates = set()
        for trend_data in trends.values():
            for point in trend_data['trend_points']:
                all_dates.add(point['date'])
        
        # ë‚ ì§œ ì •ë ¬
        sorted_dates = sorted(all_dates)
        chart_data['labels'] = sorted_dates
        
        # ê° ì •ì¹˜ì¸ë³„ ë°ì´í„°ì…‹ ìƒì„±
        colors = ['#3B82F6', '#EF4444', '#8B5CF6', '#10B981', '#F59E0B']
        
        for i, (politician, trend_data) in enumerate(trends.items()):
            # ë‚ ì§œë³„ ë°ì´í„° ë§¤í•‘
            date_values = {}
            for point in trend_data['trend_points']:
                if chart_type == "mentions":
                    date_values[point['date']] = point['mentions']
                elif chart_type == "sentiment":
                    date_values[point['date']] = point['sentiment_ratio']
            
            # ëª¨ë“  ë‚ ì§œì— ëŒ€í•œ ê°’ ìƒì„± (ì—†ëŠ” ë‚ ì§œëŠ” 0)
            values = [date_values.get(date, 0) for date in sorted_dates]
            
            dataset = {
                'label': politician,
                'data': values,
                'borderColor': colors[i % len(colors)],
                'backgroundColor': colors[i % len(colors)] + '20',  # íˆ¬ëª…ë„ ì¶”ê°€
                'tension': 0.4
            }
            
            chart_data['datasets'].append(dataset)
        
        return chart_data
    
    def save_trend_analysis(self, trends, ranking, chart_data):
        """íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        analysis_result = {
            'generated_at': datetime.now().isoformat(),
            'trends': trends,
            'ranking': ranking,
            'chart_data': chart_data,
            'summary': {
                'total_politicians': len(trends),
                'total_mentions': sum(t['total_mentions'] for t in trends.values()),
                'top_politician': ranking[0]['politician'] if ranking else None,
                'analysis_period': f"ìµœê·¼ {len(chart_data.get('labels', []))}ì¼"
            }
        }
        
        filename = 'trend_analysis_result.json'
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(analysis_result, f, ensure_ascii=False, indent=2)
            
            logger.info(f"íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼ ì €ì¥: {filename}")
            return filename
        except Exception as e:
            logger.error(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")
            return None

def main():
    analyzer = TrendAnalyzer()
    
    print("ğŸ“ˆ ë‰´ìŠ¤ ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘")
    
    # 1. ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ ë¶„ì„
    trends = analyzer.analyze_mention_trends()
    if trends:
        print(f"âœ… íŠ¸ë Œë“œ ë¶„ì„ ì™„ë£Œ: {len(trends)}ëª…")
        
        # 2. ë­í‚¹ ìƒì„±
        ranking = analyzer.create_trending_ranking(trends)
        print(f"âœ… ë­í‚¹ ìƒì„± ì™„ë£Œ: {len(ranking)}ëª…")
        
        print("\nğŸ“Š íŠ¸ë Œë”© ë­í‚¹:")
        for item in ranking:
            print(f"  {item['rank']}. {item['politician']} ({item['party']})")
            print(f"     ì´ ì–¸ê¸‰: {item['total_mentions']}ê±´, í‰ê· : {item['average_mentions']:.1f}ê±´")
            print(f"     ê°ì •ë¹„ìœ¨: {item['sentiment_ratio']:.2f}, í”¼í¬: {item['peak_date']}")
        
        # 3. ì°¨íŠ¸ ë°ì´í„° ìƒì„±
        chart_data = analyzer.generate_chart_data(trends, "mentions")
        print(f"âœ… ì°¨íŠ¸ ë°ì´í„° ìƒì„±: {len(chart_data['datasets'])}ê°œ ë°ì´í„°ì…‹")
        
        # 4. ê²°ê³¼ ì €ì¥
        result_file = analyzer.save_trend_analysis(trends, ranking, chart_data)
        if result_file:
            print(f"ğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥: {result_file}")
    else:
        print("âŒ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()

